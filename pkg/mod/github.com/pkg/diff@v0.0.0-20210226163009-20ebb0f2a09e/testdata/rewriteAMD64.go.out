--- testdata/rewriteAMD64.go.a
+++ testdata/rewriteAMD64.go.b
@@ -1199,7 +1199,6 @@
 		return true
 	}
 	// match: (ADCQ x y (FlagEQ))
-	// cond:
 	// result: (ADDQcarry x y)
 	for {
 		_ = v.Args[2]
@@ -1218,7 +1217,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADCQconst_0(v *Value) bool {
 	// match: (ADCQconst x [c] (FlagEQ))
-	// cond:
 	// result: (ADDQconstcarry x [c])
 	for {
 		c := v.AuxInt
@@ -1237,7 +1235,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDL_0(v *Value) bool {
 	// match: (ADDL x (MOVLconst [c]))
-	// cond:
 	// result: (ADDLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -1253,7 +1250,6 @@
 		return true
 	}
 	// match: (ADDL (MOVLconst [c]) x)
-	// cond:
 	// result: (ADDLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -1283,12 +1279,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -1310,12 +1303,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -1338,12 +1328,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -1366,12 +1353,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -1394,12 +1378,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -1422,30 +1403,23 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (ADDL x (SHLLconst [3] y))
-	// cond:
 	// result: (LEAL8 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AddArg(x)
@@ -1453,17 +1427,13 @@
 		return true
 	}
 	// match: (ADDL (SHLLconst [3] y) x)
-	// cond:
 	// result: (LEAL8 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AddArg(x)
@@ -1474,18 +1444,14 @@
 }
 func rewriteValueAMD64_OpAMD64ADDL_10(v *Value) bool {
 	// match: (ADDL x (SHLLconst [2] y))
-	// cond:
 	// result: (LEAL4 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL4)
 		v.AddArg(x)
@@ -1493,17 +1459,13 @@
 		return true
 	}
 	// match: (ADDL (SHLLconst [2] y) x)
-	// cond:
 	// result: (LEAL4 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 2 {
 			break
 		}
-		if v_0.AuxInt != 2 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL4)
 		v.AddArg(x)
@@ -1511,18 +1473,14 @@
 		return true
 	}
 	// match: (ADDL x (SHLLconst [1] y))
-	// cond:
 	// result: (LEAL2 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL2)
 		v.AddArg(x)
@@ -1530,17 +1488,13 @@
 		return true
 	}
 	// match: (ADDL (SHLLconst [1] y) x)
-	// cond:
 	// result: (LEAL2 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL2)
 		v.AddArg(x)
@@ -1548,7 +1502,6 @@
 		return true
 	}
 	// match: (ADDL x (ADDL y y))
-	// cond:
 	// result: (LEAL2 x y)
 	for {
 		_ = v.Args[1]
@@ -1567,7 +1520,6 @@
 		return true
 	}
 	// match: (ADDL (ADDL y y) x)
-	// cond:
 	// result: (LEAL2 x y)
 	for {
 		x := v.Args[1]
@@ -1585,7 +1537,6 @@
 		return true
 	}
 	// match: (ADDL x (ADDL x y))
-	// cond:
 	// result: (LEAL2 y x)
 	for {
 		_ = v.Args[1]
@@ -1604,7 +1555,6 @@
 		return true
 	}
 	// match: (ADDL x (ADDL y x))
-	// cond:
 	// result: (LEAL2 y x)
 	for {
 		_ = v.Args[1]
@@ -1624,7 +1574,6 @@
 		return true
 	}
 	// match: (ADDL (ADDL x y) x)
-	// cond:
 	// result: (LEAL2 y x)
 	for {
 		x := v.Args[1]
@@ -1642,7 +1591,6 @@
 		return true
 	}
 	// match: (ADDL (ADDL y x) x)
-	// cond:
 	// result: (LEAL2 y x)
 	for {
 		x := v.Args[1]
@@ -1664,7 +1612,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDL_20(v *Value) bool {
 	// match: (ADDL (ADDLconst [c] x) y)
-	// cond:
 	// result: (LEAL1 [c] x y)
 	for {
 		y := v.Args[1]
@@ -1681,7 +1628,6 @@
 		return true
 	}
 	// match: (ADDL y (ADDLconst [c] x))
-	// cond:
 	// result: (LEAL1 [c] x y)
 	for {
 		_ = v.Args[1]
@@ -1744,7 +1690,6 @@
 		return true
 	}
 	// match: (ADDL x (NEGL y))
-	// cond:
 	// result: (SUBL x y)
 	for {
 		_ = v.Args[1]
@@ -1760,7 +1705,6 @@
 		return true
 	}
 	// match: (ADDL (NEGL y) x)
-	// cond:
 	// result: (SUBL x y)
 	for {
 		x := v.Args[1]
@@ -1827,7 +1771,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDLconst_0(v *Value) bool {
 	// match: (ADDLconst [c] (ADDL x y))
-	// cond:
 	// result: (LEAL1 [c] x y)
 	for {
 		c := v.AuxInt
@@ -1844,17 +1787,13 @@
 		return true
 	}
 	// match: (ADDLconst [c] (SHLLconst [1] x))
-	// cond:
 	// result: (LEAL1 [c] x x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64LEAL1)
 		v.AuxInt = c
@@ -1990,7 +1929,6 @@
 		return true
 	}
 	// match: (ADDLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [int64(int32(c+d))])
 	for {
 		c := v.AuxInt
@@ -2004,7 +1942,6 @@
 		return true
 	}
 	// match: (ADDLconst [c] (ADDLconst [d] x))
-	// cond:
 	// result: (ADDLconst [int64(int32(c+d))] x)
 	for {
 		c := v.AuxInt
@@ -2023,7 +1960,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDLconst_10(v *Value) bool {
 	// match: (ADDLconst [off] x:(SP))
-	// cond:
 	// result: (LEAL [off] x)
 	for {
 		off := v.AuxInt
@@ -2143,7 +2079,6 @@
 		return true
 	}
 	// match: (ADDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ADDL x (MOVLf2i y))
 	for {
 		off := v.AuxInt
@@ -2152,15 +2087,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSSstore {
+		if v_2.Op != OpAMD64MOVSSstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -2283,12 +2212,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -2310,30 +2236,23 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (ADDQ x (SHLQconst [3] y))
-	// cond:
 	// result: (LEAQ8 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AddArg(x)
@@ -2341,17 +2260,13 @@
 		return true
 	}
 	// match: (ADDQ (SHLQconst [3] y) x)
-	// cond:
 	// result: (LEAQ8 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AddArg(x)
@@ -2359,18 +2274,14 @@
 		return true
 	}
 	// match: (ADDQ x (SHLQconst [2] y))
-	// cond:
 	// result: (LEAQ4 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ4)
 		v.AddArg(x)
@@ -2378,17 +2289,13 @@
 		return true
 	}
 	// match: (ADDQ (SHLQconst [2] y) x)
-	// cond:
 	// result: (LEAQ4 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 2 {
 			break
 		}
-		if v_0.AuxInt != 2 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ4)
 		v.AddArg(x)
@@ -2396,18 +2303,14 @@
 		return true
 	}
 	// match: (ADDQ x (SHLQconst [1] y))
-	// cond:
 	// result: (LEAQ2 x y)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ2)
 		v.AddArg(x)
@@ -2415,17 +2318,13 @@
 		return true
 	}
 	// match: (ADDQ (SHLQconst [1] y) x)
-	// cond:
 	// result: (LEAQ2 x y)
 	for {
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ2)
 		v.AddArg(x)
@@ -2436,7 +2335,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDQ_10(v *Value) bool {
 	// match: (ADDQ x (ADDQ y y))
-	// cond:
 	// result: (LEAQ2 x y)
 	for {
 		_ = v.Args[1]
@@ -2455,7 +2353,6 @@
 		return true
 	}
 	// match: (ADDQ (ADDQ y y) x)
-	// cond:
 	// result: (LEAQ2 x y)
 	for {
 		x := v.Args[1]
@@ -2473,7 +2370,6 @@
 		return true
 	}
 	// match: (ADDQ x (ADDQ x y))
-	// cond:
 	// result: (LEAQ2 y x)
 	for {
 		_ = v.Args[1]
@@ -2492,7 +2388,6 @@
 		return true
 	}
 	// match: (ADDQ x (ADDQ y x))
-	// cond:
 	// result: (LEAQ2 y x)
 	for {
 		_ = v.Args[1]
@@ -2512,7 +2407,6 @@
 		return true
 	}
 	// match: (ADDQ (ADDQ x y) x)
-	// cond:
 	// result: (LEAQ2 y x)
 	for {
 		x := v.Args[1]
@@ -2530,7 +2424,6 @@
 		return true
 	}
 	// match: (ADDQ (ADDQ y x) x)
-	// cond:
 	// result: (LEAQ2 y x)
 	for {
 		x := v.Args[1]
@@ -2549,7 +2442,6 @@
 		return true
 	}
 	// match: (ADDQ (ADDQconst [c] x) y)
-	// cond:
 	// result: (LEAQ1 [c] x y)
 	for {
 		y := v.Args[1]
@@ -2566,7 +2458,6 @@
 		return true
 	}
 	// match: (ADDQ y (ADDQconst [c] x))
-	// cond:
 	// result: (LEAQ1 [c] x y)
 	for {
 		_ = v.Args[1]
@@ -2632,7 +2523,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDQ_20(v *Value) bool {
 	// match: (ADDQ x (NEGQ y))
-	// cond:
 	// result: (SUBQ x y)
 	for {
 		_ = v.Args[1]
@@ -2648,7 +2538,6 @@
 		return true
 	}
 	// match: (ADDQ (NEGQ y) x)
-	// cond:
 	// result: (SUBQ x y)
 	for {
 		x := v.Args[1]
@@ -2755,7 +2644,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDQconst_0(v *Value) bool {
 	// match: (ADDQconst [c] (ADDQ x y))
-	// cond:
 	// result: (LEAQ1 [c] x y)
 	for {
 		c := v.AuxInt
@@ -2772,17 +2660,13 @@
 		return true
 	}
 	// match: (ADDQconst [c] (SHLQconst [1] x))
-	// cond:
 	// result: (LEAQ1 [c] x x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64LEAQ1)
 		v.AuxInt = c
@@ -2904,7 +2788,6 @@
 		return true
 	}
 	// match: (ADDQconst [0] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -2917,7 +2800,6 @@
 		return true
 	}
 	// match: (ADDQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [c+d])
 	for {
 		c := v.AuxInt
@@ -2953,7 +2835,6 @@
 }
 func rewriteValueAMD64_OpAMD64ADDQconst_10(v *Value) bool {
 	// match: (ADDQconst [off] x:(SP))
-	// cond:
 	// result: (LEAQ [off] x)
 	for {
 		off := v.AuxInt
@@ -3073,7 +2954,6 @@
 		return true
 	}
 	// match: (ADDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ADDQ x (MOVQf2i y))
 	for {
 		off := v.AuxInt
@@ -3082,15 +2962,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSDstore {
+		if v_2.Op != OpAMD64MOVSDstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -3266,7 +3140,6 @@
 		return true
 	}
 	// match: (ADDSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ADDSD x (MOVQi2f y))
 	for {
 		off := v.AuxInt
@@ -3275,15 +3148,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVQstore {
+		if v_2.Op != OpAMD64MOVQstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -3405,7 +3272,6 @@
 		return true
 	}
 	// match: (ADDSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ADDSS x (MOVLi2f y))
 	for {
 		off := v.AuxInt
@@ -3414,15 +3280,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVLstore {
+		if v_2.Op != OpAMD64MOVLstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -3455,15 +3315,9 @@
 		}
 		y := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVLconst {
+		if v_0_0_0.Op != OpAMD64MOVLconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTRL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -3485,15 +3339,9 @@
 		}
 		y := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVLconst {
+		if v_1_0_0.Op != OpAMD64MOVLconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTRL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -3537,7 +3385,6 @@
 		return true
 	}
 	// match: (ANDL x (MOVLconst [c]))
-	// cond:
 	// result: (ANDLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -3553,7 +3400,6 @@
 		return true
 	}
 	// match: (ANDL (MOVLconst [c]) x)
-	// cond:
 	// result: (ANDLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -3568,7 +3414,6 @@
 		return true
 	}
 	// match: (ANDL x x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[1]
@@ -3649,7 +3494,6 @@
 		return true
 	}
 	// match: (ANDLconst [c] (ANDLconst [d] x))
-	// cond:
 	// result: (ANDLconst [c & d] x)
 	for {
 		c := v.AuxInt
@@ -3665,7 +3509,6 @@
 		return true
 	}
 	// match: (ANDLconst [c] (BTRLconst [d] x))
-	// cond:
 	// result: (ANDLconst [c &^ (1<<uint32(d))] x)
 	for {
 		c := v.AuxInt
@@ -3681,7 +3524,6 @@
 		return true
 	}
 	// match: (ANDLconst [ 0xFF] x)
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		if v.AuxInt != 0xFF {
@@ -3693,7 +3535,6 @@
 		return true
 	}
 	// match: (ANDLconst [0xFFFF] x)
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		if v.AuxInt != 0xFFFF {
@@ -3731,7 +3572,6 @@
 		return true
 	}
 	// match: (ANDLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [c&d])
 	for {
 		c := v.AuxInt
@@ -3851,7 +3691,6 @@
 		return true
 	}
 	// match: (ANDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ANDL x (MOVLf2i y))
 	for {
 		off := v.AuxInt
@@ -3860,15 +3699,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSSstore {
+		if v_2.Op != OpAMD64MOVSSstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -3955,15 +3788,9 @@
 		}
 		y := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0_0.Op != OpAMD64MOVQconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTRQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -3985,15 +3812,9 @@
 		}
 		y := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVQconst {
+		if v_1_0_0.Op != OpAMD64MOVQconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTRQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -4074,7 +3895,6 @@
 		return true
 	}
 	// match: (ANDQ x x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[1]
@@ -4155,7 +3975,6 @@
 		return true
 	}
 	// match: (ANDQconst [c] (ANDQconst [d] x))
-	// cond:
 	// result: (ANDQconst [c & d] x)
 	for {
 		c := v.AuxInt
@@ -4171,7 +3990,6 @@
 		return true
 	}
 	// match: (ANDQconst [c] (BTRQconst [d] x))
-	// cond:
 	// result: (ANDQconst [c &^ (1<<uint32(d))] x)
 	for {
 		c := v.AuxInt
@@ -4187,7 +4005,6 @@
 		return true
 	}
 	// match: (ANDQconst [ 0xFF] x)
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		if v.AuxInt != 0xFF {
@@ -4199,7 +4016,6 @@
 		return true
 	}
 	// match: (ANDQconst [0xFFFF] x)
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		if v.AuxInt != 0xFFFF {
@@ -4211,7 +4027,6 @@
 		return true
 	}
 	// match: (ANDQconst [0xFFFFFFFF] x)
-	// cond:
 	// result: (MOVLQZX x)
 	for {
 		if v.AuxInt != 0xFFFFFFFF {
@@ -4223,7 +4038,6 @@
 		return true
 	}
 	// match: (ANDQconst [0] _)
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		if v.AuxInt != 0 {
@@ -4234,7 +4048,6 @@
 		return true
 	}
 	// match: (ANDQconst [-1] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != -1 {
@@ -4247,7 +4060,6 @@
 		return true
 	}
 	// match: (ANDQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [c&d])
 	for {
 		c := v.AuxInt
@@ -4367,7 +4179,6 @@
 		return true
 	}
 	// match: (ANDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
-	// cond:
 	// result: (ANDQ x (MOVQf2i y))
 	for {
 		off := v.AuxInt
@@ -4376,15 +4187,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSDstore {
+		if v_2.Op != OpAMD64MOVSDstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -4456,7 +4261,6 @@
 func rewriteValueAMD64_OpAMD64BSFQ_0(v *Value) bool {
 	b := v.Block
 	// match: (BSFQ (ORQconst <t> [1<<8] (MOVBQZX x)))
-	// cond:
 	// result: (BSFQ (ORQconst <t> [1<<8] x))
 	for {
 		v_0 := v.Args[0]
@@ -4480,7 +4284,6 @@
 		return true
 	}
 	// match: (BSFQ (ORQconst <t> [1<<16] (MOVWQZX x)))
-	// cond:
 	// result: (BSFQ (ORQconst <t> [1<<16] x))
 	for {
 		v_0 := v.Args[0]
@@ -4507,7 +4310,6 @@
 }
 func rewriteValueAMD64_OpAMD64BTCLconst_0(v *Value) bool {
 	// match: (BTCLconst [c] (XORLconst [d] x))
-	// cond:
 	// result: (XORLconst [d ^ 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -4523,7 +4325,6 @@
 		return true
 	}
 	// match: (BTCLconst [c] (BTCLconst [d] x))
-	// cond:
 	// result: (XORLconst [1<<uint32(c) ^ 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -4539,7 +4340,6 @@
 		return true
 	}
 	// match: (BTCLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [d^(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -4660,7 +4460,6 @@
 }
 func rewriteValueAMD64_OpAMD64BTCQconst_0(v *Value) bool {
 	// match: (BTCQconst [c] (XORQconst [d] x))
-	// cond:
 	// result: (XORQconst [d ^ 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -4676,7 +4475,6 @@
 		return true
 	}
 	// match: (BTCQconst [c] (BTCQconst [d] x))
-	// cond:
 	// result: (XORQconst [1<<uint32(c) ^ 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -4692,7 +4490,6 @@
 		return true
 	}
 	// match: (BTCQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [d^(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -4851,7 +4648,6 @@
 		return true
 	}
 	// match: (BTLconst [0] s:(SHRQ x y))
-	// cond:
 	// result: (BTQ y x)
 	for {
 		if v.AuxInt != 0 {
@@ -4907,7 +4703,6 @@
 		return true
 	}
 	// match: (BTLconst [0] s:(SHRL x y))
-	// cond:
 	// result: (BTL y x)
 	for {
 		if v.AuxInt != 0 {
@@ -4966,7 +4761,6 @@
 		return true
 	}
 	// match: (BTQconst [0] s:(SHRQ x y))
-	// cond:
 	// result: (BTQ y x)
 	for {
 		if v.AuxInt != 0 {
@@ -4987,17 +4781,13 @@
 }
 func rewriteValueAMD64_OpAMD64BTRLconst_0(v *Value) bool {
 	// match: (BTRLconst [c] (BTSLconst [c] x))
-	// cond:
 	// result: (BTRLconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTSLconst {
+		if v_0.Op != OpAMD64BTSLconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTRLconst)
 		v.AuxInt = c
@@ -5005,17 +4795,13 @@
 		return true
 	}
 	// match: (BTRLconst [c] (BTCLconst [c] x))
-	// cond:
 	// result: (BTRLconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTCLconst {
+		if v_0.Op != OpAMD64BTCLconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTRLconst)
 		v.AuxInt = c
@@ -5023,7 +4809,6 @@
 		return true
 	}
 	// match: (BTRLconst [c] (ANDLconst [d] x))
-	// cond:
 	// result: (ANDLconst [d &^ (1<<uint32(c))] x)
 	for {
 		c := v.AuxInt
@@ -5039,7 +4824,6 @@
 		return true
 	}
 	// match: (BTRLconst [c] (BTRLconst [d] x))
-	// cond:
 	// result: (ANDLconst [^(1<<uint32(c) | 1<<uint32(d))] x)
 	for {
 		c := v.AuxInt
@@ -5055,7 +4839,6 @@
 		return true
 	}
 	// match: (BTRLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [d&^(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -5176,17 +4959,13 @@
 }
 func rewriteValueAMD64_OpAMD64BTRQconst_0(v *Value) bool {
 	// match: (BTRQconst [c] (BTSQconst [c] x))
-	// cond:
 	// result: (BTRQconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTSQconst {
+		if v_0.Op != OpAMD64BTSQconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTRQconst)
 		v.AuxInt = c
@@ -5194,17 +4973,13 @@
 		return true
 	}
 	// match: (BTRQconst [c] (BTCQconst [c] x))
-	// cond:
 	// result: (BTRQconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTCQconst {
+		if v_0.Op != OpAMD64BTCQconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTRQconst)
 		v.AuxInt = c
@@ -5212,7 +4987,6 @@
 		return true
 	}
 	// match: (BTRQconst [c] (ANDQconst [d] x))
-	// cond:
 	// result: (ANDQconst [d &^ (1<<uint32(c))] x)
 	for {
 		c := v.AuxInt
@@ -5228,7 +5002,6 @@
 		return true
 	}
 	// match: (BTRQconst [c] (BTRQconst [d] x))
-	// cond:
 	// result: (ANDQconst [^(1<<uint32(c) | 1<<uint32(d))] x)
 	for {
 		c := v.AuxInt
@@ -5244,7 +5017,6 @@
 		return true
 	}
 	// match: (BTRQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [d&^(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -5365,17 +5137,13 @@
 }
 func rewriteValueAMD64_OpAMD64BTSLconst_0(v *Value) bool {
 	// match: (BTSLconst [c] (BTRLconst [c] x))
-	// cond:
 	// result: (BTSLconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTRLconst {
+		if v_0.Op != OpAMD64BTRLconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTSLconst)
 		v.AuxInt = c
@@ -5383,17 +5151,13 @@
 		return true
 	}
 	// match: (BTSLconst [c] (BTCLconst [c] x))
-	// cond:
 	// result: (BTSLconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTCLconst {
+		if v_0.Op != OpAMD64BTCLconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTSLconst)
 		v.AuxInt = c
@@ -5401,7 +5165,6 @@
 		return true
 	}
 	// match: (BTSLconst [c] (ORLconst [d] x))
-	// cond:
 	// result: (ORLconst [d | 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -5417,7 +5180,6 @@
 		return true
 	}
 	// match: (BTSLconst [c] (BTSLconst [d] x))
-	// cond:
 	// result: (ORLconst [1<<uint32(d) | 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -5433,7 +5195,6 @@
 		return true
 	}
 	// match: (BTSLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [d|(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -5554,17 +5315,13 @@
 }
 func rewriteValueAMD64_OpAMD64BTSQconst_0(v *Value) bool {
 	// match: (BTSQconst [c] (BTRQconst [c] x))
-	// cond:
 	// result: (BTSQconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTRQconst {
+		if v_0.Op != OpAMD64BTRQconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTSQconst)
 		v.AuxInt = c
@@ -5572,17 +5329,13 @@
 		return true
 	}
 	// match: (BTSQconst [c] (BTCQconst [c] x))
-	// cond:
 	// result: (BTSQconst [c] x)
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64BTCQconst {
+		if v_0.Op != OpAMD64BTCQconst || v_0.AuxInt != c {
 			break
 		}
-		if v_0.AuxInt != c {
-			break
-		}
 		x := v_0.Args[0]
 		v.reset(OpAMD64BTSQconst)
 		v.AuxInt = c
@@ -5590,7 +5343,6 @@
 		return true
 	}
 	// match: (BTSQconst [c] (ORQconst [d] x))
-	// cond:
 	// result: (ORQconst [d | 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -5606,7 +5358,6 @@
 		return true
 	}
 	// match: (BTSQconst [c] (BTSQconst [d] x))
-	// cond:
 	// result: (ORQconst [1<<uint32(d) | 1<<uint32(c)] x)
 	for {
 		c := v.AuxInt
@@ -5622,7 +5373,6 @@
 		return true
 	}
 	// match: (BTSQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [d|(1<<uint32(c))])
 	for {
 		c := v.AuxInt
@@ -5743,7 +5493,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLCC_0(v *Value) bool {
 	// match: (CMOVLCC x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLLS x y cond)
 	for {
 		_ = v.Args[2]
@@ -5761,7 +5510,6 @@
 		return true
 	}
 	// match: (CMOVLCC _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5776,7 +5524,6 @@
 		return true
 	}
 	// match: (CMOVLCC _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5791,7 +5538,6 @@
 		return true
 	}
 	// match: (CMOVLCC y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5806,7 +5552,6 @@
 		return true
 	}
 	// match: (CMOVLCC y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5821,7 +5566,6 @@
 		return true
 	}
 	// match: (CMOVLCC _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5839,7 +5583,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLCS_0(v *Value) bool {
 	// match: (CMOVLCS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLHI x y cond)
 	for {
 		_ = v.Args[2]
@@ -5857,7 +5600,6 @@
 		return true
 	}
 	// match: (CMOVLCS y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5872,7 +5614,6 @@
 		return true
 	}
 	// match: (CMOVLCS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5887,7 +5628,6 @@
 		return true
 	}
 	// match: (CMOVLCS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5902,7 +5642,6 @@
 		return true
 	}
 	// match: (CMOVLCS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5917,7 +5656,6 @@
 		return true
 	}
 	// match: (CMOVLCS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5935,7 +5673,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLEQ_0(v *Value) bool {
 	// match: (CMOVLEQ x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLEQ x y cond)
 	for {
 		_ = v.Args[2]
@@ -5953,7 +5690,6 @@
 		return true
 	}
 	// match: (CMOVLEQ _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -5968,7 +5704,6 @@
 		return true
 	}
 	// match: (CMOVLEQ y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5983,7 +5718,6 @@
 		return true
 	}
 	// match: (CMOVLEQ y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -5998,7 +5732,6 @@
 		return true
 	}
 	// match: (CMOVLEQ y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6013,7 +5746,6 @@
 		return true
 	}
 	// match: (CMOVLEQ y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6031,7 +5763,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLGE_0(v *Value) bool {
 	// match: (CMOVLGE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLLE x y cond)
 	for {
 		_ = v.Args[2]
@@ -6049,7 +5780,6 @@
 		return true
 	}
 	// match: (CMOVLGE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6064,7 +5794,6 @@
 		return true
 	}
 	// match: (CMOVLGE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6079,7 +5808,6 @@
 		return true
 	}
 	// match: (CMOVLGE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6094,7 +5822,6 @@
 		return true
 	}
 	// match: (CMOVLGE y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6109,7 +5836,6 @@
 		return true
 	}
 	// match: (CMOVLGE y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6127,7 +5853,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLGT_0(v *Value) bool {
 	// match: (CMOVLGT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLLT x y cond)
 	for {
 		_ = v.Args[2]
@@ -6145,7 +5870,6 @@
 		return true
 	}
 	// match: (CMOVLGT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6160,7 +5884,6 @@
 		return true
 	}
 	// match: (CMOVLGT _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6175,7 +5898,6 @@
 		return true
 	}
 	// match: (CMOVLGT _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6190,7 +5912,6 @@
 		return true
 	}
 	// match: (CMOVLGT y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6205,7 +5926,6 @@
 		return true
 	}
 	// match: (CMOVLGT y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6223,7 +5943,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLHI_0(v *Value) bool {
 	// match: (CMOVLHI x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLCS x y cond)
 	for {
 		_ = v.Args[2]
@@ -6241,7 +5960,6 @@
 		return true
 	}
 	// match: (CMOVLHI y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6256,7 +5974,6 @@
 		return true
 	}
 	// match: (CMOVLHI _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6271,7 +5988,6 @@
 		return true
 	}
 	// match: (CMOVLHI y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6286,7 +6002,6 @@
 		return true
 	}
 	// match: (CMOVLHI y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6301,7 +6016,6 @@
 		return true
 	}
 	// match: (CMOVLHI _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6319,7 +6033,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLLE_0(v *Value) bool {
 	// match: (CMOVLLE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLGE x y cond)
 	for {
 		_ = v.Args[2]
@@ -6337,7 +6050,6 @@
 		return true
 	}
 	// match: (CMOVLLE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6352,7 +6064,6 @@
 		return true
 	}
 	// match: (CMOVLLE y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6367,7 +6078,6 @@
 		return true
 	}
 	// match: (CMOVLLE y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6382,7 +6092,6 @@
 		return true
 	}
 	// match: (CMOVLLE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6397,7 +6106,6 @@
 		return true
 	}
 	// match: (CMOVLLE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6415,7 +6123,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLLS_0(v *Value) bool {
 	// match: (CMOVLLS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLCC x y cond)
 	for {
 		_ = v.Args[2]
@@ -6433,7 +6140,6 @@
 		return true
 	}
 	// match: (CMOVLLS _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6448,7 +6154,6 @@
 		return true
 	}
 	// match: (CMOVLLS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6463,7 +6168,6 @@
 		return true
 	}
 	// match: (CMOVLLS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6478,7 +6182,6 @@
 		return true
 	}
 	// match: (CMOVLLS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6493,7 +6196,6 @@
 		return true
 	}
 	// match: (CMOVLLS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6511,7 +6213,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLLT_0(v *Value) bool {
 	// match: (CMOVLLT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLGT x y cond)
 	for {
 		_ = v.Args[2]
@@ -6529,7 +6230,6 @@
 		return true
 	}
 	// match: (CMOVLLT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6544,7 +6244,6 @@
 		return true
 	}
 	// match: (CMOVLLT y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6559,7 +6258,6 @@
 		return true
 	}
 	// match: (CMOVLLT y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6574,7 +6272,6 @@
 		return true
 	}
 	// match: (CMOVLLT _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6589,7 +6286,6 @@
 		return true
 	}
 	// match: (CMOVLLT _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6607,7 +6303,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVLNE_0(v *Value) bool {
 	// match: (CMOVLNE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVLNE x y cond)
 	for {
 		_ = v.Args[2]
@@ -6625,7 +6320,6 @@
 		return true
 	}
 	// match: (CMOVLNE y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6640,7 +6334,6 @@
 		return true
 	}
 	// match: (CMOVLNE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6655,7 +6348,6 @@
 		return true
 	}
 	// match: (CMOVLNE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6670,7 +6362,6 @@
 		return true
 	}
 	// match: (CMOVLNE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6685,7 +6376,6 @@
 		return true
 	}
 	// match: (CMOVLNE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6703,7 +6393,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQCC_0(v *Value) bool {
 	// match: (CMOVQCC x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQLS x y cond)
 	for {
 		_ = v.Args[2]
@@ -6721,7 +6410,6 @@
 		return true
 	}
 	// match: (CMOVQCC _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6736,7 +6424,6 @@
 		return true
 	}
 	// match: (CMOVQCC _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6751,7 +6438,6 @@
 		return true
 	}
 	// match: (CMOVQCC y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6766,7 +6452,6 @@
 		return true
 	}
 	// match: (CMOVQCC y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6781,7 +6466,6 @@
 		return true
 	}
 	// match: (CMOVQCC _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6799,7 +6483,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQCS_0(v *Value) bool {
 	// match: (CMOVQCS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQHI x y cond)
 	for {
 		_ = v.Args[2]
@@ -6817,7 +6500,6 @@
 		return true
 	}
 	// match: (CMOVQCS y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6832,7 +6514,6 @@
 		return true
 	}
 	// match: (CMOVQCS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6847,7 +6528,6 @@
 		return true
 	}
 	// match: (CMOVQCS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6862,7 +6542,6 @@
 		return true
 	}
 	// match: (CMOVQCS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6877,7 +6556,6 @@
 		return true
 	}
 	// match: (CMOVQCS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6895,7 +6573,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQEQ_0(v *Value) bool {
 	// match: (CMOVQEQ x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQEQ x y cond)
 	for {
 		_ = v.Args[2]
@@ -6913,7 +6590,6 @@
 		return true
 	}
 	// match: (CMOVQEQ _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -6928,7 +6604,6 @@
 		return true
 	}
 	// match: (CMOVQEQ y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6943,7 +6618,6 @@
 		return true
 	}
 	// match: (CMOVQEQ y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6958,7 +6632,6 @@
 		return true
 	}
 	// match: (CMOVQEQ y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -6973,7 +6646,6 @@
 		return true
 	}
 	// match: (CMOVQEQ y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7018,7 +6690,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQGE_0(v *Value) bool {
 	// match: (CMOVQGE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQLE x y cond)
 	for {
 		_ = v.Args[2]
@@ -7036,7 +6707,6 @@
 		return true
 	}
 	// match: (CMOVQGE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7051,7 +6721,6 @@
 		return true
 	}
 	// match: (CMOVQGE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7066,7 +6735,6 @@
 		return true
 	}
 	// match: (CMOVQGE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7081,7 +6749,6 @@
 		return true
 	}
 	// match: (CMOVQGE y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7096,7 +6763,6 @@
 		return true
 	}
 	// match: (CMOVQGE y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7114,7 +6780,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQGT_0(v *Value) bool {
 	// match: (CMOVQGT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQLT x y cond)
 	for {
 		_ = v.Args[2]
@@ -7132,7 +6797,6 @@
 		return true
 	}
 	// match: (CMOVQGT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7147,7 +6811,6 @@
 		return true
 	}
 	// match: (CMOVQGT _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7162,7 +6825,6 @@
 		return true
 	}
 	// match: (CMOVQGT _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7177,7 +6839,6 @@
 		return true
 	}
 	// match: (CMOVQGT y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7192,7 +6853,6 @@
 		return true
 	}
 	// match: (CMOVQGT y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7210,7 +6870,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQHI_0(v *Value) bool {
 	// match: (CMOVQHI x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQCS x y cond)
 	for {
 		_ = v.Args[2]
@@ -7228,7 +6887,6 @@
 		return true
 	}
 	// match: (CMOVQHI y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7243,7 +6901,6 @@
 		return true
 	}
 	// match: (CMOVQHI _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7258,7 +6915,6 @@
 		return true
 	}
 	// match: (CMOVQHI y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7273,7 +6929,6 @@
 		return true
 	}
 	// match: (CMOVQHI y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7288,7 +6943,6 @@
 		return true
 	}
 	// match: (CMOVQHI _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7306,7 +6960,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQLE_0(v *Value) bool {
 	// match: (CMOVQLE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQGE x y cond)
 	for {
 		_ = v.Args[2]
@@ -7324,7 +6977,6 @@
 		return true
 	}
 	// match: (CMOVQLE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7339,7 +6991,6 @@
 		return true
 	}
 	// match: (CMOVQLE y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7354,7 +7005,6 @@
 		return true
 	}
 	// match: (CMOVQLE y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7369,7 +7019,6 @@
 		return true
 	}
 	// match: (CMOVQLE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7384,7 +7033,6 @@
 		return true
 	}
 	// match: (CMOVQLE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7402,7 +7050,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQLS_0(v *Value) bool {
 	// match: (CMOVQLS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQCC x y cond)
 	for {
 		_ = v.Args[2]
@@ -7420,7 +7067,6 @@
 		return true
 	}
 	// match: (CMOVQLS _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7435,7 +7081,6 @@
 		return true
 	}
 	// match: (CMOVQLS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7450,7 +7095,6 @@
 		return true
 	}
 	// match: (CMOVQLS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7465,7 +7109,6 @@
 		return true
 	}
 	// match: (CMOVQLS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7480,7 +7123,6 @@
 		return true
 	}
 	// match: (CMOVQLS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7498,7 +7140,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQLT_0(v *Value) bool {
 	// match: (CMOVQLT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQGT x y cond)
 	for {
 		_ = v.Args[2]
@@ -7516,7 +7157,6 @@
 		return true
 	}
 	// match: (CMOVQLT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7531,7 +7171,6 @@
 		return true
 	}
 	// match: (CMOVQLT y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7546,7 +7185,6 @@
 		return true
 	}
 	// match: (CMOVQLT y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7561,7 +7199,6 @@
 		return true
 	}
 	// match: (CMOVQLT _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7576,7 +7213,6 @@
 		return true
 	}
 	// match: (CMOVQLT _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7594,7 +7230,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVQNE_0(v *Value) bool {
 	// match: (CMOVQNE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVQNE x y cond)
 	for {
 		_ = v.Args[2]
@@ -7612,7 +7247,6 @@
 		return true
 	}
 	// match: (CMOVQNE y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7627,7 +7261,6 @@
 		return true
 	}
 	// match: (CMOVQNE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7642,7 +7275,6 @@
 		return true
 	}
 	// match: (CMOVQNE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7657,7 +7289,6 @@
 		return true
 	}
 	// match: (CMOVQNE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7672,7 +7303,6 @@
 		return true
 	}
 	// match: (CMOVQNE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7690,7 +7320,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWCC_0(v *Value) bool {
 	// match: (CMOVWCC x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWLS x y cond)
 	for {
 		_ = v.Args[2]
@@ -7708,7 +7337,6 @@
 		return true
 	}
 	// match: (CMOVWCC _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7723,7 +7351,6 @@
 		return true
 	}
 	// match: (CMOVWCC _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7738,7 +7365,6 @@
 		return true
 	}
 	// match: (CMOVWCC y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7753,7 +7379,6 @@
 		return true
 	}
 	// match: (CMOVWCC y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7768,7 +7393,6 @@
 		return true
 	}
 	// match: (CMOVWCC _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7786,7 +7410,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWCS_0(v *Value) bool {
 	// match: (CMOVWCS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWHI x y cond)
 	for {
 		_ = v.Args[2]
@@ -7804,7 +7427,6 @@
 		return true
 	}
 	// match: (CMOVWCS y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7819,7 +7441,6 @@
 		return true
 	}
 	// match: (CMOVWCS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7834,7 +7455,6 @@
 		return true
 	}
 	// match: (CMOVWCS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7849,7 +7469,6 @@
 		return true
 	}
 	// match: (CMOVWCS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7864,7 +7483,6 @@
 		return true
 	}
 	// match: (CMOVWCS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7882,7 +7500,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWEQ_0(v *Value) bool {
 	// match: (CMOVWEQ x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWEQ x y cond)
 	for {
 		_ = v.Args[2]
@@ -7900,7 +7517,6 @@
 		return true
 	}
 	// match: (CMOVWEQ _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -7915,7 +7531,6 @@
 		return true
 	}
 	// match: (CMOVWEQ y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7930,7 +7545,6 @@
 		return true
 	}
 	// match: (CMOVWEQ y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7945,7 +7559,6 @@
 		return true
 	}
 	// match: (CMOVWEQ y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7960,7 +7573,6 @@
 		return true
 	}
 	// match: (CMOVWEQ y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -7978,7 +7590,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWGE_0(v *Value) bool {
 	// match: (CMOVWGE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWLE x y cond)
 	for {
 		_ = v.Args[2]
@@ -7996,7 +7607,6 @@
 		return true
 	}
 	// match: (CMOVWGE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8011,7 +7621,6 @@
 		return true
 	}
 	// match: (CMOVWGE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8026,7 +7635,6 @@
 		return true
 	}
 	// match: (CMOVWGE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8041,7 +7649,6 @@
 		return true
 	}
 	// match: (CMOVWGE y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8056,7 +7663,6 @@
 		return true
 	}
 	// match: (CMOVWGE y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8074,7 +7680,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWGT_0(v *Value) bool {
 	// match: (CMOVWGT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWLT x y cond)
 	for {
 		_ = v.Args[2]
@@ -8092,7 +7697,6 @@
 		return true
 	}
 	// match: (CMOVWGT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8107,7 +7711,6 @@
 		return true
 	}
 	// match: (CMOVWGT _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8122,7 +7725,6 @@
 		return true
 	}
 	// match: (CMOVWGT _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8137,7 +7739,6 @@
 		return true
 	}
 	// match: (CMOVWGT y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8152,7 +7753,6 @@
 		return true
 	}
 	// match: (CMOVWGT y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8170,7 +7770,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWHI_0(v *Value) bool {
 	// match: (CMOVWHI x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWCS x y cond)
 	for {
 		_ = v.Args[2]
@@ -8188,7 +7787,6 @@
 		return true
 	}
 	// match: (CMOVWHI y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8203,7 +7801,6 @@
 		return true
 	}
 	// match: (CMOVWHI _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8218,7 +7815,6 @@
 		return true
 	}
 	// match: (CMOVWHI y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8233,7 +7829,6 @@
 		return true
 	}
 	// match: (CMOVWHI y _ (FlagLT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8248,7 +7843,6 @@
 		return true
 	}
 	// match: (CMOVWHI _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8266,7 +7860,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWLE_0(v *Value) bool {
 	// match: (CMOVWLE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWGE x y cond)
 	for {
 		_ = v.Args[2]
@@ -8284,7 +7877,6 @@
 		return true
 	}
 	// match: (CMOVWLE _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8299,7 +7891,6 @@
 		return true
 	}
 	// match: (CMOVWLE y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8314,7 +7905,6 @@
 		return true
 	}
 	// match: (CMOVWLE y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8329,7 +7919,6 @@
 		return true
 	}
 	// match: (CMOVWLE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8344,7 +7933,6 @@
 		return true
 	}
 	// match: (CMOVWLE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8362,7 +7950,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWLS_0(v *Value) bool {
 	// match: (CMOVWLS x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWCC x y cond)
 	for {
 		_ = v.Args[2]
@@ -8380,7 +7967,6 @@
 		return true
 	}
 	// match: (CMOVWLS _ x (FlagEQ))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8395,7 +7981,6 @@
 		return true
 	}
 	// match: (CMOVWLS y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8410,7 +7995,6 @@
 		return true
 	}
 	// match: (CMOVWLS _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8425,7 +8009,6 @@
 		return true
 	}
 	// match: (CMOVWLS _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8440,7 +8023,6 @@
 		return true
 	}
 	// match: (CMOVWLS y _ (FlagLT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8458,7 +8040,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWLT_0(v *Value) bool {
 	// match: (CMOVWLT x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWGT x y cond)
 	for {
 		_ = v.Args[2]
@@ -8476,7 +8057,6 @@
 		return true
 	}
 	// match: (CMOVWLT y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8491,7 +8071,6 @@
 		return true
 	}
 	// match: (CMOVWLT y _ (FlagGT_UGT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8506,7 +8085,6 @@
 		return true
 	}
 	// match: (CMOVWLT y _ (FlagGT_ULT))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8521,7 +8099,6 @@
 		return true
 	}
 	// match: (CMOVWLT _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8536,7 +8113,6 @@
 		return true
 	}
 	// match: (CMOVWLT _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8554,7 +8130,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMOVWNE_0(v *Value) bool {
 	// match: (CMOVWNE x y (InvertFlags cond))
-	// cond:
 	// result: (CMOVWNE x y cond)
 	for {
 		_ = v.Args[2]
@@ -8572,7 +8147,6 @@
 		return true
 	}
 	// match: (CMOVWNE y _ (FlagEQ))
-	// cond:
 	// result: y
 	for {
 		_ = v.Args[2]
@@ -8587,7 +8161,6 @@
 		return true
 	}
 	// match: (CMOVWNE _ x (FlagGT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8602,7 +8175,6 @@
 		return true
 	}
 	// match: (CMOVWNE _ x (FlagGT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8617,7 +8189,6 @@
 		return true
 	}
 	// match: (CMOVWNE _ x (FlagLT_ULT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8632,7 +8203,6 @@
 		return true
 	}
 	// match: (CMOVWNE _ x (FlagLT_UGT))
-	// cond:
 	// result: x
 	for {
 		_ = v.Args[2]
@@ -8651,7 +8221,6 @@
 func rewriteValueAMD64_OpAMD64CMPB_0(v *Value) bool {
 	b := v.Block
 	// match: (CMPB x (MOVLconst [c]))
-	// cond:
 	// result: (CMPBconst x [int64(int8(c))])
 	for {
 		_ = v.Args[1]
@@ -8667,7 +8236,6 @@
 		return true
 	}
 	// match: (CMPB (MOVLconst [c]) x)
-	// cond:
 	// result: (InvertFlags (CMPBconst x [int64(int8(c))]))
 	for {
 		x := v.Args[1]
@@ -8835,7 +8403,6 @@
 		return true
 	}
 	// match: (CMPBconst (ANDL x y) [0])
-	// cond:
 	// result: (TESTB x y)
 	for {
 		if v.AuxInt != 0 {
@@ -8853,7 +8420,6 @@
 		return true
 	}
 	// match: (CMPBconst (ANDLconst [c] x) [0])
-	// cond:
 	// result: (TESTBconst [int64(int8(c))] x)
 	for {
 		if v.AuxInt != 0 {
@@ -8871,7 +8437,6 @@
 		return true
 	}
 	// match: (CMPBconst x [0])
-	// cond:
 	// result: (TESTB x x)
 	for {
 		if v.AuxInt != 0 {
@@ -9041,7 +8606,6 @@
 func rewriteValueAMD64_OpAMD64CMPL_0(v *Value) bool {
 	b := v.Block
 	// match: (CMPL x (MOVLconst [c]))
-	// cond:
 	// result: (CMPLconst x [c])
 	for {
 		_ = v.Args[1]
@@ -9057,7 +8621,6 @@
 		return true
 	}
 	// match: (CMPL (MOVLconst [c]) x)
-	// cond:
 	// result: (InvertFlags (CMPLconst x [c]))
 	for {
 		x := v.Args[1]
@@ -9240,7 +8803,6 @@
 		return true
 	}
 	// match: (CMPLconst (ANDL x y) [0])
-	// cond:
 	// result: (TESTL x y)
 	for {
 		if v.AuxInt != 0 {
@@ -9258,7 +8820,6 @@
 		return true
 	}
 	// match: (CMPLconst (ANDLconst [c] x) [0])
-	// cond:
 	// result: (TESTLconst [c] x)
 	for {
 		if v.AuxInt != 0 {
@@ -9276,7 +8837,6 @@
 		return true
 	}
 	// match: (CMPLconst x [0])
-	// cond:
 	// result: (TESTL x x)
 	for {
 		if v.AuxInt != 0 {
@@ -9543,7 +9103,6 @@
 }
 func rewriteValueAMD64_OpAMD64CMPQconst_0(v *Value) bool {
 	// match: (CMPQconst (NEGQ (ADDQconst [-16] (ANDQconst [15] _))) [32])
-	// cond:
 	// result: (FlagLT_ULT)
 	for {
 		if v.AuxInt != 32 {
@@ -9554,24 +9113,17 @@
 			break
 		}
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0.Op != OpAMD64ADDQconst || v_0_0.AuxInt != -16 {
 			break
 		}
-		if v_0_0.AuxInt != -16 {
-			break
-		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_0_0.AuxInt != 15 {
-			break
-		}
 		v.reset(OpAMD64FlagLT_ULT)
 		return true
 	}
 	// match: (CMPQconst (NEGQ (ADDQconst [ -8] (ANDQconst [7] _))) [32])
-	// cond:
 	// result: (FlagLT_ULT)
 	for {
 		if v.AuxInt != 32 {
@@ -9582,19 +9134,13 @@
 			break
 		}
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0.Op != OpAMD64ADDQconst || v_0_0.AuxInt != -8 {
 			break
 		}
-		if v_0_0.AuxInt != -8 {
-			break
-		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_0_0.AuxInt != 7 {
-			break
-		}
 		v.reset(OpAMD64FlagLT_ULT)
 		return true
 	}
@@ -9684,12 +9230,9 @@
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64MOVBQZX {
+		if v_0.Op != OpAMD64MOVBQZX || !(0xFF < c) {
 			break
 		}
-		if !(0xFF < c) {
-			break
-		}
 		v.reset(OpAMD64FlagLT_ULT)
 		return true
 	}
@@ -9699,12 +9242,9 @@
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64MOVWQZX {
+		if v_0.Op != OpAMD64MOVWQZX || !(0xFFFF < c) {
 			break
 		}
-		if !(0xFFFF < c) {
-			break
-		}
 		v.reset(OpAMD64FlagLT_ULT)
 		return true
 	}
@@ -9714,12 +9254,9 @@
 	for {
 		c := v.AuxInt
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64MOVLQZX {
+		if v_0.Op != OpAMD64MOVLQZX || !(0xFFFFFFFF < c) {
 			break
 		}
-		if !(0xFFFFFFFF < c) {
-			break
-		}
 		v.reset(OpAMD64FlagLT_ULT)
 		return true
 	}
@@ -9776,7 +9313,6 @@
 		return true
 	}
 	// match: (CMPQconst (ANDQ x y) [0])
-	// cond:
 	// result: (TESTQ x y)
 	for {
 		if v.AuxInt != 0 {
@@ -9794,7 +9330,6 @@
 		return true
 	}
 	// match: (CMPQconst (ANDQconst [c] x) [0])
-	// cond:
 	// result: (TESTQconst [c] x)
 	for {
 		if v.AuxInt != 0 {
@@ -9812,7 +9347,6 @@
 		return true
 	}
 	// match: (CMPQconst x [0])
-	// cond:
 	// result: (TESTQ x x)
 	for {
 		if v.AuxInt != 0 {
@@ -9982,7 +9516,6 @@
 func rewriteValueAMD64_OpAMD64CMPW_0(v *Value) bool {
 	b := v.Block
 	// match: (CMPW x (MOVLconst [c]))
-	// cond:
 	// result: (CMPWconst x [int64(int16(c))])
 	for {
 		_ = v.Args[1]
@@ -9998,7 +9531,6 @@
 		return true
 	}
 	// match: (CMPW (MOVLconst [c]) x)
-	// cond:
 	// result: (InvertFlags (CMPWconst x [int64(int16(c))]))
 	for {
 		x := v.Args[1]
@@ -10166,7 +9698,6 @@
 		return true
 	}
 	// match: (CMPWconst (ANDL x y) [0])
-	// cond:
 	// result: (TESTW x y)
 	for {
 		if v.AuxInt != 0 {
@@ -10184,7 +9715,6 @@
 		return true
 	}
 	// match: (CMPWconst (ANDLconst [c] x) [0])
-	// cond:
 	// result: (TESTWconst [int64(int16(c))] x)
 	for {
 		if v.AuxInt != 0 {
@@ -10202,7 +9732,6 @@
 		return true
 	}
 	// match: (CMPWconst x [0])
-	// cond:
 	// result: (TESTW x x)
 	for {
 		if v.AuxInt != 0 {
@@ -10756,7 +10285,6 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} x (SHLLconst [1] y))
-	// cond:
 	// result: (LEAL2 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -10764,12 +10292,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL2)
 		v.AuxInt = c
@@ -10779,19 +10304,15 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} (SHLLconst [1] y) x)
-	// cond:
 	// result: (LEAL2 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL2)
 		v.AuxInt = c
@@ -10801,7 +10322,6 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} x (SHLLconst [2] y))
-	// cond:
 	// result: (LEAL4 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -10809,12 +10329,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL4)
 		v.AuxInt = c
@@ -10824,19 +10341,15 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} (SHLLconst [2] y) x)
-	// cond:
 	// result: (LEAL4 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 2 {
 			break
 		}
-		if v_0.AuxInt != 2 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL4)
 		v.AuxInt = c
@@ -10846,7 +10359,6 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} x (SHLLconst [3] y))
-	// cond:
 	// result: (LEAL8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -10854,12 +10366,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AuxInt = c
@@ -10869,19 +10378,15 @@
 		return true
 	}
 	// match: (LEAL1 [c] {s} (SHLLconst [3] y) x)
-	// cond:
 	// result: (LEAL8 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AuxInt = c
@@ -10941,7 +10446,6 @@
 		return true
 	}
 	// match: (LEAL2 [c] {s} x (SHLLconst [1] y))
-	// cond:
 	// result: (LEAL4 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -10949,12 +10453,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL4)
 		v.AuxInt = c
@@ -10964,7 +10465,6 @@
 		return true
 	}
 	// match: (LEAL2 [c] {s} x (SHLLconst [2] y))
-	// cond:
 	// result: (LEAL8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -10972,12 +10472,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AuxInt = c
@@ -11037,7 +10534,6 @@
 		return true
 	}
 	// match: (LEAL4 [c] {s} x (SHLLconst [1] y))
-	// cond:
 	// result: (LEAL8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11045,12 +10541,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLLconst {
+		if v_1.Op != OpAMD64SHLLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAL8)
 		v.AuxInt = c
@@ -11324,7 +10817,6 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} x (SHLQconst [1] y))
-	// cond:
 	// result: (LEAQ2 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11332,12 +10824,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ2)
 		v.AuxInt = c
@@ -11347,19 +10836,15 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} (SHLQconst [1] y) x)
-	// cond:
 	// result: (LEAQ2 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ2)
 		v.AuxInt = c
@@ -11369,7 +10854,6 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} x (SHLQconst [2] y))
-	// cond:
 	// result: (LEAQ4 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11377,12 +10861,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ4)
 		v.AuxInt = c
@@ -11392,19 +10873,15 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} (SHLQconst [2] y) x)
-	// cond:
 	// result: (LEAQ4 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 2 {
 			break
 		}
-		if v_0.AuxInt != 2 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ4)
 		v.AuxInt = c
@@ -11414,7 +10891,6 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} x (SHLQconst [3] y))
-	// cond:
 	// result: (LEAQ8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11422,12 +10898,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AuxInt = c
@@ -11437,19 +10910,15 @@
 		return true
 	}
 	// match: (LEAQ1 [c] {s} (SHLQconst [3] y) x)
-	// cond:
 	// result: (LEAQ8 [c] {s} x y)
 	for {
 		c := v.AuxInt
 		s := v.Aux
 		x := v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		y := v_0.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AuxInt = c
@@ -11558,7 +11027,6 @@
 		return true
 	}
 	// match: (LEAQ2 [c] {s} x (SHLQconst [1] y))
-	// cond:
 	// result: (LEAQ4 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11566,12 +11034,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ4)
 		v.AuxInt = c
@@ -11581,7 +11046,6 @@
 		return true
 	}
 	// match: (LEAQ2 [c] {s} x (SHLQconst [2] y))
-	// cond:
 	// result: (LEAQ8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11589,12 +11053,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AuxInt = c
@@ -11678,7 +11139,6 @@
 		return true
 	}
 	// match: (LEAQ4 [c] {s} x (SHLQconst [1] y))
-	// cond:
 	// result: (LEAQ8 [c] {s} x y)
 	for {
 		c := v.AuxInt
@@ -11686,12 +11146,9 @@
 		_ = v.Args[1]
 		x := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		y := v_1.Args[0]
 		v.reset(OpAMD64LEAQ8)
 		v.AuxInt = c
@@ -11921,7 +11378,6 @@
 		return true
 	}
 	// match: (MOVBQSX (MOVBQSX x))
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -12129,7 +11585,6 @@
 		return true
 	}
 	// match: (MOVBQZX (ANDLconst [c] x))
-	// cond:
 	// result: (ANDLconst [c & 0xff] x)
 	for {
 		v_0 := v.Args[0]
@@ -12144,7 +11599,6 @@
 		return true
 	}
 	// match: (MOVBQZX (MOVBQZX x))
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -12385,12 +11839,9 @@
 		sym := v.Aux
 		_ = v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpSB {
+		if v_0.Op != OpSB || !(symIsRO(sym)) {
 			break
 		}
-		if !(symIsRO(sym)) {
-			break
-		}
 		v.reset(OpAMD64MOVLconst)
 		v.AuxInt = int64(read8(sym, off))
 		return true
@@ -12792,7 +12243,6 @@
 func rewriteValueAMD64_OpAMD64MOVBstore_10(v *Value) bool {
 	b := v.Block
 	// match: (MOVBstore [off] {sym} ptr (MOVBQSX x) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -12813,7 +12263,6 @@
 		return true
 	}
 	// match: (MOVBstore [off] {sym} ptr (MOVBQZX x) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -12994,32 +12443,17 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x0 := v.Args[2]
-		if x0.Op != OpAMD64MOVBstore {
+		if x0.Op != OpAMD64MOVBstore || x0.AuxInt != i-1 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-1 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[2]
 		if p != x0.Args[0] {
 			break
 		}
 		x0_1 := x0.Args[1]
-		if x0_1.Op != OpAMD64SHRWconst {
+		if x0_1.Op != OpAMD64SHRWconst || x0_1.AuxInt != 8 || w != x0_1.Args[0] || !(x0.Uses == 1 && clobber(x0)) {
 			break
 		}
-		if x0_1.AuxInt != 8 {
-			break
-		}
-		if w != x0_1.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && clobber(x0)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13041,80 +12475,41 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x2 := v.Args[2]
-		if x2.Op != OpAMD64MOVBstore {
+		if x2.Op != OpAMD64MOVBstore || x2.AuxInt != i-1 || x2.Aux != s {
 			break
 		}
-		if x2.AuxInt != i-1 {
-			break
-		}
-		if x2.Aux != s {
-			break
-		}
 		_ = x2.Args[2]
 		if p != x2.Args[0] {
 			break
 		}
 		x2_1 := x2.Args[1]
-		if x2_1.Op != OpAMD64SHRLconst {
+		if x2_1.Op != OpAMD64SHRLconst || x2_1.AuxInt != 8 || w != x2_1.Args[0] {
 			break
 		}
-		if x2_1.AuxInt != 8 {
-			break
-		}
-		if w != x2_1.Args[0] {
-			break
-		}
 		x1 := x2.Args[2]
-		if x1.Op != OpAMD64MOVBstore {
+		if x1.Op != OpAMD64MOVBstore || x1.AuxInt != i-2 || x1.Aux != s {
 			break
 		}
-		if x1.AuxInt != i-2 {
-			break
-		}
-		if x1.Aux != s {
-			break
-		}
 		_ = x1.Args[2]
 		if p != x1.Args[0] {
 			break
 		}
 		x1_1 := x1.Args[1]
-		if x1_1.Op != OpAMD64SHRLconst {
+		if x1_1.Op != OpAMD64SHRLconst || x1_1.AuxInt != 16 || w != x1_1.Args[0] {
 			break
 		}
-		if x1_1.AuxInt != 16 {
-			break
-		}
-		if w != x1_1.Args[0] {
-			break
-		}
 		x0 := x1.Args[2]
-		if x0.Op != OpAMD64MOVBstore {
+		if x0.Op != OpAMD64MOVBstore || x0.AuxInt != i-3 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-3 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[2]
 		if p != x0.Args[0] {
 			break
 		}
 		x0_1 := x0.Args[1]
-		if x0_1.Op != OpAMD64SHRLconst {
+		if x0_1.Op != OpAMD64SHRLconst || x0_1.AuxInt != 24 || w != x0_1.Args[0] || !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2)) {
 			break
 		}
-		if x0_1.AuxInt != 24 {
-			break
-		}
-		if w != x0_1.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 3
 		v.Aux = s
@@ -13140,176 +12535,89 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x6 := v.Args[2]
-		if x6.Op != OpAMD64MOVBstore {
+		if x6.Op != OpAMD64MOVBstore || x6.AuxInt != i-1 || x6.Aux != s {
 			break
 		}
-		if x6.AuxInt != i-1 {
-			break
-		}
-		if x6.Aux != s {
-			break
-		}
 		_ = x6.Args[2]
 		if p != x6.Args[0] {
 			break
 		}
 		x6_1 := x6.Args[1]
-		if x6_1.Op != OpAMD64SHRQconst {
+		if x6_1.Op != OpAMD64SHRQconst || x6_1.AuxInt != 8 || w != x6_1.Args[0] {
 			break
 		}
-		if x6_1.AuxInt != 8 {
-			break
-		}
-		if w != x6_1.Args[0] {
-			break
-		}
 		x5 := x6.Args[2]
-		if x5.Op != OpAMD64MOVBstore {
+		if x5.Op != OpAMD64MOVBstore || x5.AuxInt != i-2 || x5.Aux != s {
 			break
 		}
-		if x5.AuxInt != i-2 {
-			break
-		}
-		if x5.Aux != s {
-			break
-		}
 		_ = x5.Args[2]
 		if p != x5.Args[0] {
 			break
 		}
 		x5_1 := x5.Args[1]
-		if x5_1.Op != OpAMD64SHRQconst {
+		if x5_1.Op != OpAMD64SHRQconst || x5_1.AuxInt != 16 || w != x5_1.Args[0] {
 			break
 		}
-		if x5_1.AuxInt != 16 {
-			break
-		}
-		if w != x5_1.Args[0] {
-			break
-		}
 		x4 := x5.Args[2]
-		if x4.Op != OpAMD64MOVBstore {
+		if x4.Op != OpAMD64MOVBstore || x4.AuxInt != i-3 || x4.Aux != s {
 			break
 		}
-		if x4.AuxInt != i-3 {
-			break
-		}
-		if x4.Aux != s {
-			break
-		}
 		_ = x4.Args[2]
 		if p != x4.Args[0] {
 			break
 		}
 		x4_1 := x4.Args[1]
-		if x4_1.Op != OpAMD64SHRQconst {
+		if x4_1.Op != OpAMD64SHRQconst || x4_1.AuxInt != 24 || w != x4_1.Args[0] {
 			break
 		}
-		if x4_1.AuxInt != 24 {
-			break
-		}
-		if w != x4_1.Args[0] {
-			break
-		}
 		x3 := x4.Args[2]
-		if x3.Op != OpAMD64MOVBstore {
+		if x3.Op != OpAMD64MOVBstore || x3.AuxInt != i-4 || x3.Aux != s {
 			break
 		}
-		if x3.AuxInt != i-4 {
-			break
-		}
-		if x3.Aux != s {
-			break
-		}
 		_ = x3.Args[2]
 		if p != x3.Args[0] {
 			break
 		}
 		x3_1 := x3.Args[1]
-		if x3_1.Op != OpAMD64SHRQconst {
+		if x3_1.Op != OpAMD64SHRQconst || x3_1.AuxInt != 32 || w != x3_1.Args[0] {
 			break
 		}
-		if x3_1.AuxInt != 32 {
-			break
-		}
-		if w != x3_1.Args[0] {
-			break
-		}
 		x2 := x3.Args[2]
-		if x2.Op != OpAMD64MOVBstore {
+		if x2.Op != OpAMD64MOVBstore || x2.AuxInt != i-5 || x2.Aux != s {
 			break
 		}
-		if x2.AuxInt != i-5 {
-			break
-		}
-		if x2.Aux != s {
-			break
-		}
 		_ = x2.Args[2]
 		if p != x2.Args[0] {
 			break
 		}
 		x2_1 := x2.Args[1]
-		if x2_1.Op != OpAMD64SHRQconst {
+		if x2_1.Op != OpAMD64SHRQconst || x2_1.AuxInt != 40 || w != x2_1.Args[0] {
 			break
 		}
-		if x2_1.AuxInt != 40 {
-			break
-		}
-		if w != x2_1.Args[0] {
-			break
-		}
 		x1 := x2.Args[2]
-		if x1.Op != OpAMD64MOVBstore {
+		if x1.Op != OpAMD64MOVBstore || x1.AuxInt != i-6 || x1.Aux != s {
 			break
 		}
-		if x1.AuxInt != i-6 {
-			break
-		}
-		if x1.Aux != s {
-			break
-		}
 		_ = x1.Args[2]
 		if p != x1.Args[0] {
 			break
 		}
 		x1_1 := x1.Args[1]
-		if x1_1.Op != OpAMD64SHRQconst {
+		if x1_1.Op != OpAMD64SHRQconst || x1_1.AuxInt != 48 || w != x1_1.Args[0] {
 			break
 		}
-		if x1_1.AuxInt != 48 {
-			break
-		}
-		if w != x1_1.Args[0] {
-			break
-		}
 		x0 := x1.Args[2]
-		if x0.Op != OpAMD64MOVBstore {
+		if x0.Op != OpAMD64MOVBstore || x0.AuxInt != i-7 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-7 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[2]
 		if p != x0.Args[0] {
 			break
 		}
 		x0_1 := x0.Args[1]
-		if x0_1.Op != OpAMD64SHRQconst {
+		if x0_1.Op != OpAMD64SHRQconst || x0_1.AuxInt != 56 || w != x0_1.Args[0] || !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && x3.Uses == 1 && x4.Uses == 1 && x5.Uses == 1 && x6.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2) && clobber(x3) && clobber(x4) && clobber(x5) && clobber(x6)) {
 			break
 		}
-		if x0_1.AuxInt != 56 {
-			break
-		}
-		if w != x0_1.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && x3.Uses == 1 && x4.Uses == 1 && x5.Uses == 1 && x6.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2) && clobber(x3) && clobber(x4) && clobber(x5) && clobber(x6)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = i - 7
 		v.Aux = s
@@ -13329,33 +12637,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRWconst {
+		if v_1.Op != OpAMD64SHRWconst || v_1.AuxInt != 8 {
 			break
 		}
-		if v_1.AuxInt != 8 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13373,33 +12666,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRLconst {
+		if v_1.Op != OpAMD64SHRLconst || v_1.AuxInt != 8 {
 			break
 		}
-		if v_1.AuxInt != 8 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13417,33 +12695,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRQconst {
+		if v_1.Op != OpAMD64SHRQconst || v_1.AuxInt != 8 {
 			break
 		}
-		if v_1.AuxInt != 8 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13462,32 +12725,17 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i+1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i+1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		x_1 := x.Args[1]
-		if x_1.Op != OpAMD64SHRWconst {
+		if x_1.Op != OpAMD64SHRWconst || x_1.AuxInt != 8 || w != x_1.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if x_1.AuxInt != 8 {
-			break
-		}
-		if w != x_1.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i
 		v.Aux = s
@@ -13506,32 +12754,17 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i+1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i+1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		x_1 := x.Args[1]
-		if x_1.Op != OpAMD64SHRLconst {
+		if x_1.Op != OpAMD64SHRLconst || x_1.AuxInt != 8 || w != x_1.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if x_1.AuxInt != 8 {
-			break
-		}
-		if w != x_1.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i
 		v.Aux = s
@@ -13550,32 +12783,17 @@
 		p := v.Args[0]
 		w := v.Args[1]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i+1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i+1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		x_1 := x.Args[1]
-		if x_1.Op != OpAMD64SHRQconst {
+		if x_1.Op != OpAMD64SHRQconst || x_1.AuxInt != 8 || w != x_1.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if x_1.AuxInt != 8 {
-			break
-		}
-		if w != x_1.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i
 		v.Aux = s
@@ -13599,32 +12817,17 @@
 		j := v_1.AuxInt
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		w0 := x.Args[1]
-		if w0.Op != OpAMD64SHRLconst {
+		if w0.Op != OpAMD64SHRLconst || w0.AuxInt != j-8 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-8 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13648,32 +12851,17 @@
 		j := v_1.AuxInt
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVBstore {
+		if x.Op != OpAMD64MOVBstore || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		w0 := x.Args[1]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-8 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-8 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13699,42 +12887,21 @@
 		mem := x1.Args[1]
 		p2 := x1.Args[0]
 		mem2 := v.Args[2]
-		if mem2.Op != OpAMD64MOVBstore {
+		if mem2.Op != OpAMD64MOVBstore || mem2.AuxInt != i-1 || mem2.Aux != s {
 			break
 		}
-		if mem2.AuxInt != i-1 {
-			break
-		}
-		if mem2.Aux != s {
-			break
-		}
 		_ = mem2.Args[2]
 		if p != mem2.Args[0] {
 			break
 		}
 		x2 := mem2.Args[1]
-		if x2.Op != OpAMD64MOVBload {
+		if x2.Op != OpAMD64MOVBload || x2.AuxInt != j-1 || x2.Aux != s2 {
 			break
 		}
-		if x2.AuxInt != j-1 {
-			break
-		}
-		if x2.Aux != s2 {
-			break
-		}
 		_ = x2.Args[1]
-		if p2 != x2.Args[0] {
+		if p2 != x2.Args[0] || mem != x2.Args[1] || mem != mem2.Args[2] || !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
 			break
 		}
-		if mem != x2.Args[1] {
-			break
-		}
-		if mem != mem2.Args[2] {
-			break
-		}
-		if !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstore)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -13879,7 +13046,6 @@
 		return true
 	}
 	// match: (MOVBstoreconst [x] {sym} (ADDQ ptr idx) mem)
-	// cond:
 	// result: (MOVBstoreconstidx1 [x] {sym} ptr idx mem)
 	for {
 		x := v.AuxInt
@@ -13916,12 +13082,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreconst)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xff|ValAndOff(c).Val()<<8, ValAndOff(a).Off())
 		v.Aux = s
@@ -13946,12 +13109,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreconst)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xff|ValAndOff(c).Val()<<8, ValAndOff(a).Off())
 		v.Aux = s
@@ -14077,15 +13237,9 @@
 			break
 		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || i != x.Args[1] || !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if i != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+1 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreconstidx1)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xff|ValAndOff(c).Val()<<8, ValAndOff(a).Off())
 		v.Aux = s
@@ -14163,35 +13317,17 @@
 		idx := v.Args[1]
 		w := v.Args[2]
 		x0 := v.Args[3]
-		if x0.Op != OpAMD64MOVBstoreidx1 {
+		if x0.Op != OpAMD64MOVBstoreidx1 || x0.AuxInt != i-1 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-1 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[3]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
 		x0_2 := x0.Args[2]
-		if x0_2.Op != OpAMD64SHRWconst {
+		if x0_2.Op != OpAMD64SHRWconst || x0_2.AuxInt != 8 || w != x0_2.Args[0] || !(x0.Uses == 1 && clobber(x0)) {
 			break
 		}
-		if x0_2.AuxInt != 8 {
-			break
-		}
-		if w != x0_2.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && clobber(x0)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14215,89 +13351,41 @@
 		idx := v.Args[1]
 		w := v.Args[2]
 		x2 := v.Args[3]
-		if x2.Op != OpAMD64MOVBstoreidx1 {
+		if x2.Op != OpAMD64MOVBstoreidx1 || x2.AuxInt != i-1 || x2.Aux != s {
 			break
 		}
-		if x2.AuxInt != i-1 {
-			break
-		}
-		if x2.Aux != s {
-			break
-		}
 		_ = x2.Args[3]
-		if p != x2.Args[0] {
+		if p != x2.Args[0] || idx != x2.Args[1] {
 			break
 		}
-		if idx != x2.Args[1] {
-			break
-		}
 		x2_2 := x2.Args[2]
-		if x2_2.Op != OpAMD64SHRLconst {
+		if x2_2.Op != OpAMD64SHRLconst || x2_2.AuxInt != 8 || w != x2_2.Args[0] {
 			break
 		}
-		if x2_2.AuxInt != 8 {
-			break
-		}
-		if w != x2_2.Args[0] {
-			break
-		}
 		x1 := x2.Args[3]
-		if x1.Op != OpAMD64MOVBstoreidx1 {
+		if x1.Op != OpAMD64MOVBstoreidx1 || x1.AuxInt != i-2 || x1.Aux != s {
 			break
 		}
-		if x1.AuxInt != i-2 {
-			break
-		}
-		if x1.Aux != s {
-			break
-		}
 		_ = x1.Args[3]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
 		x1_2 := x1.Args[2]
-		if x1_2.Op != OpAMD64SHRLconst {
+		if x1_2.Op != OpAMD64SHRLconst || x1_2.AuxInt != 16 || w != x1_2.Args[0] {
 			break
 		}
-		if x1_2.AuxInt != 16 {
-			break
-		}
-		if w != x1_2.Args[0] {
-			break
-		}
 		x0 := x1.Args[3]
-		if x0.Op != OpAMD64MOVBstoreidx1 {
+		if x0.Op != OpAMD64MOVBstoreidx1 || x0.AuxInt != i-3 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-3 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[3]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
 		x0_2 := x0.Args[2]
-		if x0_2.Op != OpAMD64SHRLconst {
+		if x0_2.Op != OpAMD64SHRLconst || x0_2.AuxInt != 24 || w != x0_2.Args[0] || !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2)) {
 			break
 		}
-		if x0_2.AuxInt != 24 {
-			break
-		}
-		if w != x0_2.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 3
 		v.Aux = s
@@ -14320,197 +13408,89 @@
 		idx := v.Args[1]
 		w := v.Args[2]
 		x6 := v.Args[3]
-		if x6.Op != OpAMD64MOVBstoreidx1 {
+		if x6.Op != OpAMD64MOVBstoreidx1 || x6.AuxInt != i-1 || x6.Aux != s {
 			break
 		}
-		if x6.AuxInt != i-1 {
-			break
-		}
-		if x6.Aux != s {
-			break
-		}
 		_ = x6.Args[3]
-		if p != x6.Args[0] {
+		if p != x6.Args[0] || idx != x6.Args[1] {
 			break
 		}
-		if idx != x6.Args[1] {
-			break
-		}
 		x6_2 := x6.Args[2]
-		if x6_2.Op != OpAMD64SHRQconst {
+		if x6_2.Op != OpAMD64SHRQconst || x6_2.AuxInt != 8 || w != x6_2.Args[0] {
 			break
 		}
-		if x6_2.AuxInt != 8 {
-			break
-		}
-		if w != x6_2.Args[0] {
-			break
-		}
 		x5 := x6.Args[3]
-		if x5.Op != OpAMD64MOVBstoreidx1 {
+		if x5.Op != OpAMD64MOVBstoreidx1 || x5.AuxInt != i-2 || x5.Aux != s {
 			break
 		}
-		if x5.AuxInt != i-2 {
-			break
-		}
-		if x5.Aux != s {
-			break
-		}
 		_ = x5.Args[3]
-		if p != x5.Args[0] {
+		if p != x5.Args[0] || idx != x5.Args[1] {
 			break
 		}
-		if idx != x5.Args[1] {
-			break
-		}
 		x5_2 := x5.Args[2]
-		if x5_2.Op != OpAMD64SHRQconst {
+		if x5_2.Op != OpAMD64SHRQconst || x5_2.AuxInt != 16 || w != x5_2.Args[0] {
 			break
 		}
-		if x5_2.AuxInt != 16 {
-			break
-		}
-		if w != x5_2.Args[0] {
-			break
-		}
 		x4 := x5.Args[3]
-		if x4.Op != OpAMD64MOVBstoreidx1 {
+		if x4.Op != OpAMD64MOVBstoreidx1 || x4.AuxInt != i-3 || x4.Aux != s {
 			break
 		}
-		if x4.AuxInt != i-3 {
-			break
-		}
-		if x4.Aux != s {
-			break
-		}
 		_ = x4.Args[3]
-		if p != x4.Args[0] {
+		if p != x4.Args[0] || idx != x4.Args[1] {
 			break
 		}
-		if idx != x4.Args[1] {
-			break
-		}
 		x4_2 := x4.Args[2]
-		if x4_2.Op != OpAMD64SHRQconst {
+		if x4_2.Op != OpAMD64SHRQconst || x4_2.AuxInt != 24 || w != x4_2.Args[0] {
 			break
 		}
-		if x4_2.AuxInt != 24 {
-			break
-		}
-		if w != x4_2.Args[0] {
-			break
-		}
 		x3 := x4.Args[3]
-		if x3.Op != OpAMD64MOVBstoreidx1 {
+		if x3.Op != OpAMD64MOVBstoreidx1 || x3.AuxInt != i-4 || x3.Aux != s {
 			break
 		}
-		if x3.AuxInt != i-4 {
-			break
-		}
-		if x3.Aux != s {
-			break
-		}
 		_ = x3.Args[3]
-		if p != x3.Args[0] {
+		if p != x3.Args[0] || idx != x3.Args[1] {
 			break
 		}
-		if idx != x3.Args[1] {
-			break
-		}
 		x3_2 := x3.Args[2]
-		if x3_2.Op != OpAMD64SHRQconst {
+		if x3_2.Op != OpAMD64SHRQconst || x3_2.AuxInt != 32 || w != x3_2.Args[0] {
 			break
 		}
-		if x3_2.AuxInt != 32 {
-			break
-		}
-		if w != x3_2.Args[0] {
-			break
-		}
 		x2 := x3.Args[3]
-		if x2.Op != OpAMD64MOVBstoreidx1 {
+		if x2.Op != OpAMD64MOVBstoreidx1 || x2.AuxInt != i-5 || x2.Aux != s {
 			break
 		}
-		if x2.AuxInt != i-5 {
-			break
-		}
-		if x2.Aux != s {
-			break
-		}
 		_ = x2.Args[3]
-		if p != x2.Args[0] {
+		if p != x2.Args[0] || idx != x2.Args[1] {
 			break
 		}
-		if idx != x2.Args[1] {
-			break
-		}
 		x2_2 := x2.Args[2]
-		if x2_2.Op != OpAMD64SHRQconst {
+		if x2_2.Op != OpAMD64SHRQconst || x2_2.AuxInt != 40 || w != x2_2.Args[0] {
 			break
 		}
-		if x2_2.AuxInt != 40 {
-			break
-		}
-		if w != x2_2.Args[0] {
-			break
-		}
 		x1 := x2.Args[3]
-		if x1.Op != OpAMD64MOVBstoreidx1 {
+		if x1.Op != OpAMD64MOVBstoreidx1 || x1.AuxInt != i-6 || x1.Aux != s {
 			break
 		}
-		if x1.AuxInt != i-6 {
-			break
-		}
-		if x1.Aux != s {
-			break
-		}
 		_ = x1.Args[3]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
 		x1_2 := x1.Args[2]
-		if x1_2.Op != OpAMD64SHRQconst {
+		if x1_2.Op != OpAMD64SHRQconst || x1_2.AuxInt != 48 || w != x1_2.Args[0] {
 			break
 		}
-		if x1_2.AuxInt != 48 {
-			break
-		}
-		if w != x1_2.Args[0] {
-			break
-		}
 		x0 := x1.Args[3]
-		if x0.Op != OpAMD64MOVBstoreidx1 {
+		if x0.Op != OpAMD64MOVBstoreidx1 || x0.AuxInt != i-7 || x0.Aux != s {
 			break
 		}
-		if x0.AuxInt != i-7 {
-			break
-		}
-		if x0.Aux != s {
-			break
-		}
 		mem := x0.Args[3]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
 		x0_2 := x0.Args[2]
-		if x0_2.Op != OpAMD64SHRQconst {
+		if x0_2.Op != OpAMD64SHRQconst || x0_2.AuxInt != 56 || w != x0_2.Args[0] || !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && x3.Uses == 1 && x4.Uses == 1 && x5.Uses == 1 && x6.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2) && clobber(x3) && clobber(x4) && clobber(x5) && clobber(x6)) {
 			break
 		}
-		if x0_2.AuxInt != 56 {
-			break
-		}
-		if w != x0_2.Args[0] {
-			break
-		}
-		if !(x0.Uses == 1 && x1.Uses == 1 && x2.Uses == 1 && x3.Uses == 1 && x4.Uses == 1 && x5.Uses == 1 && x6.Uses == 1 && clobber(x0) && clobber(x1) && clobber(x2) && clobber(x3) && clobber(x4) && clobber(x5) && clobber(x6)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = i - 7
 		v.Aux = s
@@ -14532,36 +13512,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRWconst {
+		if v_2.Op != OpAMD64SHRWconst || v_2.AuxInt != 8 {
 			break
 		}
-		if v_2.AuxInt != 8 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVBstoreidx1 {
+		if x.Op != OpAMD64MOVBstoreidx1 || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14581,36 +13543,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRLconst {
+		if v_2.Op != OpAMD64SHRLconst || v_2.AuxInt != 8 {
 			break
 		}
-		if v_2.AuxInt != 8 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVBstoreidx1 {
+		if x.Op != OpAMD64MOVBstoreidx1 || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14630,36 +13574,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRQconst {
+		if v_2.Op != OpAMD64SHRQconst || v_2.AuxInt != 8 {
 			break
 		}
-		if v_2.AuxInt != 8 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVBstoreidx1 {
+		if x.Op != OpAMD64MOVBstoreidx1 || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14685,35 +13611,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVBstoreidx1 {
+		if x.Op != OpAMD64MOVBstoreidx1 || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRLconst {
+		if w0.Op != OpAMD64SHRLconst || w0.AuxInt != j-8 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-8 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14739,35 +13647,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVBstoreidx1 {
+		if x.Op != OpAMD64MOVBstoreidx1 || x.AuxInt != i-1 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-1 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-8 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-8 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVWstoreidx1)
 		v.AuxInt = i - 1
 		v.Aux = s
@@ -14878,7 +13768,6 @@
 		return true
 	}
 	// match: (MOVLQSX (MOVLQSX x))
-	// cond:
 	// result: (MOVLQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -14891,7 +13780,6 @@
 		return true
 	}
 	// match: (MOVLQSX (MOVWQSX x))
-	// cond:
 	// result: (MOVWQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -14904,7 +13792,6 @@
 		return true
 	}
 	// match: (MOVLQSX (MOVBQSX x))
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -15089,7 +13976,6 @@
 		return true
 	}
 	// match: (MOVLQZX (ANDLconst [c] x))
-	// cond:
 	// result: (ANDLconst [c] x)
 	for {
 		v_0 := v.Args[0]
@@ -15104,7 +13990,6 @@
 		return true
 	}
 	// match: (MOVLQZX (MOVLQZX x))
-	// cond:
 	// result: (MOVLQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -15117,7 +14002,6 @@
 		return true
 	}
 	// match: (MOVLQZX (MOVWQZX x))
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -15130,7 +14014,6 @@
 		return true
 	}
 	// match: (MOVLQZX (MOVBQZX x))
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -15470,7 +14353,6 @@
 		return true
 	}
 	// match: (MOVLload [off] {sym} ptr (MOVSSstore [off] {sym} ptr val _))
-	// cond:
 	// result: (MOVLf2i val)
 	for {
 		off := v.AuxInt
@@ -15478,15 +14360,9 @@
 		_ = v.Args[1]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64MOVSSstore {
+		if v_1.Op != OpAMD64MOVSSstore || v_1.AuxInt != off || v_1.Aux != sym {
 			break
 		}
-		if v_1.AuxInt != off {
-			break
-		}
-		if v_1.Aux != sym {
-			break
-		}
 		_ = v_1.Args[2]
 		if ptr != v_1.Args[0] {
 			break
@@ -15509,12 +14385,9 @@
 		sym := v.Aux
 		_ = v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpSB {
+		if v_0.Op != OpSB || !(symIsRO(sym)) {
 			break
 		}
-		if !(symIsRO(sym)) {
-			break
-		}
 		v.reset(OpAMD64MOVQconst)
 		v.AuxInt = int64(read32(sym, off, config.BigEndian))
 		return true
@@ -15523,7 +14396,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVLloadidx1_0(v *Value) bool {
 	// match: (MOVLloadidx1 [c] {sym} ptr (SHLQconst [2] idx) mem)
-	// cond:
 	// result: (MOVLloadidx4 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -15531,12 +14403,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVLloadidx4)
 		v.AuxInt = c
@@ -15547,19 +14416,15 @@
 		return true
 	}
 	// match: (MOVLloadidx1 [c] {sym} (SHLQconst [2] idx) ptr mem)
-	// cond:
 	// result: (MOVLloadidx4 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
 		sym := v.Aux
 		mem := v.Args[2]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 2 {
 			break
 		}
-		if v_0.AuxInt != 2 {
-			break
-		}
 		idx := v_0.Args[0]
 		ptr := v.Args[1]
 		v.reset(OpAMD64MOVLloadidx4)
@@ -15571,7 +14436,6 @@
 		return true
 	}
 	// match: (MOVLloadidx1 [c] {sym} ptr (SHLQconst [3] idx) mem)
-	// cond:
 	// result: (MOVLloadidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -15579,12 +14443,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVLloadidx8)
 		v.AuxInt = c
@@ -15595,19 +14456,15 @@
 		return true
 	}
 	// match: (MOVLloadidx1 [c] {sym} (SHLQconst [3] idx) ptr mem)
-	// cond:
 	// result: (MOVLloadidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
 		sym := v.Aux
 		mem := v.Args[2]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		idx := v_0.Args[0]
 		ptr := v.Args[1]
 		v.reset(OpAMD64MOVLloadidx8)
@@ -15920,7 +14777,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVLstore_0(v *Value) bool {
 	// match: (MOVLstore [off] {sym} ptr (MOVLQSX x) mem)
-	// cond:
 	// result: (MOVLstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -15941,7 +14797,6 @@
 		return true
 	}
 	// match: (MOVLstore [off] {sym} ptr (MOVLQZX x) mem)
-	// cond:
 	// result: (MOVLstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -16182,33 +15037,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRQconst {
+		if v_1.Op != OpAMD64SHRQconst || v_1.AuxInt != 32 {
 			break
 		}
-		if v_1.AuxInt != 32 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVLstore {
+		if x.Op != OpAMD64MOVLstore || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -16232,32 +15072,17 @@
 		j := v_1.AuxInt
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVLstore {
+		if x.Op != OpAMD64MOVLstore || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		w0 := x.Args[1]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-32 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-32 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -16283,42 +15108,21 @@
 		mem := x1.Args[1]
 		p2 := x1.Args[0]
 		mem2 := v.Args[2]
-		if mem2.Op != OpAMD64MOVLstore {
+		if mem2.Op != OpAMD64MOVLstore || mem2.AuxInt != i-4 || mem2.Aux != s {
 			break
 		}
-		if mem2.AuxInt != i-4 {
-			break
-		}
-		if mem2.Aux != s {
-			break
-		}
 		_ = mem2.Args[2]
 		if p != mem2.Args[0] {
 			break
 		}
 		x2 := mem2.Args[1]
-		if x2.Op != OpAMD64MOVLload {
+		if x2.Op != OpAMD64MOVLload || x2.AuxInt != j-4 || x2.Aux != s2 {
 			break
 		}
-		if x2.AuxInt != j-4 {
-			break
-		}
-		if x2.Aux != s2 {
-			break
-		}
 		_ = x2.Args[1]
-		if p2 != x2.Args[0] {
+		if p2 != x2.Args[0] || mem != x2.Args[1] || mem != mem2.Args[2] || !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
 			break
 		}
-		if mem != x2.Args[1] {
-			break
-		}
-		if mem != mem2.Args[2] {
-			break
-		}
-		if !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -16392,26 +15196,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ADDLload {
+		if y.Op != OpAMD64ADDLload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ADDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16429,26 +15221,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ANDLload {
+		if y.Op != OpAMD64ANDLload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ANDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16466,26 +15246,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ORLload {
+		if y.Op != OpAMD64ORLload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16503,26 +15271,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64XORLload {
+		if y.Op != OpAMD64XORLload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64XORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16545,25 +15301,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ADDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16590,25 +15334,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ADDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16631,25 +15363,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64SUBLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16672,25 +15392,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ANDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16714,25 +15422,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ANDLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16755,25 +15451,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16797,25 +15481,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16838,25 +15510,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64XORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16880,25 +15540,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64XORLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16921,25 +15569,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTCLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -16962,25 +15598,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTRLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -17006,25 +15630,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTSLmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -17047,23 +15659,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ADDLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17085,23 +15688,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ANDLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17123,23 +15717,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ORLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17161,23 +15746,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64XORLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17199,23 +15775,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTCLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17237,23 +15804,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTRLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17275,23 +15833,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVLload {
+		if l.Op != OpAMD64MOVLload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTSLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -17300,7 +15849,6 @@
 		return true
 	}
 	// match: (MOVLstore [off] {sym} ptr (MOVLf2i val) mem)
-	// cond:
 	// result: (MOVSSstore [off] {sym} ptr val mem)
 	for {
 		off := v.AuxInt
@@ -17425,7 +15973,6 @@
 		return true
 	}
 	// match: (MOVLstoreconst [x] {sym} (ADDQ ptr idx) mem)
-	// cond:
 	// result: (MOVLstoreconstidx1 [x] {sym} ptr idx mem)
 	for {
 		x := v.AuxInt
@@ -17462,12 +16009,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = ValAndOff(a).Off()
 		v.Aux = s
@@ -17495,12 +16039,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstore)
 		v.AuxInt = ValAndOff(a).Off()
 		v.Aux = s
@@ -17564,7 +16105,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (MOVLstoreconstidx1 [c] {sym} ptr (SHLQconst [2] idx) mem)
-	// cond:
 	// result: (MOVLstoreconstidx4 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -17572,12 +16112,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVLstoreconstidx4)
 		v.AuxInt = c
@@ -17655,15 +16192,9 @@
 			break
 		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || i != x.Args[1] || !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if i != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = ValAndOff(a).Off()
 		v.Aux = s
@@ -17748,15 +16279,9 @@
 			break
 		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || i != x.Args[1] || !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if i != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+4 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = ValAndOff(a).Off()
 		v.Aux = s
@@ -17775,7 +16300,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVLstoreidx1_0(v *Value) bool {
 	// match: (MOVLstoreidx1 [c] {sym} ptr (SHLQconst [2] idx) val mem)
-	// cond:
 	// result: (MOVLstoreidx4 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -17783,12 +16307,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVLstoreidx4)
@@ -17801,7 +16322,6 @@
 		return true
 	}
 	// match: (MOVLstoreidx1 [c] {sym} ptr (SHLQconst [3] idx) val mem)
-	// cond:
 	// result: (MOVLstoreidx8 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -17809,12 +16329,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVLstoreidx8)
@@ -17890,36 +16407,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRQconst {
+		if v_2.Op != OpAMD64SHRQconst || v_2.AuxInt != 32 {
 			break
 		}
-		if v_2.AuxInt != 32 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVLstoreidx1 {
+		if x.Op != OpAMD64MOVLstoreidx1 || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -17945,35 +16444,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVLstoreidx1 {
+		if x.Op != OpAMD64MOVLstoreidx1 || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-32 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-32 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -18076,36 +16557,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRQconst {
+		if v_2.Op != OpAMD64SHRQconst || v_2.AuxInt != 32 {
 			break
 		}
-		if v_2.AuxInt != 32 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVLstoreidx4 {
+		if x.Op != OpAMD64MOVLstoreidx4 || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -18134,35 +16597,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVLstoreidx4 {
+		if x.Op != OpAMD64MOVLstoreidx4 || x.AuxInt != i-4 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-4 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-32 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-32 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVQstoreidx1)
 		v.AuxInt = i - 4
 		v.Aux = s
@@ -18691,7 +17136,6 @@
 		return true
 	}
 	// match: (MOVQload [off] {sym} ptr (MOVSDstore [off] {sym} ptr val _))
-	// cond:
 	// result: (MOVQf2i val)
 	for {
 		off := v.AuxInt
@@ -18699,15 +17143,9 @@
 		_ = v.Args[1]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64MOVSDstore {
+		if v_1.Op != OpAMD64MOVSDstore || v_1.AuxInt != off || v_1.Aux != sym {
 			break
 		}
-		if v_1.AuxInt != off {
-			break
-		}
-		if v_1.Aux != sym {
-			break
-		}
 		_ = v_1.Args[2]
 		if ptr != v_1.Args[0] {
 			break
@@ -18725,12 +17163,9 @@
 		sym := v.Aux
 		_ = v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpSB {
+		if v_0.Op != OpSB || !(symIsRO(sym)) {
 			break
 		}
-		if !(symIsRO(sym)) {
-			break
-		}
 		v.reset(OpAMD64MOVQconst)
 		v.AuxInt = int64(read64(sym, off, config.BigEndian))
 		return true
@@ -18739,7 +17174,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVQloadidx1_0(v *Value) bool {
 	// match: (MOVQloadidx1 [c] {sym} ptr (SHLQconst [3] idx) mem)
-	// cond:
 	// result: (MOVQloadidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -18747,12 +17181,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVQloadidx8)
 		v.AuxInt = c
@@ -18763,19 +17194,15 @@
 		return true
 	}
 	// match: (MOVQloadidx1 [c] {sym} (SHLQconst [3] idx) ptr mem)
-	// cond:
 	// result: (MOVQloadidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
 		sym := v.Aux
 		mem := v.Args[2]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 3 {
 			break
 		}
-		if v_0.AuxInt != 3 {
-			break
-		}
 		idx := v_0.Args[0]
 		ptr := v.Args[1]
 		v.reset(OpAMD64MOVQloadidx8)
@@ -19227,26 +17654,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ADDQload {
+		if y.Op != OpAMD64ADDQload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ADDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19264,26 +17679,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ANDQload {
+		if y.Op != OpAMD64ANDQload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ANDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19304,26 +17707,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64ORQload {
+		if y.Op != OpAMD64ORQload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64ORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19341,26 +17732,14 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != OpAMD64XORQload {
+		if y.Op != OpAMD64XORQload || y.AuxInt != off || y.Aux != sym {
 			break
 		}
-		if y.AuxInt != off {
-			break
-		}
-		if y.Aux != sym {
-			break
-		}
 		_ = y.Args[2]
 		x := y.Args[0]
-		if ptr != y.Args[1] {
+		if ptr != y.Args[1] || mem != y.Args[2] || !(y.Uses == 1 && clobber(y)) {
 			break
 		}
-		if mem != y.Args[2] {
-			break
-		}
-		if !(y.Uses == 1 && clobber(y)) {
-			break
-		}
 		v.reset(OpAMD64XORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19383,25 +17762,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ADDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19425,25 +17792,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ADDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19466,25 +17821,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64SUBQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19507,25 +17850,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ANDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19549,25 +17880,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ANDQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19590,25 +17909,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19632,25 +17939,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64ORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19673,25 +17968,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64XORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19718,25 +18001,13 @@
 		_ = y.Args[1]
 		x := y.Args[0]
 		l := y.Args[1]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64XORQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19759,25 +18030,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTCQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19800,25 +18059,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTRQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19841,25 +18088,13 @@
 		}
 		x := y.Args[1]
 		l := y.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
-		if ptr != l.Args[0] {
+		if ptr != l.Args[0] || mem != l.Args[1] || !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
 			break
 		}
-		if mem != l.Args[1] {
-			break
-		}
-		if !(y.Uses == 1 && l.Uses == 1 && clobber(y) && clobber(l)) {
-			break
-		}
 		v.reset(OpAMD64BTSQmodify)
 		v.AuxInt = off
 		v.Aux = sym
@@ -19882,23 +18117,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ADDQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -19920,23 +18146,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ANDQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -19958,23 +18175,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64ORQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -19996,23 +18204,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64XORQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -20034,23 +18233,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTCQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -20072,23 +18262,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTRQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -20113,23 +18294,14 @@
 		}
 		c := a.AuxInt
 		l := a.Args[0]
-		if l.Op != OpAMD64MOVQload {
+		if l.Op != OpAMD64MOVQload || l.AuxInt != off || l.Aux != sym {
 			break
 		}
-		if l.AuxInt != off {
-			break
-		}
-		if l.Aux != sym {
-			break
-		}
 		_ = l.Args[1]
 		ptr2 := l.Args[0]
-		if mem != l.Args[1] {
+		if mem != l.Args[1] || !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
 			break
 		}
-		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off) && clobber(l) && clobber(a)) {
-			break
-		}
 		v.reset(OpAMD64BTSQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
@@ -20138,7 +18310,6 @@
 		return true
 	}
 	// match: (MOVQstore [off] {sym} ptr (MOVQf2i val) mem)
-	// cond:
 	// result: (MOVSDstore [off] {sym} ptr val mem)
 	for {
 		off := v.AuxInt
@@ -20263,7 +18434,6 @@
 		return true
 	}
 	// match: (MOVQstoreconst [x] {sym} (ADDQ ptr idx) mem)
-	// cond:
 	// result: (MOVQstoreconstidx1 [x] {sym} ptr idx mem)
 	for {
 		x := v.AuxInt
@@ -20300,12 +18470,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(config.useSSE && x.Uses == 1 && ValAndOff(c2).Off()+8 == ValAndOff(c).Off() && ValAndOff(c).Val() == 0 && ValAndOff(c2).Val() == 0 && clobber(x)) {
 			break
 		}
-		if !(config.useSSE && x.Uses == 1 && ValAndOff(c2).Off()+8 == ValAndOff(c).Off() && ValAndOff(c).Val() == 0 && ValAndOff(c2).Val() == 0 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVOstore)
 		v.AuxInt = ValAndOff(c2).Off()
 		v.Aux = s
@@ -20367,7 +18534,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVQstoreconstidx1_0(v *Value) bool {
 	// match: (MOVQstoreconstidx1 [c] {sym} ptr (SHLQconst [3] idx) mem)
-	// cond:
 	// result: (MOVQstoreconstidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -20375,12 +18541,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVQstoreconstidx8)
 		v.AuxInt = c
@@ -20497,7 +18660,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVQstoreidx1_0(v *Value) bool {
 	// match: (MOVQstoreidx1 [c] {sym} ptr (SHLQconst [3] idx) val mem)
-	// cond:
 	// result: (MOVQstoreidx8 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -20505,12 +18667,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVQstoreidx8)
@@ -20810,7 +18969,6 @@
 		return true
 	}
 	// match: (MOVSDload [off] {sym} ptr (MOVQstore [off] {sym} ptr val _))
-	// cond:
 	// result: (MOVQi2f val)
 	for {
 		off := v.AuxInt
@@ -20818,15 +18976,9 @@
 		_ = v.Args[1]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64MOVQstore {
+		if v_1.Op != OpAMD64MOVQstore || v_1.AuxInt != off || v_1.Aux != sym {
 			break
 		}
-		if v_1.AuxInt != off {
-			break
-		}
-		if v_1.Aux != sym {
-			break
-		}
 		_ = v_1.Args[2]
 		if ptr != v_1.Args[0] {
 			break
@@ -20840,7 +18992,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVSDloadidx1_0(v *Value) bool {
 	// match: (MOVSDloadidx1 [c] {sym} ptr (SHLQconst [3] idx) mem)
-	// cond:
 	// result: (MOVSDloadidx8 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -20848,12 +18999,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVSDloadidx8)
 		v.AuxInt = c
@@ -21149,7 +19297,6 @@
 		return true
 	}
 	// match: (MOVSDstore [off] {sym} ptr (MOVQi2f val) mem)
-	// cond:
 	// result: (MOVQstore [off] {sym} ptr val mem)
 	for {
 		off := v.AuxInt
@@ -21173,7 +19320,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVSDstoreidx1_0(v *Value) bool {
 	// match: (MOVSDstoreidx1 [c] {sym} ptr (SHLQconst [3] idx) val mem)
-	// cond:
 	// result: (MOVSDstoreidx8 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -21181,12 +19327,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 3 {
 			break
 		}
-		if v_1.AuxInt != 3 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVSDstoreidx8)
@@ -21486,7 +19629,6 @@
 		return true
 	}
 	// match: (MOVSSload [off] {sym} ptr (MOVLstore [off] {sym} ptr val _))
-	// cond:
 	// result: (MOVLi2f val)
 	for {
 		off := v.AuxInt
@@ -21494,15 +19636,9 @@
 		_ = v.Args[1]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64MOVLstore {
+		if v_1.Op != OpAMD64MOVLstore || v_1.AuxInt != off || v_1.Aux != sym {
 			break
 		}
-		if v_1.AuxInt != off {
-			break
-		}
-		if v_1.Aux != sym {
-			break
-		}
 		_ = v_1.Args[2]
 		if ptr != v_1.Args[0] {
 			break
@@ -21516,7 +19652,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVSSloadidx1_0(v *Value) bool {
 	// match: (MOVSSloadidx1 [c] {sym} ptr (SHLQconst [2] idx) mem)
-	// cond:
 	// result: (MOVSSloadidx4 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -21524,12 +19659,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVSSloadidx4)
 		v.AuxInt = c
@@ -21825,7 +19957,6 @@
 		return true
 	}
 	// match: (MOVSSstore [off] {sym} ptr (MOVLi2f val) mem)
-	// cond:
 	// result: (MOVLstore [off] {sym} ptr val mem)
 	for {
 		off := v.AuxInt
@@ -21849,7 +19980,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVSSstoreidx1_0(v *Value) bool {
 	// match: (MOVSSstoreidx1 [c] {sym} ptr (SHLQconst [2] idx) val mem)
-	// cond:
 	// result: (MOVSSstoreidx4 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -21857,12 +19987,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 2 {
 			break
 		}
-		if v_1.AuxInt != 2 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVSSstoreidx4)
@@ -22133,7 +20260,6 @@
 		return true
 	}
 	// match: (MOVWQSX (MOVWQSX x))
-	// cond:
 	// result: (MOVWQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -22146,7 +20272,6 @@
 		return true
 	}
 	// match: (MOVWQSX (MOVBQSX x))
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		v_0 := v.Args[0]
@@ -22356,7 +20481,6 @@
 		return true
 	}
 	// match: (MOVWQZX (ANDLconst [c] x))
-	// cond:
 	// result: (ANDLconst [c & 0xffff] x)
 	for {
 		v_0 := v.Args[0]
@@ -22371,7 +20495,6 @@
 		return true
 	}
 	// match: (MOVWQZX (MOVWQZX x))
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -22384,7 +20507,6 @@
 		return true
 	}
 	// match: (MOVWQZX (MOVBQZX x))
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		v_0 := v.Args[0]
@@ -22603,12 +20725,9 @@
 		sym := v.Aux
 		_ = v.Args[1]
 		v_0 := v.Args[0]
-		if v_0.Op != OpSB {
+		if v_0.Op != OpSB || !(symIsRO(sym)) {
 			break
 		}
-		if !(symIsRO(sym)) {
-			break
-		}
 		v.reset(OpAMD64MOVLconst)
 		v.AuxInt = int64(read16(sym, off, config.BigEndian))
 		return true
@@ -22617,7 +20736,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVWloadidx1_0(v *Value) bool {
 	// match: (MOVWloadidx1 [c] {sym} ptr (SHLQconst [1] idx) mem)
-	// cond:
 	// result: (MOVWloadidx2 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -22625,12 +20743,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVWloadidx2)
 		v.AuxInt = c
@@ -22641,19 +20756,15 @@
 		return true
 	}
 	// match: (MOVWloadidx1 [c] {sym} (SHLQconst [1] idx) ptr mem)
-	// cond:
 	// result: (MOVWloadidx2 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
 		sym := v.Aux
 		mem := v.Args[2]
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		idx := v_0.Args[0]
 		ptr := v.Args[1]
 		v.reset(OpAMD64MOVWloadidx2)
@@ -22890,7 +21001,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVWstore_0(v *Value) bool {
 	// match: (MOVWstore [off] {sym} ptr (MOVWQSX x) mem)
-	// cond:
 	// result: (MOVWstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -22911,7 +21021,6 @@
 		return true
 	}
 	// match: (MOVWstore [off] {sym} ptr (MOVWQZX x) mem)
-	// cond:
 	// result: (MOVWstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -23119,33 +21228,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRLconst {
+		if v_1.Op != OpAMD64SHRLconst || v_1.AuxInt != 16 {
 			break
 		}
-		if v_1.AuxInt != 16 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVWstore {
+		if x.Op != OpAMD64MOVWstore || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23168,33 +21262,18 @@
 		_ = v.Args[2]
 		p := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHRQconst {
+		if v_1.Op != OpAMD64SHRQconst || v_1.AuxInt != 16 {
 			break
 		}
-		if v_1.AuxInt != 16 {
-			break
-		}
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVWstore {
+		if x.Op != OpAMD64MOVWstore || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || w != x.Args[1] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23218,32 +21297,17 @@
 		j := v_1.AuxInt
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVWstore {
+		if x.Op != OpAMD64MOVWstore || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		w0 := x.Args[1]
-		if w0.Op != OpAMD64SHRLconst {
+		if w0.Op != OpAMD64SHRLconst || w0.AuxInt != j-16 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-16 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23267,32 +21331,17 @@
 		j := v_1.AuxInt
 		w := v_1.Args[0]
 		x := v.Args[2]
-		if x.Op != OpAMD64MOVWstore {
+		if x.Op != OpAMD64MOVWstore || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[2]
 		if p != x.Args[0] {
 			break
 		}
 		w0 := x.Args[1]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-16 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-16 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23318,42 +21367,21 @@
 		mem := x1.Args[1]
 		p2 := x1.Args[0]
 		mem2 := v.Args[2]
-		if mem2.Op != OpAMD64MOVWstore {
+		if mem2.Op != OpAMD64MOVWstore || mem2.AuxInt != i-2 || mem2.Aux != s {
 			break
 		}
-		if mem2.AuxInt != i-2 {
-			break
-		}
-		if mem2.Aux != s {
-			break
-		}
 		_ = mem2.Args[2]
 		if p != mem2.Args[0] {
 			break
 		}
 		x2 := mem2.Args[1]
-		if x2.Op != OpAMD64MOVWload {
+		if x2.Op != OpAMD64MOVWload || x2.AuxInt != j-2 || x2.Aux != s2 {
 			break
 		}
-		if x2.AuxInt != j-2 {
-			break
-		}
-		if x2.Aux != s2 {
-			break
-		}
 		_ = x2.Args[1]
-		if p2 != x2.Args[0] {
+		if p2 != x2.Args[0] || mem != x2.Args[1] || mem != mem2.Args[2] || !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
 			break
 		}
-		if mem != x2.Args[1] {
-			break
-		}
-		if mem != mem2.Args[2] {
-			break
-		}
-		if !(x1.Uses == 1 && x2.Uses == 1 && mem2.Uses == 1 && clobber(x1) && clobber(x2) && clobber(mem2)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstore)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23521,7 +21549,6 @@
 		return true
 	}
 	// match: (MOVWstoreconst [x] {sym} (ADDQ ptr idx) mem)
-	// cond:
 	// result: (MOVWstoreconstidx1 [x] {sym} ptr idx mem)
 	for {
 		x := v.AuxInt
@@ -23558,12 +21585,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreconst)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xffff|ValAndOff(c).Val()<<16, ValAndOff(a).Off())
 		v.Aux = s
@@ -23588,12 +21612,9 @@
 			break
 		}
 		mem := x.Args[1]
-		if p != x.Args[0] {
+		if p != x.Args[0] || !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreconst)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xffff|ValAndOff(c).Val()<<16, ValAndOff(a).Off())
 		v.Aux = s
@@ -23652,7 +21673,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVWstoreconstidx1_0(v *Value) bool {
 	// match: (MOVWstoreconstidx1 [c] {sym} ptr (SHLQconst [1] idx) mem)
-	// cond:
 	// result: (MOVWstoreconstidx2 [c] {sym} ptr idx mem)
 	for {
 		c := v.AuxInt
@@ -23660,12 +21680,9 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		idx := v_1.Args[0]
 		v.reset(OpAMD64MOVWstoreconstidx2)
 		v.AuxInt = c
@@ -23743,15 +21760,9 @@
 			break
 		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || i != x.Args[1] || !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if i != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreconstidx1)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xffff|ValAndOff(c).Val()<<16, ValAndOff(a).Off())
 		v.Aux = s
@@ -23832,15 +21843,9 @@
 			break
 		}
 		mem := x.Args[2]
-		if p != x.Args[0] {
+		if p != x.Args[0] || i != x.Args[1] || !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
 			break
 		}
-		if i != x.Args[1] {
-			break
-		}
-		if !(x.Uses == 1 && ValAndOff(a).Off()+2 == ValAndOff(c).Off() && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreconstidx1)
 		v.AuxInt = makeValAndOff(ValAndOff(a).Val()&0xffff|ValAndOff(c).Val()<<16, ValAndOff(a).Off())
 		v.Aux = s
@@ -23856,7 +21861,6 @@
 }
 func rewriteValueAMD64_OpAMD64MOVWstoreidx1_0(v *Value) bool {
 	// match: (MOVWstoreidx1 [c] {sym} ptr (SHLQconst [1] idx) val mem)
-	// cond:
 	// result: (MOVWstoreidx2 [c] {sym} ptr idx val mem)
 	for {
 		c := v.AuxInt
@@ -23864,12 +21868,9 @@
 		mem := v.Args[3]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64SHLQconst {
+		if v_1.Op != OpAMD64SHLQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		idx := v_1.Args[0]
 		val := v.Args[2]
 		v.reset(OpAMD64MOVWstoreidx2)
@@ -23945,36 +21946,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRLconst {
+		if v_2.Op != OpAMD64SHRLconst || v_2.AuxInt != 16 {
 			break
 		}
-		if v_2.AuxInt != 16 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx1 {
+		if x.Op != OpAMD64MOVWstoreidx1 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -23994,36 +21977,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRQconst {
+		if v_2.Op != OpAMD64SHRQconst || v_2.AuxInt != 16 {
 			break
 		}
-		if v_2.AuxInt != 16 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx1 {
+		if x.Op != OpAMD64MOVWstoreidx1 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24049,35 +22014,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx1 {
+		if x.Op != OpAMD64MOVWstoreidx1 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRLconst {
+		if w0.Op != OpAMD64SHRLconst || w0.AuxInt != j-16 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-16 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24103,35 +22050,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx1 {
+		if x.Op != OpAMD64MOVWstoreidx1 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-16 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-16 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24234,36 +22163,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRLconst {
+		if v_2.Op != OpAMD64SHRLconst || v_2.AuxInt != 16 {
 			break
 		}
-		if v_2.AuxInt != 16 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx2 {
+		if x.Op != OpAMD64MOVWstoreidx2 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24286,36 +22197,18 @@
 		p := v.Args[0]
 		idx := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64SHRQconst {
+		if v_2.Op != OpAMD64SHRQconst || v_2.AuxInt != 16 {
 			break
 		}
-		if v_2.AuxInt != 16 {
-			break
-		}
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx2 {
+		if x.Op != OpAMD64MOVWstoreidx2 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] || w != x.Args[2] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
-		if w != x.Args[2] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24344,35 +22237,17 @@
 		j := v_2.AuxInt
 		w := v_2.Args[0]
 		x := v.Args[3]
-		if x.Op != OpAMD64MOVWstoreidx2 {
+		if x.Op != OpAMD64MOVWstoreidx2 || x.AuxInt != i-2 || x.Aux != s {
 			break
 		}
-		if x.AuxInt != i-2 {
-			break
-		}
-		if x.Aux != s {
-			break
-		}
 		mem := x.Args[3]
-		if p != x.Args[0] {
+		if p != x.Args[0] || idx != x.Args[1] {
 			break
 		}
-		if idx != x.Args[1] {
-			break
-		}
 		w0 := x.Args[2]
-		if w0.Op != OpAMD64SHRQconst {
+		if w0.Op != OpAMD64SHRQconst || w0.AuxInt != j-16 || w != w0.Args[0] || !(x.Uses == 1 && clobber(x)) {
 			break
 		}
-		if w0.AuxInt != j-16 {
-			break
-		}
-		if w != w0.Args[0] {
-			break
-		}
-		if !(x.Uses == 1 && clobber(x)) {
-			break
-		}
 		v.reset(OpAMD64MOVLstoreidx1)
 		v.AuxInt = i - 2
 		v.Aux = s
@@ -24414,7 +22289,6 @@
 }
 func rewriteValueAMD64_OpAMD64MULL_0(v *Value) bool {
 	// match: (MULL x (MOVLconst [c]))
-	// cond:
 	// result: (MULLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -24430,7 +22304,6 @@
 		return true
 	}
 	// match: (MULL (MOVLconst [c]) x)
-	// cond:
 	// result: (MULLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -24449,7 +22322,6 @@
 func rewriteValueAMD64_OpAMD64MULLconst_0(v *Value) bool {
 	b := v.Block
 	// match: (MULLconst [c] (MULLconst [d] x))
-	// cond:
 	// result: (MULLconst [int64(int32(c * d))] x)
 	for {
 		c := v.AuxInt
@@ -24465,7 +22337,6 @@
 		return true
 	}
 	// match: (MULLconst [-9] x)
-	// cond:
 	// result: (NEGL (LEAL8 <v.Type> x x))
 	for {
 		if v.AuxInt != -9 {
@@ -24480,7 +22351,6 @@
 		return true
 	}
 	// match: (MULLconst [-5] x)
-	// cond:
 	// result: (NEGL (LEAL4 <v.Type> x x))
 	for {
 		if v.AuxInt != -5 {
@@ -24495,7 +22365,6 @@
 		return true
 	}
 	// match: (MULLconst [-3] x)
-	// cond:
 	// result: (NEGL (LEAL2 <v.Type> x x))
 	for {
 		if v.AuxInt != -3 {
@@ -24510,7 +22379,6 @@
 		return true
 	}
 	// match: (MULLconst [-1] x)
-	// cond:
 	// result: (NEGL x)
 	for {
 		if v.AuxInt != -1 {
@@ -24522,7 +22390,6 @@
 		return true
 	}
 	// match: (MULLconst [ 0] _)
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		if v.AuxInt != 0 {
@@ -24533,7 +22400,6 @@
 		return true
 	}
 	// match: (MULLconst [ 1] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 1 {
@@ -24546,7 +22412,6 @@
 		return true
 	}
 	// match: (MULLconst [ 3] x)
-	// cond:
 	// result: (LEAL2 x x)
 	for {
 		if v.AuxInt != 3 {
@@ -24559,7 +22424,6 @@
 		return true
 	}
 	// match: (MULLconst [ 5] x)
-	// cond:
 	// result: (LEAL4 x x)
 	for {
 		if v.AuxInt != 5 {
@@ -24572,7 +22436,6 @@
 		return true
 	}
 	// match: (MULLconst [ 7] x)
-	// cond:
 	// result: (LEAL2 x (LEAL2 <v.Type> x x))
 	for {
 		if v.AuxInt != 7 {
@@ -24592,7 +22455,6 @@
 func rewriteValueAMD64_OpAMD64MULLconst_10(v *Value) bool {
 	b := v.Block
 	// match: (MULLconst [ 9] x)
-	// cond:
 	// result: (LEAL8 x x)
 	for {
 		if v.AuxInt != 9 {
@@ -24605,7 +22467,6 @@
 		return true
 	}
 	// match: (MULLconst [11] x)
-	// cond:
 	// result: (LEAL2 x (LEAL4 <v.Type> x x))
 	for {
 		if v.AuxInt != 11 {
@@ -24621,7 +22482,6 @@
 		return true
 	}
 	// match: (MULLconst [13] x)
-	// cond:
 	// result: (LEAL4 x (LEAL2 <v.Type> x x))
 	for {
 		if v.AuxInt != 13 {
@@ -24637,7 +22497,6 @@
 		return true
 	}
 	// match: (MULLconst [19] x)
-	// cond:
 	// result: (LEAL2 x (LEAL8 <v.Type> x x))
 	for {
 		if v.AuxInt != 19 {
@@ -24653,7 +22512,6 @@
 		return true
 	}
 	// match: (MULLconst [21] x)
-	// cond:
 	// result: (LEAL4 x (LEAL4 <v.Type> x x))
 	for {
 		if v.AuxInt != 21 {
@@ -24669,7 +22527,6 @@
 		return true
 	}
 	// match: (MULLconst [25] x)
-	// cond:
 	// result: (LEAL8 x (LEAL2 <v.Type> x x))
 	for {
 		if v.AuxInt != 25 {
@@ -24685,7 +22542,6 @@
 		return true
 	}
 	// match: (MULLconst [27] x)
-	// cond:
 	// result: (LEAL8 (LEAL2 <v.Type> x x) (LEAL2 <v.Type> x x))
 	for {
 		if v.AuxInt != 27 {
@@ -24704,7 +22560,6 @@
 		return true
 	}
 	// match: (MULLconst [37] x)
-	// cond:
 	// result: (LEAL4 x (LEAL8 <v.Type> x x))
 	for {
 		if v.AuxInt != 37 {
@@ -24720,7 +22575,6 @@
 		return true
 	}
 	// match: (MULLconst [41] x)
-	// cond:
 	// result: (LEAL8 x (LEAL4 <v.Type> x x))
 	for {
 		if v.AuxInt != 41 {
@@ -24736,7 +22590,6 @@
 		return true
 	}
 	// match: (MULLconst [45] x)
-	// cond:
 	// result: (LEAL8 (LEAL4 <v.Type> x x) (LEAL4 <v.Type> x x))
 	for {
 		if v.AuxInt != 45 {
@@ -24759,7 +22612,6 @@
 func rewriteValueAMD64_OpAMD64MULLconst_20(v *Value) bool {
 	b := v.Block
 	// match: (MULLconst [73] x)
-	// cond:
 	// result: (LEAL8 x (LEAL8 <v.Type> x x))
 	for {
 		if v.AuxInt != 73 {
@@ -24775,7 +22627,6 @@
 		return true
 	}
 	// match: (MULLconst [81] x)
-	// cond:
 	// result: (LEAL8 (LEAL8 <v.Type> x x) (LEAL8 <v.Type> x x))
 	for {
 		if v.AuxInt != 81 {
@@ -24933,7 +22784,6 @@
 }
 func rewriteValueAMD64_OpAMD64MULLconst_30(v *Value) bool {
 	// match: (MULLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [int64(int32(c*d))])
 	for {
 		c := v.AuxInt
@@ -25010,7 +22860,6 @@
 		return true
 	}
 	// match: (MULQconst [-9] x)
-	// cond:
 	// result: (NEGQ (LEAQ8 <v.Type> x x))
 	for {
 		if v.AuxInt != -9 {
@@ -25025,7 +22874,6 @@
 		return true
 	}
 	// match: (MULQconst [-5] x)
-	// cond:
 	// result: (NEGQ (LEAQ4 <v.Type> x x))
 	for {
 		if v.AuxInt != -5 {
@@ -25040,7 +22888,6 @@
 		return true
 	}
 	// match: (MULQconst [-3] x)
-	// cond:
 	// result: (NEGQ (LEAQ2 <v.Type> x x))
 	for {
 		if v.AuxInt != -3 {
@@ -25055,7 +22902,6 @@
 		return true
 	}
 	// match: (MULQconst [-1] x)
-	// cond:
 	// result: (NEGQ x)
 	for {
 		if v.AuxInt != -1 {
@@ -25067,7 +22913,6 @@
 		return true
 	}
 	// match: (MULQconst [ 0] _)
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		if v.AuxInt != 0 {
@@ -25078,7 +22923,6 @@
 		return true
 	}
 	// match: (MULQconst [ 1] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 1 {
@@ -25091,7 +22935,6 @@
 		return true
 	}
 	// match: (MULQconst [ 3] x)
-	// cond:
 	// result: (LEAQ2 x x)
 	for {
 		if v.AuxInt != 3 {
@@ -25104,7 +22947,6 @@
 		return true
 	}
 	// match: (MULQconst [ 5] x)
-	// cond:
 	// result: (LEAQ4 x x)
 	for {
 		if v.AuxInt != 5 {
@@ -25117,7 +22959,6 @@
 		return true
 	}
 	// match: (MULQconst [ 7] x)
-	// cond:
 	// result: (LEAQ2 x (LEAQ2 <v.Type> x x))
 	for {
 		if v.AuxInt != 7 {
@@ -25137,7 +22978,6 @@
 func rewriteValueAMD64_OpAMD64MULQconst_10(v *Value) bool {
 	b := v.Block
 	// match: (MULQconst [ 9] x)
-	// cond:
 	// result: (LEAQ8 x x)
 	for {
 		if v.AuxInt != 9 {
@@ -25150,7 +22990,6 @@
 		return true
 	}
 	// match: (MULQconst [11] x)
-	// cond:
 	// result: (LEAQ2 x (LEAQ4 <v.Type> x x))
 	for {
 		if v.AuxInt != 11 {
@@ -25166,7 +23005,6 @@
 		return true
 	}
 	// match: (MULQconst [13] x)
-	// cond:
 	// result: (LEAQ4 x (LEAQ2 <v.Type> x x))
 	for {
 		if v.AuxInt != 13 {
@@ -25182,7 +23020,6 @@
 		return true
 	}
 	// match: (MULQconst [19] x)
-	// cond:
 	// result: (LEAQ2 x (LEAQ8 <v.Type> x x))
 	for {
 		if v.AuxInt != 19 {
@@ -25198,7 +23035,6 @@
 		return true
 	}
 	// match: (MULQconst [21] x)
-	// cond:
 	// result: (LEAQ4 x (LEAQ4 <v.Type> x x))
 	for {
 		if v.AuxInt != 21 {
@@ -25214,7 +23050,6 @@
 		return true
 	}
 	// match: (MULQconst [25] x)
-	// cond:
 	// result: (LEAQ8 x (LEAQ2 <v.Type> x x))
 	for {
 		if v.AuxInt != 25 {
@@ -25230,7 +23065,6 @@
 		return true
 	}
 	// match: (MULQconst [27] x)
-	// cond:
 	// result: (LEAQ8 (LEAQ2 <v.Type> x x) (LEAQ2 <v.Type> x x))
 	for {
 		if v.AuxInt != 27 {
@@ -25249,7 +23083,6 @@
 		return true
 	}
 	// match: (MULQconst [37] x)
-	// cond:
 	// result: (LEAQ4 x (LEAQ8 <v.Type> x x))
 	for {
 		if v.AuxInt != 37 {
@@ -25265,7 +23098,6 @@
 		return true
 	}
 	// match: (MULQconst [41] x)
-	// cond:
 	// result: (LEAQ8 x (LEAQ4 <v.Type> x x))
 	for {
 		if v.AuxInt != 41 {
@@ -25281,7 +23113,6 @@
 		return true
 	}
 	// match: (MULQconst [45] x)
-	// cond:
 	// result: (LEAQ8 (LEAQ4 <v.Type> x x) (LEAQ4 <v.Type> x x))
 	for {
 		if v.AuxInt != 45 {
@@ -25304,7 +23135,6 @@
 func rewriteValueAMD64_OpAMD64MULQconst_20(v *Value) bool {
 	b := v.Block
 	// match: (MULQconst [73] x)
-	// cond:
 	// result: (LEAQ8 x (LEAQ8 <v.Type> x x))
 	for {
 		if v.AuxInt != 73 {
@@ -25320,7 +23150,6 @@
 		return true
 	}
 	// match: (MULQconst [81] x)
-	// cond:
 	// result: (LEAQ8 (LEAQ8 <v.Type> x x) (LEAQ8 <v.Type> x x))
 	for {
 		if v.AuxInt != 81 {
@@ -25478,7 +23307,6 @@
 }
 func rewriteValueAMD64_OpAMD64MULQconst_30(v *Value) bool {
 	// match: (MULQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [c*d])
 	for {
 		c := v.AuxInt
@@ -25618,7 +23446,6 @@
 		return true
 	}
 	// match: (MULSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
-	// cond:
 	// result: (MULSD x (MOVQi2f y))
 	for {
 		off := v.AuxInt
@@ -25627,15 +23454,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVQstore {
+		if v_2.Op != OpAMD64MOVQstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -25757,7 +23578,6 @@
 		return true
 	}
 	// match: (MULSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
-	// cond:
 	// result: (MULSS x (MOVLi2f y))
 	for {
 		off := v.AuxInt
@@ -25766,15 +23586,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVLstore {
+		if v_2.Op != OpAMD64MOVLstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -25791,7 +23605,6 @@
 }
 func rewriteValueAMD64_OpAMD64NEGL_0(v *Value) bool {
 	// match: (NEGL (NEGL x))
-	// cond:
 	// result: x
 	for {
 		v_0 := v.Args[0]
@@ -25823,7 +23636,6 @@
 		return true
 	}
 	// match: (NEGL (MOVLconst [c]))
-	// cond:
 	// result: (MOVLconst [int64(int32(-c))])
 	for {
 		v_0 := v.Args[0]
@@ -25839,7 +23651,6 @@
 }
 func rewriteValueAMD64_OpAMD64NEGQ_0(v *Value) bool {
 	// match: (NEGQ (NEGQ x))
-	// cond:
 	// result: x
 	for {
 		v_0 := v.Args[0]
@@ -25871,7 +23682,6 @@
 		return true
 	}
 	// match: (NEGQ (MOVQconst [c]))
-	// cond:
 	// result: (MOVQconst [-c])
 	for {
 		v_0 := v.Args[0]
@@ -25909,7 +23719,6 @@
 }
 func rewriteValueAMD64_OpAMD64NOTL_0(v *Value) bool {
 	// match: (NOTL (MOVLconst [c]))
-	// cond:
 	// result: (MOVLconst [^c])
 	for {
 		v_0 := v.Args[0]
@@ -25925,7 +23734,6 @@
 }
 func rewriteValueAMD64_OpAMD64NOTQ_0(v *Value) bool {
 	// match: (NOTQ (MOVQconst [c]))
-	// cond:
 	// result: (MOVQconst [^c])
 	for {
 		v_0 := v.Args[0]
@@ -25953,15 +23761,9 @@
 		}
 		y := v_0.Args[1]
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64MOVLconst {
+		if v_0_0.Op != OpAMD64MOVLconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTSL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -25979,15 +23781,9 @@
 		}
 		y := v_1.Args[1]
 		v_1_0 := v_1.Args[0]
-		if v_1_0.Op != OpAMD64MOVLconst {
+		if v_1_0.Op != OpAMD64MOVLconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTSL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -26031,7 +23827,6 @@
 		return true
 	}
 	// match: (ORL x (MOVLconst [c]))
-	// cond:
 	// result: (ORLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -26047,7 +23842,6 @@
 		return true
 	}
 	// match: (ORL (MOVLconst [c]) x)
-	// cond:
 	// result: (ORLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -26077,12 +23871,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -26104,12 +23895,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -26132,12 +23920,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -26160,12 +23945,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -26191,12 +23973,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -26219,19 +23998,15 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (ORL (SHLL x y) (ANDL (SHRL x (NEGQ y)) (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32]))))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26255,51 +24030,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGQ {
+		if v_1_0_1.Op != OpAMD64NEGQ || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 32 {
 			break
 		}
-		if v_1_1_0.AuxInt != 32 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 31 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHLL x y) (ANDL (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32])) (SHRL x (NEGQ y))))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26319,33 +24078,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 32 {
 			break
 		}
-		if v_1_0_0.AuxInt != 32 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 31 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRL {
 			break
@@ -26355,19 +24102,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGQ {
+		if v_1_1_1.Op != OpAMD64NEGQ || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SHRL x (NEGQ y)) (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32]))) (SHLL x y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26392,51 +24135,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 32 {
 			break
 		}
-		if v_0_1_0.AuxInt != 32 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 31 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32])) (SHRL x (NEGQ y))) (SHLL x y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26450,30 +24177,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 32 {
 			break
 		}
-		if v_0_0_0.AuxInt != 32 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 31 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRL {
@@ -26482,30 +24200,23 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGQ {
+		if v_0_1_1.Op != OpAMD64NEGQ || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHLL x y) (ANDL (SHRL x (NEGL y)) (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32]))))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26529,51 +24240,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGL {
+		if v_1_0_1.Op != OpAMD64NEGL || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 32 {
 			break
 		}
-		if v_1_1_0.AuxInt != 32 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 31 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHLL x y) (ANDL (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32])) (SHRL x (NEGL y))))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26593,33 +24288,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 32 {
 			break
 		}
-		if v_1_0_0.AuxInt != 32 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 31 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRL {
 			break
@@ -26629,19 +24312,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGL {
+		if v_1_1_1.Op != OpAMD64NEGL || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SHRL x (NEGL y)) (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32]))) (SHLL x y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26666,51 +24345,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 32 {
 			break
 		}
-		if v_0_1_0.AuxInt != 32 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 31 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32])) (SHRL x (NEGL y))) (SHLL x y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -26724,30 +24387,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 32 {
 			break
 		}
-		if v_0_0_0.AuxInt != 32 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 31 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRL {
@@ -26756,23 +24410,17 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGL {
+		if v_0_1_1.Op != OpAMD64NEGL || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -26782,7 +24430,6 @@
 }
 func rewriteValueAMD64_OpAMD64ORL_20(v *Value) bool {
 	// match: (ORL (SHRL x y) (ANDL (SHLL x (NEGQ y)) (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32]))))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -26806,51 +24453,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGQ {
+		if v_1_0_1.Op != OpAMD64NEGQ || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 32 {
 			break
 		}
-		if v_1_1_0.AuxInt != 32 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 31 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHRL x y) (ANDL (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32])) (SHLL x (NEGQ y))))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -26870,33 +24501,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 32 {
 			break
 		}
-		if v_1_0_0.AuxInt != 32 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 31 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHLL {
 			break
@@ -26906,19 +24525,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGQ {
+		if v_1_1_1.Op != OpAMD64NEGQ || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SHLL x (NEGQ y)) (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32]))) (SHRL x y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -26943,51 +24558,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 32 {
 			break
 		}
-		if v_0_1_0.AuxInt != 32 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 31 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SBBLcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [31]) [-32])) [32])) (SHLL x (NEGQ y))) (SHRL x y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -27001,30 +24600,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 32 {
 			break
 		}
-		if v_0_0_0.AuxInt != 32 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 31 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHLL {
@@ -27033,30 +24623,23 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGQ {
+		if v_0_1_1.Op != OpAMD64NEGQ || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHRL x y) (ANDL (SHLL x (NEGL y)) (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32]))))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -27080,51 +24663,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGL {
+		if v_1_0_1.Op != OpAMD64NEGL || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 32 {
 			break
 		}
-		if v_1_1_0.AuxInt != 32 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 31 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (SHRL x y) (ANDL (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32])) (SHLL x (NEGL y))))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -27144,33 +24711,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 32 {
 			break
 		}
-		if v_1_0_0.AuxInt != 32 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 31 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHLL {
 			break
@@ -27180,19 +24735,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGL {
+		if v_1_1_1.Op != OpAMD64NEGL || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SHLL x (NEGL y)) (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32]))) (SHRL x y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -27217,51 +24768,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 32 {
 			break
 		}
-		if v_0_1_0.AuxInt != 32 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 31 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 31 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL (ANDL (SBBLcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [31]) [-32])) [32])) (SHLL x (NEGL y))) (SHRL x y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -27275,30 +24810,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 32 {
 			break
 		}
-		if v_0_0_0.AuxInt != 32 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -32 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -32 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 31 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 31 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHLL {
@@ -27307,23 +24833,17 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGL {
+		if v_0_1_1.Op != OpAMD64NEGL || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRL {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27341,12 +24861,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -27366,57 +24883,33 @@
 			break
 		}
 		v_1_0_1_0 := v_1_0_1.Args[0]
-		if v_1_0_1_0.Op != OpAMD64ADDQconst {
+		if v_1_0_1_0.Op != OpAMD64ADDQconst || v_1_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_0_1_0_0 := v_1_0_1_0.Args[0]
-		if v_1_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_1_0_0.Op != OpAMD64ANDQconst || v_1_0_1_0_0.AuxInt != 15 || y != v_1_0_1_0_0.Args[0] {
 			break
 		}
-		if v_1_0_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_0_1_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 16 {
 			break
 		}
-		if v_1_1_0.AuxInt != 16 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 15 || y != v_1_1_0_0_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27434,12 +24927,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -27451,33 +24941,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 16 {
 			break
 		}
-		if v_1_0_0.AuxInt != 16 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 15 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRW {
 			break
@@ -27491,25 +24969,13 @@
 			break
 		}
 		v_1_1_1_0 := v_1_1_1.Args[0]
-		if v_1_1_1_0.Op != OpAMD64ADDQconst {
+		if v_1_1_1_0.Op != OpAMD64ADDQconst || v_1_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_1_0_0 := v_1_1_1_0.Args[0]
-		if v_1_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_1_0_0.Op != OpAMD64ANDQconst || v_1_1_1_0_0.AuxInt != 15 || y != v_1_1_1_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27539,52 +25005,34 @@
 			break
 		}
 		v_0_0_1_0 := v_0_0_1.Args[0]
-		if v_0_0_1_0.Op != OpAMD64ADDQconst {
+		if v_0_0_1_0.Op != OpAMD64ADDQconst || v_0_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_0_1_0_0 := v_0_0_1_0.Args[0]
-		if v_0_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_1_0_0.Op != OpAMD64ANDQconst || v_0_0_1_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_0_1_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_0_1_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 16 {
 			break
 		}
-		if v_0_1_0.AuxInt != 16 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 15 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -27594,18 +25042,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27626,30 +25065,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 16 {
 			break
 		}
-		if v_0_0_0.AuxInt != 16 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRW {
@@ -27662,22 +25092,13 @@
 			break
 		}
 		v_0_1_1_0 := v_0_1_1.Args[0]
-		if v_0_1_1_0.Op != OpAMD64ADDQconst {
+		if v_0_1_1_0.Op != OpAMD64ADDQconst || v_0_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_1_0_0 := v_0_1_1_0.Args[0]
-		if v_0_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_1_0_0.Op != OpAMD64ANDQconst || v_0_1_1_0_0.AuxInt != 15 || y != v_0_1_1_0_0.Args[0] {
 			break
 		}
-		if v_0_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_0_1_1_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -27687,18 +25108,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27716,12 +25128,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -27741,57 +25150,33 @@
 			break
 		}
 		v_1_0_1_0 := v_1_0_1.Args[0]
-		if v_1_0_1_0.Op != OpAMD64ADDLconst {
+		if v_1_0_1_0.Op != OpAMD64ADDLconst || v_1_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_0_1_0_0 := v_1_0_1_0.Args[0]
-		if v_1_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_1_0_0.Op != OpAMD64ANDLconst || v_1_0_1_0_0.AuxInt != 15 || y != v_1_0_1_0_0.Args[0] {
 			break
 		}
-		if v_1_0_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_0_1_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 16 {
 			break
 		}
-		if v_1_1_0.AuxInt != 16 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 15 || y != v_1_1_0_0_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27809,12 +25194,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -27826,33 +25208,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 16 {
 			break
 		}
-		if v_1_0_0.AuxInt != 16 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 15 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRW {
 			break
@@ -27866,25 +25236,13 @@
 			break
 		}
 		v_1_1_1_0 := v_1_1_1.Args[0]
-		if v_1_1_1_0.Op != OpAMD64ADDLconst {
+		if v_1_1_1_0.Op != OpAMD64ADDLconst || v_1_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_1_0_0 := v_1_1_1_0.Args[0]
-		if v_1_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_1_0_0.Op != OpAMD64ANDLconst || v_1_1_1_0_0.AuxInt != 15 || y != v_1_1_1_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27911,52 +25269,34 @@
 			break
 		}
 		v_0_0_1_0 := v_0_0_1.Args[0]
-		if v_0_0_1_0.Op != OpAMD64ADDLconst {
+		if v_0_0_1_0.Op != OpAMD64ADDLconst || v_0_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_0_1_0_0 := v_0_0_1_0.Args[0]
-		if v_0_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_1_0_0.Op != OpAMD64ANDLconst || v_0_0_1_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_0_1_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_0_1_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 16 {
 			break
 		}
-		if v_0_1_0.AuxInt != 16 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 15 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -27966,18 +25306,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -27998,30 +25329,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 16 {
 			break
 		}
-		if v_0_0_0.AuxInt != 16 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -16 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -16 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRW {
@@ -28034,22 +25356,13 @@
 			break
 		}
 		v_0_1_1_0 := v_0_1_1.Args[0]
-		if v_0_1_1_0.Op != OpAMD64ADDLconst {
+		if v_0_1_1_0.Op != OpAMD64ADDLconst || v_0_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_1_0_0 := v_0_1_1_0.Args[0]
-		if v_0_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_1_0_0.Op != OpAMD64ANDLconst || v_0_1_1_0_0.AuxInt != 15 || y != v_0_1_1_0_0.Args[0] {
 			break
 		}
-		if v_0_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_0_1_1_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -28059,18 +25372,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28088,12 +25392,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
@@ -28108,25 +25409,13 @@
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0.Op != OpAMD64ADDQconst || v_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
-		if v_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0.AuxInt != 15 || y != v_1_1_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64RORW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28148,19 +25437,13 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0.Op != OpAMD64ADDQconst || v_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
-		if v_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_1_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_1_0_0.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRW {
@@ -28171,18 +25454,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64RORW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28200,12 +25474,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 15 {
 			break
 		}
-		if v_0_1.AuxInt != 15 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
@@ -28220,25 +25491,13 @@
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0.Op != OpAMD64ADDLconst || v_1_1_0.AuxInt != -16 {
 			break
 		}
-		if v_1_1_0.AuxInt != -16 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
-		if v_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0.AuxInt != 15 || y != v_1_1_0_0.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1_0_0.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64RORW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28260,19 +25519,13 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0.Op != OpAMD64ADDLconst || v_0_1_0.AuxInt != -16 {
 			break
 		}
-		if v_0_1_0.AuxInt != -16 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
-		if v_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0.AuxInt != 15 {
 			break
 		}
-		if v_0_1_0_0.AuxInt != 15 {
-			break
-		}
 		y := v_0_1_0_0.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRW {
@@ -28283,18 +25536,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 15 || y != v_1_1.Args[0] || !(v.Type.Size() == 2) {
 			break
 		}
-		if v_1_1.AuxInt != 15 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64RORW)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28315,12 +25559,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -28340,57 +25581,33 @@
 			break
 		}
 		v_1_0_1_0 := v_1_0_1.Args[0]
-		if v_1_0_1_0.Op != OpAMD64ADDQconst {
+		if v_1_0_1_0.Op != OpAMD64ADDQconst || v_1_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_0_1_0_0 := v_1_0_1_0.Args[0]
-		if v_1_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_1_0_0.Op != OpAMD64ANDQconst || v_1_0_1_0_0.AuxInt != 7 || y != v_1_0_1_0_0.Args[0] {
 			break
 		}
-		if v_1_0_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_0_1_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 8 {
 			break
 		}
-		if v_1_1_0.AuxInt != 8 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 7 || y != v_1_1_0_0_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28408,12 +25625,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -28425,33 +25639,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 8 {
 			break
 		}
-		if v_1_0_0.AuxInt != 8 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 7 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRB {
 			break
@@ -28465,25 +25667,13 @@
 			break
 		}
 		v_1_1_1_0 := v_1_1_1.Args[0]
-		if v_1_1_1_0.Op != OpAMD64ADDQconst {
+		if v_1_1_1_0.Op != OpAMD64ADDQconst || v_1_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_1_0_0 := v_1_1_1_0.Args[0]
-		if v_1_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_1_0_0.Op != OpAMD64ANDQconst || v_1_1_1_0_0.AuxInt != 7 || y != v_1_1_1_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28510,52 +25700,34 @@
 			break
 		}
 		v_0_0_1_0 := v_0_0_1.Args[0]
-		if v_0_0_1_0.Op != OpAMD64ADDQconst {
+		if v_0_0_1_0.Op != OpAMD64ADDQconst || v_0_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_0_1_0_0 := v_0_0_1_0.Args[0]
-		if v_0_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_1_0_0.Op != OpAMD64ANDQconst || v_0_0_1_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_0_1_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_0_1_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 8 {
 			break
 		}
-		if v_0_1_0.AuxInt != 8 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 7 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -28565,18 +25737,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28597,30 +25760,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 8 {
 			break
 		}
-		if v_0_0_0.AuxInt != 8 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRB {
@@ -28633,22 +25787,13 @@
 			break
 		}
 		v_0_1_1_0 := v_0_1_1.Args[0]
-		if v_0_1_1_0.Op != OpAMD64ADDQconst {
+		if v_0_1_1_0.Op != OpAMD64ADDQconst || v_0_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_1_0_0 := v_0_1_1_0.Args[0]
-		if v_0_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_1_0_0.Op != OpAMD64ANDQconst || v_0_1_1_0_0.AuxInt != 7 || y != v_0_1_1_0_0.Args[0] {
 			break
 		}
-		if v_0_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_0_1_1_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -28658,18 +25803,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28687,12 +25823,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -28712,57 +25845,33 @@
 			break
 		}
 		v_1_0_1_0 := v_1_0_1.Args[0]
-		if v_1_0_1_0.Op != OpAMD64ADDLconst {
+		if v_1_0_1_0.Op != OpAMD64ADDLconst || v_1_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_0_1_0_0 := v_1_0_1_0.Args[0]
-		if v_1_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_1_0_0.Op != OpAMD64ANDLconst || v_1_0_1_0_0.AuxInt != 7 || y != v_1_0_1_0_0.Args[0] {
 			break
 		}
-		if v_1_0_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_0_1_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 8 {
 			break
 		}
-		if v_1_1_0.AuxInt != 8 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 7 || y != v_1_1_0_0_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28780,12 +25889,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64ANDL {
@@ -28797,33 +25903,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 8 {
 			break
 		}
-		if v_1_0_0.AuxInt != 8 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 7 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRB {
 			break
@@ -28837,25 +25931,13 @@
 			break
 		}
 		v_1_1_1_0 := v_1_1_1.Args[0]
-		if v_1_1_1_0.Op != OpAMD64ADDLconst {
+		if v_1_1_1_0.Op != OpAMD64ADDLconst || v_1_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_1_0_0 := v_1_1_1_0.Args[0]
-		if v_1_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_1_0_0.Op != OpAMD64ANDLconst || v_1_1_1_0_0.AuxInt != 7 || y != v_1_1_1_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28882,52 +25964,34 @@
 			break
 		}
 		v_0_0_1_0 := v_0_0_1.Args[0]
-		if v_0_0_1_0.Op != OpAMD64ADDLconst {
+		if v_0_0_1_0.Op != OpAMD64ADDLconst || v_0_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_0_1_0_0 := v_0_0_1_0.Args[0]
-		if v_0_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_1_0_0.Op != OpAMD64ANDLconst || v_0_0_1_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_0_1_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_0_1_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SBBLcarrymask {
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 8 {
 			break
 		}
-		if v_0_1_0.AuxInt != 8 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 7 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -28937,18 +26001,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -28969,30 +26024,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 8 {
 			break
 		}
-		if v_0_0_0.AuxInt != 8 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -8 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -8 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRB {
@@ -29005,22 +26051,13 @@
 			break
 		}
 		v_0_1_1_0 := v_0_1_1.Args[0]
-		if v_0_1_1_0.Op != OpAMD64ADDLconst {
+		if v_0_1_1_0.Op != OpAMD64ADDLconst || v_0_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_1_0_0 := v_0_1_1_0.Args[0]
-		if v_0_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_1_0_0.Op != OpAMD64ANDLconst || v_0_1_1_0_0.AuxInt != 7 || y != v_0_1_1_0_0.Args[0] {
 			break
 		}
-		if v_0_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_0_1_1_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
 			break
@@ -29030,18 +26067,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -29059,12 +26087,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDQconst {
+		if v_0_1.Op != OpAMD64ANDQconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
@@ -29079,25 +26104,13 @@
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0.Op != OpAMD64ADDQconst || v_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
-		if v_1_1_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0.AuxInt != 7 || y != v_1_1_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64RORB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -29119,19 +26132,13 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0.Op != OpAMD64ADDQconst || v_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
-		if v_0_1_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_1_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_1_0_0.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRB {
@@ -29142,18 +26149,9 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDQconst {
+		if v_1_1.Op != OpAMD64ANDQconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64RORB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -29176,12 +26174,9 @@
 		_ = v_0.Args[1]
 		x := v_0.Args[0]
 		v_0_1 := v_0.Args[1]
-		if v_0_1.Op != OpAMD64ANDLconst {
+		if v_0_1.Op != OpAMD64ANDLconst || v_0_1.AuxInt != 7 {
 			break
 		}
-		if v_0_1.AuxInt != 7 {
-			break
-		}
 		y := v_0_1.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLL {
@@ -29196,25 +26191,13 @@
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0.Op != OpAMD64ADDLconst || v_1_1_0.AuxInt != -8 {
 			break
 		}
-		if v_1_1_0.AuxInt != -8 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
-		if v_1_1_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0.AuxInt != 7 || y != v_1_1_0_0.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1_0_0.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1_0_0.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64RORB)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -29236,19 +26219,13 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0.Op != OpAMD64ADDLconst || v_0_1_0.AuxInt != -8 {
 			break
 		}
-		if v_0_1_0.AuxInt != -8 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
-		if v_0_1_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0.AuxInt != 7 {
 			break
 		}
-		if v_0_1_0_0.AuxInt != 7 {
-			break
-		}
 		y := v_0_1_0_0.Args[0]
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRB {
@@ -29259,25 +26236,15 @@
 			break
 		}
 		v_1_1 := v_1.Args[1]
-		if v_1_1.Op != OpAMD64ANDLconst {
+		if v_1_1.Op != OpAMD64ANDLconst || v_1_1.AuxInt != 7 || y != v_1_1.Args[0] || !(v.Type.Size() == 1) {
 			break
 		}
-		if v_1_1.AuxInt != 7 {
-			break
-		}
-		if y != v_1_1.Args[0] {
-			break
-		}
-		if !(v.Type.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64RORB)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORL x x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[1]
@@ -29303,12 +26270,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBload {
 			break
@@ -29318,15 +26282,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64MOVWload, typ.UInt16)
 		v.reset(OpCopy)
@@ -29343,12 +26301,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBload {
 			break
@@ -29366,15 +26321,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64MOVWload, typ.UInt16)
 		v.reset(OpCopy)
@@ -29399,12 +26348,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -29414,15 +26360,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64MOVLload, typ.UInt32)
 		v.reset(OpCopy)
@@ -29439,12 +26379,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -29462,15 +26399,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64MOVLload, typ.UInt32)
 		v.reset(OpCopy)
@@ -29518,15 +26449,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -29581,15 +26506,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -29643,15 +26562,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -29711,15 +26624,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -29751,12 +26658,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -29766,18 +26670,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -29804,12 +26699,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -29819,18 +26711,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -29857,12 +26740,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -29872,18 +26752,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -29910,12 +26781,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -29925,18 +26793,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -29954,12 +26813,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -29978,18 +26834,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -30007,12 +26854,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -30031,18 +26875,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -30060,12 +26895,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -30084,18 +26916,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -30113,12 +26936,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -30137,18 +26957,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -30175,12 +26986,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30190,18 +26998,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30233,12 +27032,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30248,18 +27044,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30286,12 +27073,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30301,18 +27085,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30339,12 +27114,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30354,18 +27126,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30383,12 +27146,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30407,18 +27167,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30436,12 +27187,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30460,18 +27208,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30489,12 +27228,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30513,18 +27249,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30542,12 +27269,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -30566,18 +27290,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -30627,18 +27342,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -30694,18 +27400,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -30761,18 +27458,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -30833,18 +27521,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -30901,18 +27580,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -30969,18 +27639,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31037,18 +27698,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31105,18 +27757,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31172,18 +27815,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31239,18 +27873,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31307,18 +27932,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31375,18 +27991,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31442,18 +28049,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31514,18 +28112,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31582,18 +28171,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31650,18 +28230,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -31693,12 +28264,9 @@
 		mem := x1.Args[1]
 		p := x1.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBload {
 			break
@@ -31708,15 +28276,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -31736,12 +28298,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBload {
 			break
@@ -31759,15 +28318,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -31787,12 +28340,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -31802,19 +28352,13 @@
 		mem := x1.Args[1]
 		p := x1.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -31824,15 +28368,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -31851,19 +28389,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -31873,12 +28405,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -31888,15 +28417,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -31946,15 +28469,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -32012,15 +28529,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -32077,15 +28588,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -32148,15 +28653,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -32191,12 +28690,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32206,18 +28702,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32247,12 +28734,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32262,18 +28746,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32303,12 +28778,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32318,18 +28790,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32359,12 +28822,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32374,18 +28834,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32406,12 +28857,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32430,18 +28878,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32462,12 +28901,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32486,18 +28922,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32518,12 +28945,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32542,18 +28966,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32574,12 +28989,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -32598,18 +29010,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -32630,12 +29033,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32646,19 +29046,13 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32668,18 +29062,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -32704,12 +29089,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32720,19 +29102,13 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32742,18 +29118,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -32773,12 +29140,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32789,19 +29153,13 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32811,18 +29169,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -32842,12 +29191,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32858,19 +29204,13 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32880,18 +29220,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -32911,19 +29242,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32934,12 +29259,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -32949,18 +29271,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -32980,19 +29293,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33003,12 +29310,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33018,18 +29322,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -33049,19 +29344,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33072,12 +29361,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33087,18 +29373,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -33118,19 +29395,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLLconst {
+		if sh.Op != OpAMD64SHLLconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33141,12 +29412,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -33156,18 +29424,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -33219,18 +29478,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33289,18 +29539,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33359,18 +29600,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33434,18 +29666,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33505,18 +29728,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33576,18 +29790,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33647,18 +29852,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33718,18 +29914,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33788,18 +29975,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33858,18 +30036,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -33929,18 +30098,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34000,18 +30160,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34070,18 +30221,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34145,18 +30287,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34216,18 +30349,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34287,18 +30411,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORL, v.Type)
 		v.reset(OpCopy)
@@ -34388,7 +30503,6 @@
 		return true
 	}
 	// match: (ORLconst [c] (ORLconst [d] x))
-	// cond:
 	// result: (ORLconst [c | d] x)
 	for {
 		c := v.AuxInt
@@ -34404,7 +30518,6 @@
 		return true
 	}
 	// match: (ORLconst [c] (BTSLconst [d] x))
-	// cond:
 	// result: (ORLconst [c | 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -34446,7 +30559,6 @@
 		return true
 	}
 	// match: (ORLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [c|d])
 	for {
 		c := v.AuxInt
@@ -34566,7 +30678,6 @@
 		return true
 	}
 	// match: (ORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
-	// cond:
 	// result: ( ORL x (MOVLf2i y))
 	for {
 		off := v.AuxInt
@@ -34575,15 +30686,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSSstore {
+		if v_2.Op != OpAMD64MOVSSstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -34666,15 +30771,9 @@
 		}
 		y := v_0.Args[1]
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0.Op != OpAMD64MOVQconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTSQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -34692,15 +30791,9 @@
 		}
 		y := v_1.Args[1]
 		v_1_0 := v_1.Args[0]
-		if v_1_0.Op != OpAMD64MOVQconst {
+		if v_1_0.Op != OpAMD64MOVQconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTSQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -34796,12 +30889,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -34823,19 +30913,15 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (ORQ (SHLQ x y) (ANDQ (SHRQ x (NEGQ y)) (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64]))))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -34859,51 +30945,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGQ {
+		if v_1_0_1.Op != OpAMD64NEGQ || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBQcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 64 {
 			break
 		}
-		if v_1_1_0.AuxInt != 64 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 63 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHLQ x y) (ANDQ (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64])) (SHRQ x (NEGQ y))))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -34923,33 +30993,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 64 {
 			break
 		}
-		if v_1_0_0.AuxInt != 64 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 63 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRQ {
 			break
@@ -34959,12 +31017,9 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGQ {
+		if v_1_1_1.Op != OpAMD64NEGQ || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -34974,7 +31029,6 @@
 }
 func rewriteValueAMD64_OpAMD64ORQ_10(v *Value) bool {
 	// match: (ORQ (ANDQ (SHRQ x (NEGQ y)) (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64]))) (SHLQ x y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -34999,51 +31053,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 64 {
 			break
 		}
-		if v_0_1_0.AuxInt != 64 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 63 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64])) (SHRQ x (NEGQ y))) (SHLQ x y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -35057,30 +31095,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 64 {
 			break
 		}
-		if v_0_0_0.AuxInt != 64 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 63 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRQ {
@@ -35089,30 +31118,23 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGQ {
+		if v_0_1_1.Op != OpAMD64NEGQ || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHLQ x y) (ANDQ (SHRQ x (NEGL y)) (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64]))))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -35136,51 +31158,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGL {
+		if v_1_0_1.Op != OpAMD64NEGL || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBQcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 64 {
 			break
 		}
-		if v_1_1_0.AuxInt != 64 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 63 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHLQ x y) (ANDQ (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64])) (SHRQ x (NEGL y))))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -35200,33 +31206,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 64 {
 			break
 		}
-		if v_1_0_0.AuxInt != 64 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 63 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHRQ {
 			break
@@ -35236,19 +31230,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGL {
+		if v_1_1_1.Op != OpAMD64NEGL || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SHRQ x (NEGL y)) (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64]))) (SHLQ x y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -35273,51 +31263,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 64 {
 			break
 		}
-		if v_0_1_0.AuxInt != 64 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 63 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64])) (SHRQ x (NEGL y))) (SHLQ x y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -35331,30 +31305,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 64 {
 			break
 		}
-		if v_0_0_0.AuxInt != 64 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 63 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHRQ {
@@ -35363,30 +31328,23 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGL {
+		if v_0_1_1.Op != OpAMD64NEGL || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHLQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64ROLQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHRQ x y) (ANDQ (SHLQ x (NEGQ y)) (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64]))))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35410,51 +31368,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGQ {
+		if v_1_0_1.Op != OpAMD64NEGQ || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBQcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPQconst {
+		if v_1_1_0.Op != OpAMD64CMPQconst || v_1_1_0.AuxInt != 64 {
 			break
 		}
-		if v_1_1_0.AuxInt != 64 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDQconst || v_1_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDQconst || v_1_1_0_0_0_0.AuxInt != 63 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHRQ x y) (ANDQ (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64])) (SHLQ x (NEGQ y))))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35474,33 +31416,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPQconst {
+		if v_1_0_0.Op != OpAMD64CMPQconst || v_1_0_0.AuxInt != 64 {
 			break
 		}
-		if v_1_0_0.AuxInt != 64 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDQconst || v_1_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDQconst || v_1_0_0_0_0_0.AuxInt != 63 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHLQ {
 			break
@@ -35510,19 +31440,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGQ {
+		if v_1_1_1.Op != OpAMD64NEGQ || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SHLQ x (NEGQ y)) (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64]))) (SHRQ x y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35547,51 +31473,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPQconst {
+		if v_0_1_0.Op != OpAMD64CMPQconst || v_0_1_0.AuxInt != 64 {
 			break
 		}
-		if v_0_1_0.AuxInt != 64 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDQconst || v_0_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDQconst || v_0_1_0_0_0_0.AuxInt != 63 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SBBQcarrymask (CMPQconst (NEGQ (ADDQconst (ANDQconst y [63]) [-64])) [64])) (SHLQ x (NEGQ y))) (SHRQ x y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35605,30 +31515,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPQconst {
+		if v_0_0_0.Op != OpAMD64CMPQconst || v_0_0_0.AuxInt != 64 {
 			break
 		}
-		if v_0_0_0.AuxInt != 64 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGQ {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDQconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDQconst || v_0_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDQconst || v_0_0_0_0_0_0.AuxInt != 63 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHLQ {
@@ -35637,23 +31538,17 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGQ {
+		if v_0_1_1.Op != OpAMD64NEGQ || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -35665,7 +31560,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (ORQ (SHRQ x y) (ANDQ (SHLQ x (NEGL y)) (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64]))))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35689,51 +31583,35 @@
 			break
 		}
 		v_1_0_1 := v_1_0.Args[1]
-		if v_1_0_1.Op != OpAMD64NEGL {
+		if v_1_0_1.Op != OpAMD64NEGL || y != v_1_0_1.Args[0] {
 			break
 		}
-		if y != v_1_0_1.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SBBQcarrymask {
 			break
 		}
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64CMPLconst {
+		if v_1_1_0.Op != OpAMD64CMPLconst || v_1_1_0.AuxInt != 64 {
 			break
 		}
-		if v_1_1_0.AuxInt != 64 {
-			break
-		}
 		v_1_1_0_0 := v_1_1_0.Args[0]
 		if v_1_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_1_0_0_0 := v_1_1_0_0.Args[0]
-		if v_1_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_1_0_0_0.Op != OpAMD64ADDLconst || v_1_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_1_0_0_0_0 := v_1_1_0_0_0.Args[0]
-		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_1_0_0_0_0.Op != OpAMD64ANDLconst || v_1_1_0_0_0_0.AuxInt != 63 || y != v_1_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_1_0_0_0_0.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (SHRQ x y) (ANDQ (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64])) (SHLQ x (NEGL y))))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35753,33 +31631,21 @@
 			break
 		}
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64CMPLconst {
+		if v_1_0_0.Op != OpAMD64CMPLconst || v_1_0_0.AuxInt != 64 {
 			break
 		}
-		if v_1_0_0.AuxInt != 64 {
-			break
-		}
 		v_1_0_0_0 := v_1_0_0.Args[0]
 		if v_1_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_1_0_0_0_0 := v_1_0_0_0.Args[0]
-		if v_1_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_1_0_0_0_0.Op != OpAMD64ADDLconst || v_1_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_1_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_1_0_0_0_0_0 := v_1_0_0_0_0.Args[0]
-		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_1_0_0_0_0_0.Op != OpAMD64ANDLconst || v_1_0_0_0_0_0.AuxInt != 63 || y != v_1_0_0_0_0_0.Args[0] {
 			break
 		}
-		if v_1_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_1_0_0_0_0_0.Args[0] {
-			break
-		}
 		v_1_1 := v_1.Args[1]
 		if v_1_1.Op != OpAMD64SHLQ {
 			break
@@ -35789,19 +31655,15 @@
 			break
 		}
 		v_1_1_1 := v_1_1.Args[1]
-		if v_1_1_1.Op != OpAMD64NEGL {
+		if v_1_1_1.Op != OpAMD64NEGL || y != v_1_1_1.Args[0] {
 			break
 		}
-		if y != v_1_1_1.Args[0] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SHLQ x (NEGL y)) (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64]))) (SHRQ x y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35826,51 +31688,35 @@
 			break
 		}
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64CMPLconst {
+		if v_0_1_0.Op != OpAMD64CMPLconst || v_0_1_0.AuxInt != 64 {
 			break
 		}
-		if v_0_1_0.AuxInt != 64 {
-			break
-		}
 		v_0_1_0_0 := v_0_1_0.Args[0]
 		if v_0_1_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_1_0_0_0 := v_0_1_0_0.Args[0]
-		if v_0_1_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_1_0_0_0.Op != OpAMD64ADDLconst || v_0_1_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_1_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_1_0_0_0_0 := v_0_1_0_0_0.Args[0]
-		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_1_0_0_0_0.Op != OpAMD64ANDLconst || v_0_1_0_0_0_0.AuxInt != 63 || y != v_0_1_0_0_0_0.Args[0] {
 			break
 		}
-		if v_0_1_0_0_0_0.AuxInt != 63 {
-			break
-		}
-		if y != v_0_1_0_0_0_0.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ (ANDQ (SBBQcarrymask (CMPLconst (NEGL (ADDLconst (ANDLconst y [63]) [-64])) [64])) (SHLQ x (NEGL y))) (SHRQ x y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -35884,30 +31730,21 @@
 			break
 		}
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64CMPLconst {
+		if v_0_0_0.Op != OpAMD64CMPLconst || v_0_0_0.AuxInt != 64 {
 			break
 		}
-		if v_0_0_0.AuxInt != 64 {
-			break
-		}
 		v_0_0_0_0 := v_0_0_0.Args[0]
 		if v_0_0_0_0.Op != OpAMD64NEGL {
 			break
 		}
 		v_0_0_0_0_0 := v_0_0_0_0.Args[0]
-		if v_0_0_0_0_0.Op != OpAMD64ADDLconst {
+		if v_0_0_0_0_0.Op != OpAMD64ADDLconst || v_0_0_0_0_0.AuxInt != -64 {
 			break
 		}
-		if v_0_0_0_0_0.AuxInt != -64 {
-			break
-		}
 		v_0_0_0_0_0_0 := v_0_0_0_0_0.Args[0]
-		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst {
+		if v_0_0_0_0_0_0.Op != OpAMD64ANDLconst || v_0_0_0_0_0_0.AuxInt != 63 {
 			break
 		}
-		if v_0_0_0_0_0_0.AuxInt != 63 {
-			break
-		}
 		y := v_0_0_0_0_0_0.Args[0]
 		v_0_1 := v_0.Args[1]
 		if v_0_1.Op != OpAMD64SHLQ {
@@ -35916,30 +31753,23 @@
 		_ = v_0_1.Args[1]
 		x := v_0_1.Args[0]
 		v_0_1_1 := v_0_1.Args[1]
-		if v_0_1_1.Op != OpAMD64NEGL {
+		if v_0_1_1.Op != OpAMD64NEGL || y != v_0_1_1.Args[0] {
 			break
 		}
-		if y != v_0_1_1.Args[0] {
-			break
-		}
 		v_1 := v.Args[1]
 		if v_1.Op != OpAMD64SHRQ {
 			break
 		}
 		_ = v_1.Args[1]
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || y != v_1.Args[1] {
 			break
 		}
-		if y != v_1.Args[1] {
-			break
-		}
 		v.reset(OpAMD64RORQ)
 		v.AddArg(x)
 		v.AddArg(y)
 		return true
 	}
 	// match: (ORQ x x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[1]
@@ -35965,12 +31795,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBload {
 			break
@@ -35980,15 +31807,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64MOVWload, typ.UInt16)
 		v.reset(OpCopy)
@@ -36005,12 +31826,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBload {
 			break
@@ -36028,15 +31846,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64MOVWload, typ.UInt16)
 		v.reset(OpCopy)
@@ -36061,12 +31873,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -36076,15 +31885,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64MOVLload, typ.UInt32)
 		v.reset(OpCopy)
@@ -36101,12 +31904,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -36124,15 +31924,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64MOVLload, typ.UInt32)
 		v.reset(OpCopy)
@@ -36157,12 +31951,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLload {
 			break
@@ -36172,15 +31963,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64MOVQload, typ.UInt64)
 		v.reset(OpCopy)
@@ -36202,12 +31987,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLload {
 			break
@@ -36225,15 +32007,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64MOVQload, typ.UInt64)
 		v.reset(OpCopy)
@@ -36281,15 +32057,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36344,15 +32114,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36406,15 +32170,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36469,15 +32227,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36531,15 +32283,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36594,15 +32340,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36656,15 +32396,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36719,15 +32453,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -36759,12 +32487,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -36774,18 +32499,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -36817,12 +32533,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -36832,18 +32545,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -36870,12 +32574,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -36885,18 +32586,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -36923,12 +32615,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -36938,18 +32627,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -36967,12 +32647,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -36991,18 +32668,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -37020,12 +32688,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -37044,18 +32709,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -37073,12 +32729,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -37097,18 +32750,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -37126,12 +32770,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -37150,18 +32791,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, v.Type)
 		v.reset(OpCopy)
@@ -37188,12 +32820,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37203,18 +32832,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37241,12 +32861,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37256,18 +32873,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37294,12 +32902,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37309,18 +32914,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37352,12 +32948,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37367,18 +32960,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37396,12 +32980,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37420,18 +33001,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37449,12 +33021,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37473,18 +33042,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37502,12 +33062,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37526,18 +33083,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37555,12 +33103,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -37579,18 +33124,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
 		v.reset(OpCopy)
@@ -37617,12 +33153,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37632,18 +33165,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37670,12 +33194,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37685,18 +33206,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37723,12 +33235,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37738,18 +33247,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37776,12 +33276,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37791,18 +33288,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37820,12 +33308,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37844,18 +33329,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37878,12 +33354,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37902,18 +33375,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37931,12 +33395,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -37955,18 +33416,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -37984,12 +33436,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		x1 := sh.Args[0]
 		if x1.Op != OpAMD64MOVLloadidx1 {
 			break
@@ -38008,18 +33457,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
 		v.reset(OpCopy)
@@ -38069,18 +33509,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38136,18 +33567,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38203,18 +33625,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38270,18 +33683,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38338,18 +33742,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38406,18 +33801,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38474,18 +33860,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38547,18 +33924,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38614,18 +33982,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38681,18 +34040,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38749,18 +34099,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38817,18 +34158,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38884,18 +34216,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -38951,18 +34274,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39019,18 +34333,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39087,18 +34392,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0+8 && j0%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39154,18 +34450,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39226,18 +34513,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39293,18 +34571,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39360,18 +34629,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39428,18 +34688,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39496,18 +34747,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39564,18 +34806,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39632,18 +34865,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39699,18 +34923,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39766,18 +34981,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39834,18 +35040,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39907,18 +35104,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -39974,18 +35162,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40041,18 +35220,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40109,18 +35279,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40177,18 +35338,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0+16 && j0%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40220,12 +35372,9 @@
 		mem := x1.Args[1]
 		p := x1.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBload {
 			break
@@ -40235,15 +35384,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -40263,12 +35406,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBload {
 			break
@@ -40286,15 +35426,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -40314,12 +35448,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -40329,19 +35460,13 @@
 		mem := x1.Args[1]
 		p := x1.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -40351,15 +35476,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -40378,19 +35497,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -40400,12 +35513,9 @@
 		mem := x0.Args[1]
 		p := x0.Args[0]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -40415,15 +35525,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -40454,12 +35558,9 @@
 		mem := x1.Args[1]
 		p := x1.Args[0]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -40473,15 +35574,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x0.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -40505,12 +35600,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -40536,15 +35628,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(x1.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -40594,15 +35680,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40660,15 +35740,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40725,15 +35799,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40791,15 +35859,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40830,12 +35892,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -40855,12 +35914,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -40870,15 +35926,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40908,12 +35958,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -40934,12 +35981,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -40949,15 +35993,9 @@
 			break
 		}
 		_ = x1.Args[1]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || mem != x1.Args[1] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x1.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x1.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -40992,12 +36030,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -41012,12 +36047,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -41027,15 +36059,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -41071,12 +36097,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWload {
 			break
@@ -41091,12 +36114,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWload {
 			break
@@ -41106,15 +36126,9 @@
 			break
 		}
 		_ = x0.Args[1]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || mem != x0.Args[1] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if mem != x0.Args[1] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(x0.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -41148,12 +36162,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41163,18 +36174,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41209,12 +36211,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41224,18 +36223,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41265,12 +36255,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41280,18 +36267,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41321,12 +36299,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41336,18 +36311,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41368,12 +36334,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41392,18 +36355,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41424,12 +36378,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41448,18 +36399,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41480,12 +36422,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41504,18 +36443,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41536,12 +36466,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 8 {
 			break
 		}
-		if sh.AuxInt != 8 {
-			break
-		}
 		x0 := sh.Args[0]
 		if x0.Op != OpAMD64MOVBloadidx1 {
 			break
@@ -41560,18 +36487,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && x0.Uses == 1 && x1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64ROLWconst, v.Type)
 		v.reset(OpCopy)
@@ -41592,12 +36510,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41608,19 +36523,13 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41630,18 +36539,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -41661,12 +36561,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41677,19 +36574,13 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41699,18 +36590,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -41730,12 +36612,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41746,19 +36625,13 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41768,18 +36641,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -41804,12 +36668,9 @@
 	for {
 		_ = v.Args[1]
 		r1 := v.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41820,19 +36681,13 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41842,18 +36697,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -41873,19 +36719,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41896,12 +36736,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41911,18 +36748,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -41942,19 +36770,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41965,12 +36787,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -41980,18 +36799,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -42011,19 +36821,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -42034,12 +36838,9 @@
 		p := x0.Args[0]
 		idx := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -42049,18 +36850,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -42080,19 +36872,13 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 16 {
 			break
 		}
-		if sh.AuxInt != 16 {
-			break
-		}
 		r0 := sh.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -42103,12 +36889,9 @@
 		idx := x0.Args[0]
 		p := x0.Args[1]
 		r1 := v.Args[1]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -42118,18 +36901,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPL, v.Type)
 		v.reset(OpCopy)
@@ -42162,12 +36936,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42181,18 +36952,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42225,12 +36987,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42244,18 +37003,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42288,12 +37038,9 @@
 		p := x1.Args[0]
 		idx := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42307,18 +37054,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42351,12 +37089,9 @@
 		idx := x1.Args[0]
 		p := x1.Args[1]
 		sh := v.Args[1]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42370,18 +37105,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42401,12 +37127,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42433,18 +37156,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42469,12 +37183,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42501,18 +37212,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42532,12 +37234,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42564,18 +37263,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42595,12 +37285,9 @@
 	for {
 		_ = v.Args[1]
 		sh := v.Args[0]
-		if sh.Op != OpAMD64SHLQconst {
+		if sh.Op != OpAMD64SHLQconst || sh.AuxInt != 32 {
 			break
 		}
-		if sh.AuxInt != 32 {
-			break
-		}
 		r0 := sh.Args[0]
 		if r0.Op != OpAMD64BSWAPL {
 			break
@@ -42627,18 +37314,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+4 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && sh.Uses == 1 && mergePoint(b, x0, x1) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(sh)) {
-			break
-		}
 		b = mergePoint(b, x0, x1)
 		v0 := b.NewValue0(v.Pos, OpAMD64BSWAPQ, v.Type)
 		v.reset(OpCopy)
@@ -42690,18 +37368,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -42760,18 +37429,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -42830,18 +37490,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -42900,18 +37551,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -42971,18 +37613,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43042,18 +37675,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43113,18 +37737,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43189,18 +37804,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43259,18 +37865,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43329,18 +37926,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43400,18 +37988,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43471,18 +38050,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43541,18 +38111,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43611,18 +38172,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43682,18 +38234,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43753,18 +38296,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+1 && j1 == j0-8 && j1%16 == 0 && x0.Uses == 1 && x1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43796,12 +38330,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -43822,12 +38353,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -43837,18 +38365,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43884,12 +38403,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -43910,12 +38426,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -43925,18 +38438,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -43967,12 +38471,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -43993,12 +38494,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44008,18 +38506,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44050,12 +38539,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44076,12 +38562,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44091,18 +38574,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44133,12 +38607,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44160,12 +38631,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44175,18 +38643,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44217,12 +38676,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44244,12 +38700,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44259,18 +38712,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if p != x1.Args[0] {
+		if p != x1.Args[0] || idx != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44301,12 +38745,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44328,12 +38769,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44343,18 +38781,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44385,12 +38814,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44412,12 +38838,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44427,18 +38850,9 @@
 			break
 		}
 		_ = x1.Args[2]
-		if idx != x1.Args[0] {
+		if idx != x1.Args[0] || p != x1.Args[1] || mem != x1.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x1.Args[1] {
-			break
-		}
-		if mem != x1.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44474,12 +38888,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44495,12 +38906,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44510,18 +38918,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44557,12 +38956,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44578,12 +38974,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44593,18 +38986,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44641,12 +39025,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44662,12 +39043,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44677,18 +39055,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44730,12 +39099,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44751,12 +39117,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44766,18 +39129,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if p != x0.Args[0] {
+		if p != x0.Args[0] || idx != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if idx != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44813,12 +39167,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44834,12 +39185,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44849,18 +39197,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44896,12 +39235,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44917,12 +39253,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -44932,18 +39265,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -44980,12 +39304,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -45001,12 +39322,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -45016,18 +39334,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -45064,12 +39373,9 @@
 		}
 		j1 := s1.AuxInt
 		r1 := s1.Args[0]
-		if r1.Op != OpAMD64ROLWconst {
+		if r1.Op != OpAMD64ROLWconst || r1.AuxInt != 8 {
 			break
 		}
-		if r1.AuxInt != 8 {
-			break
-		}
 		x1 := r1.Args[0]
 		if x1.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -45085,12 +39391,9 @@
 		}
 		j0 := s0.AuxInt
 		r0 := s0.Args[0]
-		if r0.Op != OpAMD64ROLWconst {
+		if r0.Op != OpAMD64ROLWconst || r0.AuxInt != 8 {
 			break
 		}
-		if r0.AuxInt != 8 {
-			break
-		}
 		x0 := r0.Args[0]
 		if x0.Op != OpAMD64MOVWloadidx1 {
 			break
@@ -45100,18 +39403,9 @@
 			break
 		}
 		_ = x0.Args[2]
-		if idx != x0.Args[0] {
+		if idx != x0.Args[0] || p != x0.Args[1] || mem != x0.Args[2] || !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
 			break
 		}
-		if p != x0.Args[1] {
-			break
-		}
-		if mem != x0.Args[2] {
-			break
-		}
-		if !(i1 == i0+2 && j1 == j0-16 && j1%32 == 0 && x0.Uses == 1 && x1.Uses == 1 && r0.Uses == 1 && r1.Uses == 1 && s0.Uses == 1 && s1.Uses == 1 && or.Uses == 1 && mergePoint(b, x0, x1, y) != nil && clobber(x0) && clobber(x1) && clobber(r0) && clobber(r1) && clobber(s0) && clobber(s1) && clobber(or)) {
-			break
-		}
 		b = mergePoint(b, x0, x1, y)
 		v0 := b.NewValue0(v.Pos, OpAMD64ORQ, v.Type)
 		v.reset(OpCopy)
@@ -45200,7 +39494,6 @@
 		return true
 	}
 	// match: (ORQconst [c] (ORQconst [d] x))
-	// cond:
 	// result: (ORQconst [c | d] x)
 	for {
 		c := v.AuxInt
@@ -45216,7 +39509,6 @@
 		return true
 	}
 	// match: (ORQconst [c] (BTSQconst [d] x))
-	// cond:
 	// result: (ORQconst [c | 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -45232,7 +39524,6 @@
 		return true
 	}
 	// match: (ORQconst [0] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -45245,7 +39536,6 @@
 		return true
 	}
 	// match: (ORQconst [-1] _)
-	// cond:
 	// result: (MOVQconst [-1])
 	for {
 		if v.AuxInt != -1 {
@@ -45256,7 +39546,6 @@
 		return true
 	}
 	// match: (ORQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [c|d])
 	for {
 		c := v.AuxInt
@@ -45376,7 +39665,6 @@
 		return true
 	}
 	// match: (ORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
-	// cond:
 	// result: ( ORQ x (MOVQf2i y))
 	for {
 		off := v.AuxInt
@@ -45385,15 +39673,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSDstore {
+		if v_2.Op != OpAMD64MOVSDstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -45464,7 +39746,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLB_0(v *Value) bool {
 	// match: (ROLB x (NEGQ y))
-	// cond:
 	// result: (RORB x y)
 	for {
 		_ = v.Args[1]
@@ -45480,7 +39761,6 @@
 		return true
 	}
 	// match: (ROLB x (NEGL y))
-	// cond:
 	// result: (RORB x y)
 	for {
 		_ = v.Args[1]
@@ -45496,7 +39776,6 @@
 		return true
 	}
 	// match: (ROLB x (MOVQconst [c]))
-	// cond:
 	// result: (ROLBconst [c&7 ] x)
 	for {
 		_ = v.Args[1]
@@ -45512,7 +39791,6 @@
 		return true
 	}
 	// match: (ROLB x (MOVLconst [c]))
-	// cond:
 	// result: (ROLBconst [c&7 ] x)
 	for {
 		_ = v.Args[1]
@@ -45531,7 +39809,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLBconst_0(v *Value) bool {
 	// match: (ROLBconst [c] (ROLBconst [d] x))
-	// cond:
 	// result: (ROLBconst [(c+d)& 7] x)
 	for {
 		c := v.AuxInt
@@ -45547,7 +39824,6 @@
 		return true
 	}
 	// match: (ROLBconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -45563,7 +39839,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLL_0(v *Value) bool {
 	// match: (ROLL x (NEGQ y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -45579,7 +39854,6 @@
 		return true
 	}
 	// match: (ROLL x (NEGL y))
-	// cond:
 	// result: (RORL x y)
 	for {
 		_ = v.Args[1]
@@ -45595,7 +39869,6 @@
 		return true
 	}
 	// match: (ROLL x (MOVQconst [c]))
-	// cond:
 	// result: (ROLLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -45611,7 +39884,6 @@
 		return true
 	}
 	// match: (ROLL x (MOVLconst [c]))
-	// cond:
 	// result: (ROLLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -45630,7 +39902,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLLconst_0(v *Value) bool {
 	// match: (ROLLconst [c] (ROLLconst [d] x))
-	// cond:
 	// result: (ROLLconst [(c+d)&31] x)
 	for {
 		c := v.AuxInt
@@ -45646,7 +39917,6 @@
 		return true
 	}
 	// match: (ROLLconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -45662,7 +39932,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLQ_0(v *Value) bool {
 	// match: (ROLQ x (NEGQ y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -45678,7 +39947,6 @@
 		return true
 	}
 	// match: (ROLQ x (NEGL y))
-	// cond:
 	// result: (RORQ x y)
 	for {
 		_ = v.Args[1]
@@ -45694,7 +39962,6 @@
 		return true
 	}
 	// match: (ROLQ x (MOVQconst [c]))
-	// cond:
 	// result: (ROLQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -45710,7 +39977,6 @@
 		return true
 	}
 	// match: (ROLQ x (MOVLconst [c]))
-	// cond:
 	// result: (ROLQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -45729,7 +39995,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLQconst_0(v *Value) bool {
 	// match: (ROLQconst [c] (ROLQconst [d] x))
-	// cond:
 	// result: (ROLQconst [(c+d)&63] x)
 	for {
 		c := v.AuxInt
@@ -45745,7 +40010,6 @@
 		return true
 	}
 	// match: (ROLQconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -45761,7 +40025,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLW_0(v *Value) bool {
 	// match: (ROLW x (NEGQ y))
-	// cond:
 	// result: (RORW x y)
 	for {
 		_ = v.Args[1]
@@ -45777,7 +40040,6 @@
 		return true
 	}
 	// match: (ROLW x (NEGL y))
-	// cond:
 	// result: (RORW x y)
 	for {
 		_ = v.Args[1]
@@ -45793,7 +40055,6 @@
 		return true
 	}
 	// match: (ROLW x (MOVQconst [c]))
-	// cond:
 	// result: (ROLWconst [c&15] x)
 	for {
 		_ = v.Args[1]
@@ -45809,7 +40070,6 @@
 		return true
 	}
 	// match: (ROLW x (MOVLconst [c]))
-	// cond:
 	// result: (ROLWconst [c&15] x)
 	for {
 		_ = v.Args[1]
@@ -45828,7 +40088,6 @@
 }
 func rewriteValueAMD64_OpAMD64ROLWconst_0(v *Value) bool {
 	// match: (ROLWconst [c] (ROLWconst [d] x))
-	// cond:
 	// result: (ROLWconst [(c+d)&15] x)
 	for {
 		c := v.AuxInt
@@ -45844,7 +40103,6 @@
 		return true
 	}
 	// match: (ROLWconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -45860,7 +40118,6 @@
 }
 func rewriteValueAMD64_OpAMD64RORB_0(v *Value) bool {
 	// match: (RORB x (NEGQ y))
-	// cond:
 	// result: (ROLB x y)
 	for {
 		_ = v.Args[1]
@@ -45876,7 +40133,6 @@
 		return true
 	}
 	// match: (RORB x (NEGL y))
-	// cond:
 	// result: (ROLB x y)
 	for {
 		_ = v.Args[1]
@@ -45892,7 +40148,6 @@
 		return true
 	}
 	// match: (RORB x (MOVQconst [c]))
-	// cond:
 	// result: (ROLBconst [(-c)&7 ] x)
 	for {
 		_ = v.Args[1]
@@ -45908,7 +40163,6 @@
 		return true
 	}
 	// match: (RORB x (MOVLconst [c]))
-	// cond:
 	// result: (ROLBconst [(-c)&7 ] x)
 	for {
 		_ = v.Args[1]
@@ -45927,7 +40181,6 @@
 }
 func rewriteValueAMD64_OpAMD64RORL_0(v *Value) bool {
 	// match: (RORL x (NEGQ y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -45943,7 +40196,6 @@
 		return true
 	}
 	// match: (RORL x (NEGL y))
-	// cond:
 	// result: (ROLL x y)
 	for {
 		_ = v.Args[1]
@@ -45959,7 +40211,6 @@
 		return true
 	}
 	// match: (RORL x (MOVQconst [c]))
-	// cond:
 	// result: (ROLLconst [(-c)&31] x)
 	for {
 		_ = v.Args[1]
@@ -45975,7 +40226,6 @@
 		return true
 	}
 	// match: (RORL x (MOVLconst [c]))
-	// cond:
 	// result: (ROLLconst [(-c)&31] x)
 	for {
 		_ = v.Args[1]
@@ -45994,7 +40244,6 @@
 }
 func rewriteValueAMD64_OpAMD64RORQ_0(v *Value) bool {
 	// match: (RORQ x (NEGQ y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -46010,7 +40259,6 @@
 		return true
 	}
 	// match: (RORQ x (NEGL y))
-	// cond:
 	// result: (ROLQ x y)
 	for {
 		_ = v.Args[1]
@@ -46026,7 +40274,6 @@
 		return true
 	}
 	// match: (RORQ x (MOVQconst [c]))
-	// cond:
 	// result: (ROLQconst [(-c)&63] x)
 	for {
 		_ = v.Args[1]
@@ -46042,7 +40289,6 @@
 		return true
 	}
 	// match: (RORQ x (MOVLconst [c]))
-	// cond:
 	// result: (ROLQconst [(-c)&63] x)
 	for {
 		_ = v.Args[1]
@@ -46061,7 +40307,6 @@
 }
 func rewriteValueAMD64_OpAMD64RORW_0(v *Value) bool {
 	// match: (RORW x (NEGQ y))
-	// cond:
 	// result: (ROLW x y)
 	for {
 		_ = v.Args[1]
@@ -46077,7 +40322,6 @@
 		return true
 	}
 	// match: (RORW x (NEGL y))
-	// cond:
 	// result: (ROLW x y)
 	for {
 		_ = v.Args[1]
@@ -46093,7 +40337,6 @@
 		return true
 	}
 	// match: (RORW x (MOVQconst [c]))
-	// cond:
 	// result: (ROLWconst [(-c)&15] x)
 	for {
 		_ = v.Args[1]
@@ -46109,7 +40352,6 @@
 		return true
 	}
 	// match: (RORW x (MOVLconst [c]))
-	// cond:
 	// result: (ROLWconst [(-c)&15] x)
 	for {
 		_ = v.Args[1]
@@ -46128,7 +40370,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARB_0(v *Value) bool {
 	// match: (SARB x (MOVQconst [c]))
-	// cond:
 	// result: (SARBconst [min(c&31,7)] x)
 	for {
 		_ = v.Args[1]
@@ -46144,7 +40385,6 @@
 		return true
 	}
 	// match: (SARB x (MOVLconst [c]))
-	// cond:
 	// result: (SARBconst [min(c&31,7)] x)
 	for {
 		_ = v.Args[1]
@@ -46163,7 +40403,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARBconst_0(v *Value) bool {
 	// match: (SARBconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -46176,7 +40415,6 @@
 		return true
 	}
 	// match: (SARBconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [int64(int8(d))>>uint64(c)])
 	for {
 		c := v.AuxInt
@@ -46194,7 +40432,6 @@
 func rewriteValueAMD64_OpAMD64SARL_0(v *Value) bool {
 	b := v.Block
 	// match: (SARL x (MOVQconst [c]))
-	// cond:
 	// result: (SARLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -46210,7 +40447,6 @@
 		return true
 	}
 	// match: (SARL x (MOVLconst [c]))
-	// cond:
 	// result: (SARLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -46417,7 +40653,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARLconst_0(v *Value) bool {
 	// match: (SARLconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -46430,7 +40665,6 @@
 		return true
 	}
 	// match: (SARLconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [int64(int32(d))>>uint64(c)])
 	for {
 		c := v.AuxInt
@@ -46448,7 +40682,6 @@
 func rewriteValueAMD64_OpAMD64SARQ_0(v *Value) bool {
 	b := v.Block
 	// match: (SARQ x (MOVQconst [c]))
-	// cond:
 	// result: (SARQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -46464,7 +40697,6 @@
 		return true
 	}
 	// match: (SARQ x (MOVLconst [c]))
-	// cond:
 	// result: (SARQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -46671,7 +40903,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARQconst_0(v *Value) bool {
 	// match: (SARQconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -46684,7 +40915,6 @@
 		return true
 	}
 	// match: (SARQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [d>>uint64(c)])
 	for {
 		c := v.AuxInt
@@ -46701,7 +40931,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARW_0(v *Value) bool {
 	// match: (SARW x (MOVQconst [c]))
-	// cond:
 	// result: (SARWconst [min(c&31,15)] x)
 	for {
 		_ = v.Args[1]
@@ -46717,7 +40946,6 @@
 		return true
 	}
 	// match: (SARW x (MOVLconst [c]))
-	// cond:
 	// result: (SARWconst [min(c&31,15)] x)
 	for {
 		_ = v.Args[1]
@@ -46736,7 +40964,6 @@
 }
 func rewriteValueAMD64_OpAMD64SARWconst_0(v *Value) bool {
 	// match: (SARWconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -46749,7 +40976,6 @@
 		return true
 	}
 	// match: (SARWconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [int64(int16(d))>>uint64(c)])
 	for {
 		c := v.AuxInt
@@ -46766,7 +40992,6 @@
 }
 func rewriteValueAMD64_OpAMD64SBBLcarrymask_0(v *Value) bool {
 	// match: (SBBLcarrymask (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46778,7 +41003,6 @@
 		return true
 	}
 	// match: (SBBLcarrymask (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [-1])
 	for {
 		v_0 := v.Args[0]
@@ -46790,7 +41014,6 @@
 		return true
 	}
 	// match: (SBBLcarrymask (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46802,7 +41025,6 @@
 		return true
 	}
 	// match: (SBBLcarrymask (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [-1])
 	for {
 		v_0 := v.Args[0]
@@ -46814,7 +41036,6 @@
 		return true
 	}
 	// match: (SBBLcarrymask (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46849,7 +41070,6 @@
 		return true
 	}
 	// match: (SBBQ x y (FlagEQ))
-	// cond:
 	// result: (SUBQborrow x y)
 	for {
 		_ = v.Args[2]
@@ -46868,7 +41088,6 @@
 }
 func rewriteValueAMD64_OpAMD64SBBQcarrymask_0(v *Value) bool {
 	// match: (SBBQcarrymask (FlagEQ))
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46880,7 +41099,6 @@
 		return true
 	}
 	// match: (SBBQcarrymask (FlagLT_ULT))
-	// cond:
 	// result: (MOVQconst [-1])
 	for {
 		v_0 := v.Args[0]
@@ -46892,7 +41110,6 @@
 		return true
 	}
 	// match: (SBBQcarrymask (FlagLT_UGT))
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46904,7 +41121,6 @@
 		return true
 	}
 	// match: (SBBQcarrymask (FlagGT_ULT))
-	// cond:
 	// result: (MOVQconst [-1])
 	for {
 		v_0 := v.Args[0]
@@ -46916,7 +41132,6 @@
 		return true
 	}
 	// match: (SBBQcarrymask (FlagGT_UGT))
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46931,7 +41146,6 @@
 }
 func rewriteValueAMD64_OpAMD64SBBQconst_0(v *Value) bool {
 	// match: (SBBQconst x [c] (FlagEQ))
-	// cond:
 	// result: (SUBQconstborrow x [c])
 	for {
 		c := v.AuxInt
@@ -46950,7 +41164,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETA_0(v *Value) bool {
 	// match: (SETA (InvertFlags x))
-	// cond:
 	// result: (SETB x)
 	for {
 		v_0 := v.Args[0]
@@ -46963,7 +41176,6 @@
 		return true
 	}
 	// match: (SETA (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46975,7 +41187,6 @@
 		return true
 	}
 	// match: (SETA (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -46987,7 +41198,6 @@
 		return true
 	}
 	// match: (SETA (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -46999,7 +41209,6 @@
 		return true
 	}
 	// match: (SETA (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47011,7 +41220,6 @@
 		return true
 	}
 	// match: (SETA (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47026,7 +41234,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETAE_0(v *Value) bool {
 	// match: (SETAE (InvertFlags x))
-	// cond:
 	// result: (SETBE x)
 	for {
 		v_0 := v.Args[0]
@@ -47039,7 +41246,6 @@
 		return true
 	}
 	// match: (SETAE (FlagEQ))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47051,7 +41257,6 @@
 		return true
 	}
 	// match: (SETAE (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47063,7 +41268,6 @@
 		return true
 	}
 	// match: (SETAE (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47075,7 +41279,6 @@
 		return true
 	}
 	// match: (SETAE (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47087,7 +41290,6 @@
 		return true
 	}
 	// match: (SETAE (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47104,7 +41306,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETAEstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETBEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -47176,7 +41377,6 @@
 		return true
 	}
 	// match: (SETAEstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47198,7 +41398,6 @@
 		return true
 	}
 	// match: (SETAEstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47220,7 +41419,6 @@
 		return true
 	}
 	// match: (SETAEstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47242,7 +41440,6 @@
 		return true
 	}
 	// match: (SETAEstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47264,7 +41461,6 @@
 		return true
 	}
 	// match: (SETAEstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47291,7 +41487,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETAstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETBstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -47363,7 +41558,6 @@
 		return true
 	}
 	// match: (SETAstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47385,7 +41579,6 @@
 		return true
 	}
 	// match: (SETAstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47407,7 +41600,6 @@
 		return true
 	}
 	// match: (SETAstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47429,7 +41621,6 @@
 		return true
 	}
 	// match: (SETAstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47451,7 +41642,6 @@
 		return true
 	}
 	// match: (SETAstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47476,7 +41666,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETB_0(v *Value) bool {
 	// match: (SETB (InvertFlags x))
-	// cond:
 	// result: (SETA x)
 	for {
 		v_0 := v.Args[0]
@@ -47489,7 +41678,6 @@
 		return true
 	}
 	// match: (SETB (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47501,7 +41689,6 @@
 		return true
 	}
 	// match: (SETB (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47513,7 +41700,6 @@
 		return true
 	}
 	// match: (SETB (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47525,7 +41711,6 @@
 		return true
 	}
 	// match: (SETB (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47537,7 +41722,6 @@
 		return true
 	}
 	// match: (SETB (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47552,7 +41736,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETBE_0(v *Value) bool {
 	// match: (SETBE (InvertFlags x))
-	// cond:
 	// result: (SETAE x)
 	for {
 		v_0 := v.Args[0]
@@ -47565,7 +41748,6 @@
 		return true
 	}
 	// match: (SETBE (FlagEQ))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47577,7 +41759,6 @@
 		return true
 	}
 	// match: (SETBE (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47589,7 +41770,6 @@
 		return true
 	}
 	// match: (SETBE (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47601,7 +41781,6 @@
 		return true
 	}
 	// match: (SETBE (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -47613,7 +41792,6 @@
 		return true
 	}
 	// match: (SETBE (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -47630,7 +41808,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETBEstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETAEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -47702,7 +41879,6 @@
 		return true
 	}
 	// match: (SETBEstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47724,7 +41900,6 @@
 		return true
 	}
 	// match: (SETBEstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47746,7 +41921,6 @@
 		return true
 	}
 	// match: (SETBEstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47768,7 +41942,6 @@
 		return true
 	}
 	// match: (SETBEstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47790,7 +41963,6 @@
 		return true
 	}
 	// match: (SETBEstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47817,7 +41989,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETBstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETAstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -47889,7 +42060,6 @@
 		return true
 	}
 	// match: (SETBstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47911,7 +42081,6 @@
 		return true
 	}
 	// match: (SETBstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47933,7 +42102,6 @@
 		return true
 	}
 	// match: (SETBstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -47955,7 +42123,6 @@
 		return true
 	}
 	// match: (SETBstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -47977,7 +42144,6 @@
 		return true
 	}
 	// match: (SETBstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -48018,15 +42184,9 @@
 		}
 		x := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVLconst {
+		if v_0_0_0.Op != OpAMD64MOVLconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAE)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 		v0.AddArg(x)
@@ -48050,15 +42210,9 @@
 		}
 		x := v_0_1.Args[1]
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64MOVLconst {
+		if v_0_1_0.Op != OpAMD64MOVLconst || v_0_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAE)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 		v0.AddArg(x)
@@ -48081,15 +42235,9 @@
 		}
 		x := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0_0.Op != OpAMD64MOVQconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAE)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 		v0.AddArg(x)
@@ -48113,15 +42261,9 @@
 		}
 		x := v_0_1.Args[1]
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64MOVQconst {
+		if v_0_1_0.Op != OpAMD64MOVQconst || v_0_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAE)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 		v0.AddArg(x)
@@ -48219,23 +42361,16 @@
 		return true
 	}
 	// match: (SETEQ (CMPLconst [1] s:(ANDLconst [1] _)))
-	// cond:
 	// result: (SETNE (CMPLconst [0] s))
 	for {
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64CMPLconst {
+		if v_0.Op != OpAMD64CMPLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		s := v_0.Args[0]
-		if s.Op != OpAMD64ANDLconst {
+		if s.Op != OpAMD64ANDLconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETNE)
 		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconst, types.TypeFlags)
 		v0.AuxInt = 0
@@ -48244,23 +42379,16 @@
 		return true
 	}
 	// match: (SETEQ (CMPQconst [1] s:(ANDQconst [1] _)))
-	// cond:
 	// result: (SETNE (CMPQconst [0] s))
 	for {
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64CMPQconst {
+		if v_0.Op != OpAMD64CMPQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		s := v_0.Args[0]
-		if s.Op != OpAMD64ANDQconst {
+		if s.Op != OpAMD64ANDQconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETNE)
 		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconst, types.TypeFlags)
 		v0.AuxInt = 0
@@ -48283,19 +42411,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48318,19 +42440,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48352,19 +42468,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48387,19 +42497,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48421,19 +42525,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48456,19 +42554,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48490,19 +42582,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48525,19 +42611,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48559,12 +42639,9 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48587,12 +42664,9 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48619,12 +42693,9 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48647,12 +42718,9 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -48665,7 +42733,6 @@
 		return true
 	}
 	// match: (SETEQ (InvertFlags x))
-	// cond:
 	// result: (SETEQ x)
 	for {
 		v_0 := v.Args[0]
@@ -48678,7 +42745,6 @@
 		return true
 	}
 	// match: (SETEQ (FlagEQ))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -48690,7 +42756,6 @@
 		return true
 	}
 	// match: (SETEQ (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -48702,7 +42767,6 @@
 		return true
 	}
 	// match: (SETEQ (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -48714,7 +42778,6 @@
 		return true
 	}
 	// match: (SETEQ (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -48726,7 +42789,6 @@
 		return true
 	}
 	// match: (SETEQ (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -48761,15 +42823,9 @@
 		}
 		x := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVLconst {
+		if v_1_0_0.Op != OpAMD64MOVLconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -48801,15 +42857,9 @@
 		}
 		x := v_1_1.Args[1]
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64MOVLconst {
+		if v_1_1_0.Op != OpAMD64MOVLconst || v_1_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -48840,15 +42890,9 @@
 		}
 		x := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVQconst {
+		if v_1_0_0.Op != OpAMD64MOVQconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -48880,15 +42924,9 @@
 		}
 		x := v_1_1.Args[1]
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64MOVQconst {
+		if v_1_1_0.Op != OpAMD64MOVQconst || v_1_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -49022,7 +43060,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
-	// cond:
 	// result: (SETNEstore [off] {sym} ptr (CMPLconst [0] s) mem)
 	for {
 		off := v.AuxInt
@@ -49030,19 +43067,13 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64CMPLconst {
+		if v_1.Op != OpAMD64CMPLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		s := v_1.Args[0]
-		if s.Op != OpAMD64ANDLconst {
+		if s.Op != OpAMD64ANDLconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -49055,7 +43086,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
-	// cond:
 	// result: (SETNEstore [off] {sym} ptr (CMPQconst [0] s) mem)
 	for {
 		off := v.AuxInt
@@ -49063,19 +43093,13 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64CMPQconst {
+		if v_1.Op != OpAMD64CMPQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		s := v_1.Args[0]
-		if s.Op != OpAMD64ANDQconst {
+		if s.Op != OpAMD64ANDQconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -49106,19 +43130,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49149,19 +43167,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49191,19 +43203,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRLconst {
+		if z1_0.Op != OpAMD64SHRLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49234,19 +43240,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRLconst {
+		if z1_0.Op != OpAMD64SHRLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49276,19 +43276,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49319,19 +43313,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49361,19 +43349,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49404,19 +43386,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49446,12 +43422,9 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49482,12 +43455,9 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49523,12 +43493,9 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49559,12 +43526,9 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -49581,7 +43545,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETEQstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -49653,7 +43616,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -49675,7 +43637,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -49697,7 +43658,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -49719,7 +43679,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -49741,7 +43700,6 @@
 		return true
 	}
 	// match: (SETEQstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -49766,7 +43724,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETG_0(v *Value) bool {
 	// match: (SETG (InvertFlags x))
-	// cond:
 	// result: (SETL x)
 	for {
 		v_0 := v.Args[0]
@@ -49779,7 +43736,6 @@
 		return true
 	}
 	// match: (SETG (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -49791,7 +43747,6 @@
 		return true
 	}
 	// match: (SETG (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -49803,7 +43758,6 @@
 		return true
 	}
 	// match: (SETG (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -49815,7 +43769,6 @@
 		return true
 	}
 	// match: (SETG (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -49827,7 +43780,6 @@
 		return true
 	}
 	// match: (SETG (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -49842,7 +43794,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETGE_0(v *Value) bool {
 	// match: (SETGE (InvertFlags x))
-	// cond:
 	// result: (SETLE x)
 	for {
 		v_0 := v.Args[0]
@@ -49855,7 +43806,6 @@
 		return true
 	}
 	// match: (SETGE (FlagEQ))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -49867,7 +43817,6 @@
 		return true
 	}
 	// match: (SETGE (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -49879,7 +43828,6 @@
 		return true
 	}
 	// match: (SETGE (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -49891,7 +43839,6 @@
 		return true
 	}
 	// match: (SETGE (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -49903,7 +43850,6 @@
 		return true
 	}
 	// match: (SETGE (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -49920,7 +43866,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETGEstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETLEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -49992,7 +43937,6 @@
 		return true
 	}
 	// match: (SETGEstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50014,7 +43958,6 @@
 		return true
 	}
 	// match: (SETGEstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50036,7 +43979,6 @@
 		return true
 	}
 	// match: (SETGEstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50058,7 +44000,6 @@
 		return true
 	}
 	// match: (SETGEstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50080,7 +44021,6 @@
 		return true
 	}
 	// match: (SETGEstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50107,7 +44047,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETGstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETLstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -50179,7 +44118,6 @@
 		return true
 	}
 	// match: (SETGstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50201,7 +44139,6 @@
 		return true
 	}
 	// match: (SETGstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50223,7 +44160,6 @@
 		return true
 	}
 	// match: (SETGstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50245,7 +44181,6 @@
 		return true
 	}
 	// match: (SETGstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50267,7 +44202,6 @@
 		return true
 	}
 	// match: (SETGstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50292,7 +44226,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETL_0(v *Value) bool {
 	// match: (SETL (InvertFlags x))
-	// cond:
 	// result: (SETG x)
 	for {
 		v_0 := v.Args[0]
@@ -50305,7 +44238,6 @@
 		return true
 	}
 	// match: (SETL (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -50317,7 +44249,6 @@
 		return true
 	}
 	// match: (SETL (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -50329,7 +44260,6 @@
 		return true
 	}
 	// match: (SETL (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -50341,7 +44271,6 @@
 		return true
 	}
 	// match: (SETL (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -50353,7 +44282,6 @@
 		return true
 	}
 	// match: (SETL (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -50368,7 +44296,6 @@
 }
 func rewriteValueAMD64_OpAMD64SETLE_0(v *Value) bool {
 	// match: (SETLE (InvertFlags x))
-	// cond:
 	// result: (SETGE x)
 	for {
 		v_0 := v.Args[0]
@@ -50381,7 +44308,6 @@
 		return true
 	}
 	// match: (SETLE (FlagEQ))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -50393,7 +44319,6 @@
 		return true
 	}
 	// match: (SETLE (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -50405,7 +44330,6 @@
 		return true
 	}
 	// match: (SETLE (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -50417,7 +44341,6 @@
 		return true
 	}
 	// match: (SETLE (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -50429,7 +44352,6 @@
 		return true
 	}
 	// match: (SETLE (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -50446,7 +44368,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETLEstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETGEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -50518,7 +44439,6 @@
 		return true
 	}
 	// match: (SETLEstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50540,7 +44460,6 @@
 		return true
 	}
 	// match: (SETLEstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50562,7 +44481,6 @@
 		return true
 	}
 	// match: (SETLEstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50584,7 +44502,6 @@
 		return true
 	}
 	// match: (SETLEstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50606,7 +44523,6 @@
 		return true
 	}
 	// match: (SETLEstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50633,7 +44549,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (SETLstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETGstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -50705,7 +44620,6 @@
 		return true
 	}
 	// match: (SETLstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50727,7 +44641,6 @@
 		return true
 	}
 	// match: (SETLstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50749,7 +44662,6 @@
 		return true
 	}
 	// match: (SETLstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -50771,7 +44683,6 @@
 		return true
 	}
 	// match: (SETLstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50793,7 +44704,6 @@
 		return true
 	}
 	// match: (SETLstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -50834,15 +44744,9 @@
 		}
 		x := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVLconst {
+		if v_0_0_0.Op != OpAMD64MOVLconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETB)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 		v0.AddArg(x)
@@ -50866,15 +44770,9 @@
 		}
 		x := v_0_1.Args[1]
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64MOVLconst {
+		if v_0_1_0.Op != OpAMD64MOVLconst || v_0_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETB)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 		v0.AddArg(x)
@@ -50897,15 +44795,9 @@
 		}
 		x := v_0_0.Args[1]
 		v_0_0_0 := v_0_0.Args[0]
-		if v_0_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0_0.Op != OpAMD64MOVQconst || v_0_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETB)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 		v0.AddArg(x)
@@ -50929,15 +44821,9 @@
 		}
 		x := v_0_1.Args[1]
 		v_0_1_0 := v_0_1.Args[0]
-		if v_0_1_0.Op != OpAMD64MOVQconst {
+		if v_0_1_0.Op != OpAMD64MOVQconst || v_0_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETB)
 		v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 		v0.AddArg(x)
@@ -51035,23 +44921,16 @@
 		return true
 	}
 	// match: (SETNE (CMPLconst [1] s:(ANDLconst [1] _)))
-	// cond:
 	// result: (SETEQ (CMPLconst [0] s))
 	for {
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64CMPLconst {
+		if v_0.Op != OpAMD64CMPLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		s := v_0.Args[0]
-		if s.Op != OpAMD64ANDLconst {
+		if s.Op != OpAMD64ANDLconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETEQ)
 		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconst, types.TypeFlags)
 		v0.AuxInt = 0
@@ -51060,23 +44939,16 @@
 		return true
 	}
 	// match: (SETNE (CMPQconst [1] s:(ANDQconst [1] _)))
-	// cond:
 	// result: (SETEQ (CMPQconst [0] s))
 	for {
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64CMPQconst {
+		if v_0.Op != OpAMD64CMPQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		s := v_0.Args[0]
-		if s.Op != OpAMD64ANDQconst {
+		if s.Op != OpAMD64ANDQconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETEQ)
 		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconst, types.TypeFlags)
 		v0.AuxInt = 0
@@ -51099,19 +44971,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51134,19 +45000,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51168,19 +45028,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51203,19 +45057,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51237,19 +45085,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51272,19 +45114,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51306,19 +45142,13 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51341,19 +45171,13 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51375,12 +45199,9 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51403,12 +45224,9 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51435,12 +45253,9 @@
 		}
 		z2 := v_0.Args[1]
 		z1 := v_0.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51463,12 +45278,9 @@
 		_ = v_0.Args[1]
 		z2 := v_0.Args[0]
 		z1 := v_0.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51481,7 +45293,6 @@
 		return true
 	}
 	// match: (SETNE (InvertFlags x))
-	// cond:
 	// result: (SETNE x)
 	for {
 		v_0 := v.Args[0]
@@ -51494,7 +45305,6 @@
 		return true
 	}
 	// match: (SETNE (FlagEQ))
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		v_0 := v.Args[0]
@@ -51506,7 +45316,6 @@
 		return true
 	}
 	// match: (SETNE (FlagLT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -51518,7 +45327,6 @@
 		return true
 	}
 	// match: (SETNE (FlagLT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -51530,7 +45338,6 @@
 		return true
 	}
 	// match: (SETNE (FlagGT_ULT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -51542,7 +45349,6 @@
 		return true
 	}
 	// match: (SETNE (FlagGT_UGT))
-	// cond:
 	// result: (MOVLconst [1])
 	for {
 		v_0 := v.Args[0]
@@ -51577,15 +45383,9 @@
 		}
 		x := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVLconst {
+		if v_1_0_0.Op != OpAMD64MOVLconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51617,15 +45417,9 @@
 		}
 		x := v_1_1.Args[1]
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64MOVLconst {
+		if v_1_1_0.Op != OpAMD64MOVLconst || v_1_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51656,15 +45450,9 @@
 		}
 		x := v_1_0.Args[1]
 		v_1_0_0 := v_1_0.Args[0]
-		if v_1_0_0.Op != OpAMD64MOVQconst {
+		if v_1_0_0.Op != OpAMD64MOVQconst || v_1_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51696,15 +45484,9 @@
 		}
 		x := v_1_1.Args[1]
 		v_1_1_0 := v_1_1.Args[0]
-		if v_1_1_0.Op != OpAMD64MOVQconst {
+		if v_1_1_0.Op != OpAMD64MOVQconst || v_1_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51838,7 +45620,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
-	// cond:
 	// result: (SETEQstore [off] {sym} ptr (CMPLconst [0] s) mem)
 	for {
 		off := v.AuxInt
@@ -51846,19 +45627,13 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64CMPLconst {
+		if v_1.Op != OpAMD64CMPLconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		s := v_1.Args[0]
-		if s.Op != OpAMD64ANDLconst {
+		if s.Op != OpAMD64ANDLconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51871,7 +45646,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
-	// cond:
 	// result: (SETEQstore [off] {sym} ptr (CMPQconst [0] s) mem)
 	for {
 		off := v.AuxInt
@@ -51879,19 +45653,13 @@
 		mem := v.Args[2]
 		ptr := v.Args[0]
 		v_1 := v.Args[1]
-		if v_1.Op != OpAMD64CMPQconst {
+		if v_1.Op != OpAMD64CMPQconst || v_1.AuxInt != 1 {
 			break
 		}
-		if v_1.AuxInt != 1 {
-			break
-		}
 		s := v_1.Args[0]
-		if s.Op != OpAMD64ANDQconst {
+		if s.Op != OpAMD64ANDQconst || s.AuxInt != 1 {
 			break
 		}
-		if s.AuxInt != 1 {
-			break
-		}
 		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
@@ -51922,19 +45690,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -51965,19 +45727,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHLQconst {
+		if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRQconst {
+		if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52007,19 +45763,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRLconst {
+		if z1_0.Op != OpAMD64SHRLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52050,19 +45800,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHLLconst {
+		if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHRLconst {
+		if z1_0.Op != OpAMD64SHRLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52092,19 +45836,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52135,19 +45873,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLQconst {
+		if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 			break
 		}
-		if z1_0.AuxInt != 63 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52177,19 +45909,13 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52220,19 +45946,13 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		z1_0 := z1.Args[0]
-		if z1_0.Op != OpAMD64SHLLconst {
+		if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 			break
 		}
-		if z1_0.AuxInt != 31 {
-			break
-		}
 		x := z1_0.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52262,12 +45982,9 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52298,12 +46015,9 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRQconst {
+		if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 			break
 		}
-		if z1.AuxInt != 63 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52339,12 +46053,9 @@
 		}
 		z2 := v_1.Args[1]
 		z1 := v_1.Args[0]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52375,12 +46086,9 @@
 		_ = v_1.Args[1]
 		z2 := v_1.Args[0]
 		z1 := v_1.Args[1]
-		if z1.Op != OpAMD64SHRLconst {
+		if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 			break
 		}
-		if z1.AuxInt != 31 {
-			break
-		}
 		x := z1.Args[0]
 		if !(z1 == z2 && !config.nacl) {
 			break
@@ -52397,7 +46105,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (InvertFlags x) mem)
-	// cond:
 	// result: (SETNEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
@@ -52469,7 +46176,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (FlagEQ) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [0]) mem)
 	for {
 		off := v.AuxInt
@@ -52491,7 +46197,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (FlagLT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -52513,7 +46218,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (FlagLT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -52535,7 +46239,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (FlagGT_ULT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -52557,7 +46260,6 @@
 		return true
 	}
 	// match: (SETNEstore [off] {sym} ptr (FlagGT_UGT) mem)
-	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <typ.UInt8> [1]) mem)
 	for {
 		off := v.AuxInt
@@ -52583,7 +46285,6 @@
 func rewriteValueAMD64_OpAMD64SHLL_0(v *Value) bool {
 	b := v.Block
 	// match: (SHLL x (MOVQconst [c]))
-	// cond:
 	// result: (SHLLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -52599,7 +46300,6 @@
 		return true
 	}
 	// match: (SHLL x (MOVLconst [c]))
-	// cond:
 	// result: (SHLLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -52815,12 +46515,9 @@
 			break
 		}
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHRLconst {
+		if v_0.Op != OpAMD64SHRLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		if !(!config.nacl) {
 			break
@@ -52831,7 +46528,6 @@
 		return true
 	}
 	// match: (SHLLconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -52848,7 +46544,6 @@
 func rewriteValueAMD64_OpAMD64SHLQ_0(v *Value) bool {
 	b := v.Block
 	// match: (SHLQ x (MOVQconst [c]))
-	// cond:
 	// result: (SHLQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -52864,7 +46559,6 @@
 		return true
 	}
 	// match: (SHLQ x (MOVLconst [c]))
-	// cond:
 	// result: (SHLQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -53080,12 +46774,9 @@
 			break
 		}
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHRQconst {
+		if v_0.Op != OpAMD64SHRQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		if !(!config.nacl) {
 			break
@@ -53096,7 +46787,6 @@
 		return true
 	}
 	// match: (SHLQconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -53187,7 +46877,6 @@
 }
 func rewriteValueAMD64_OpAMD64SHRBconst_0(v *Value) bool {
 	// match: (SHRBconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -53204,7 +46893,6 @@
 func rewriteValueAMD64_OpAMD64SHRL_0(v *Value) bool {
 	b := v.Block
 	// match: (SHRL x (MOVQconst [c]))
-	// cond:
 	// result: (SHRLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -53220,7 +46908,6 @@
 		return true
 	}
 	// match: (SHRL x (MOVLconst [c]))
-	// cond:
 	// result: (SHRLconst [c&31] x)
 	for {
 		_ = v.Args[1]
@@ -53436,12 +47123,9 @@
 			break
 		}
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLLconst {
+		if v_0.Op != OpAMD64SHLLconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		if !(!config.nacl) {
 			break
@@ -53452,7 +47136,6 @@
 		return true
 	}
 	// match: (SHRLconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -53469,7 +47152,6 @@
 func rewriteValueAMD64_OpAMD64SHRQ_0(v *Value) bool {
 	b := v.Block
 	// match: (SHRQ x (MOVQconst [c]))
-	// cond:
 	// result: (SHRQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -53485,7 +47167,6 @@
 		return true
 	}
 	// match: (SHRQ x (MOVLconst [c]))
-	// cond:
 	// result: (SHRQconst [c&63] x)
 	for {
 		_ = v.Args[1]
@@ -53701,12 +47382,9 @@
 			break
 		}
 		v_0 := v.Args[0]
-		if v_0.Op != OpAMD64SHLQconst {
+		if v_0.Op != OpAMD64SHLQconst || v_0.AuxInt != 1 {
 			break
 		}
-		if v_0.AuxInt != 1 {
-			break
-		}
 		x := v_0.Args[0]
 		if !(!config.nacl) {
 			break
@@ -53717,7 +47395,6 @@
 		return true
 	}
 	// match: (SHRQconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -53808,7 +47485,6 @@
 }
 func rewriteValueAMD64_OpAMD64SHRWconst_0(v *Value) bool {
 	// match: (SHRWconst x [0])
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -53825,7 +47501,6 @@
 func rewriteValueAMD64_OpAMD64SUBL_0(v *Value) bool {
 	b := v.Block
 	// match: (SUBL x (MOVLconst [c]))
-	// cond:
 	// result: (SUBLconst x [c])
 	for {
 		_ = v.Args[1]
@@ -53841,7 +47516,6 @@
 		return true
 	}
 	// match: (SUBL (MOVLconst [c]) x)
-	// cond:
 	// result: (NEGL (SUBLconst <v.Type> x [c]))
 	for {
 		x := v.Args[1]
@@ -53858,7 +47532,6 @@
 		return true
 	}
 	// match: (SUBL x x)
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		x := v.Args[1]
@@ -53912,7 +47585,6 @@
 		return true
 	}
 	// match: (SUBLconst [c] x)
-	// cond:
 	// result: (ADDLconst [int64(int32(-c))] x)
 	for {
 		c := v.AuxInt
@@ -53978,7 +47650,6 @@
 		return true
 	}
 	// match: (SUBLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
-	// cond:
 	// result: (SUBL x (MOVLf2i y))
 	for {
 		off := v.AuxInt
@@ -53987,15 +47658,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSSstore {
+		if v_2.Op != OpAMD64MOVSSstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -54106,7 +47771,6 @@
 		return true
 	}
 	// match: (SUBQ x x)
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		x := v.Args[1]
@@ -54168,7 +47832,6 @@
 }
 func rewriteValueAMD64_OpAMD64SUBQconst_0(v *Value) bool {
 	// match: (SUBQconst [0] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -54195,7 +47858,6 @@
 		return true
 	}
 	// match: (SUBQconst (MOVQconst [d]) [c])
-	// cond:
 	// result: (MOVQconst [d-c])
 	for {
 		c := v.AuxInt
@@ -54284,7 +47946,6 @@
 		return true
 	}
 	// match: (SUBQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
-	// cond:
 	// result: (SUBQ x (MOVQf2i y))
 	for {
 		off := v.AuxInt
@@ -54293,15 +47954,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSDstore {
+		if v_2.Op != OpAMD64MOVSDstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -54453,7 +48108,6 @@
 		return true
 	}
 	// match: (SUBSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
-	// cond:
 	// result: (SUBSD x (MOVQi2f y))
 	for {
 		off := v.AuxInt
@@ -54462,15 +48116,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVQstore {
+		if v_2.Op != OpAMD64MOVQstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -54568,7 +48216,6 @@
 		return true
 	}
 	// match: (SUBSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
-	// cond:
 	// result: (SUBSS x (MOVLi2f y))
 	for {
 		off := v.AuxInt
@@ -54577,15 +48224,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVLstore {
+		if v_2.Op != OpAMD64MOVLstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -54603,7 +48244,6 @@
 func rewriteValueAMD64_OpAMD64TESTB_0(v *Value) bool {
 	b := v.Block
 	// match: (TESTB (MOVLconst [c]) x)
-	// cond:
 	// result: (TESTBconst [c] x)
 	for {
 		x := v.Args[1]
@@ -54618,7 +48258,6 @@
 		return true
 	}
 	// match: (TESTB x (MOVLconst [c]))
-	// cond:
 	// result: (TESTBconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -54710,7 +48349,6 @@
 func rewriteValueAMD64_OpAMD64TESTL_0(v *Value) bool {
 	b := v.Block
 	// match: (TESTL (MOVLconst [c]) x)
-	// cond:
 	// result: (TESTLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -54725,7 +48363,6 @@
 		return true
 	}
 	// match: (TESTL x (MOVLconst [c]))
-	// cond:
 	// result: (TESTLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -54930,7 +48567,6 @@
 func rewriteValueAMD64_OpAMD64TESTW_0(v *Value) bool {
 	b := v.Block
 	// match: (TESTW (MOVLconst [c]) x)
-	// cond:
 	// result: (TESTWconst [c] x)
 	for {
 		x := v.Args[1]
@@ -54945,7 +48581,6 @@
 		return true
 	}
 	// match: (TESTW x (MOVLconst [c]))
-	// cond:
 	// result: (TESTWconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -55212,15 +48847,9 @@
 		}
 		y := v_0.Args[1]
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64MOVLconst {
+		if v_0_0.Op != OpAMD64MOVLconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTCL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -55238,15 +48867,9 @@
 		}
 		y := v_1.Args[1]
 		v_1_0 := v_1.Args[0]
-		if v_1_0.Op != OpAMD64MOVLconst {
+		if v_1_0.Op != OpAMD64MOVLconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTCL)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -55290,7 +48913,6 @@
 		return true
 	}
 	// match: (XORL x (MOVLconst [c]))
-	// cond:
 	// result: (XORLconst [c] x)
 	for {
 		_ = v.Args[1]
@@ -55306,7 +48928,6 @@
 		return true
 	}
 	// match: (XORL (MOVLconst [c]) x)
-	// cond:
 	// result: (XORLconst [c] x)
 	for {
 		x := v.Args[1]
@@ -55336,12 +48957,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -55363,12 +48981,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 32-c) {
 			break
 		}
-		if !(d == 32-c) {
-			break
-		}
 		v.reset(OpAMD64ROLLconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -55391,12 +49006,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -55419,12 +49031,9 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 16-c && c < 16 && t.Size() == 2) {
 			break
 		}
-		if !(d == 16-c && c < 16 && t.Size() == 2) {
-			break
-		}
 		v.reset(OpAMD64ROLWconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -55450,12 +49059,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -55478,19 +49084,15 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 8-c && c < 8 && t.Size() == 1) {
 			break
 		}
-		if !(d == 8-c && c < 8 && t.Size() == 1) {
-			break
-		}
 		v.reset(OpAMD64ROLBconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (XORL x x)
-	// cond:
 	// result: (MOVLconst [0])
 	for {
 		x := v.Args[1]
@@ -55570,7 +49172,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETNE x))
-	// cond:
 	// result: (SETEQ x)
 	for {
 		if v.AuxInt != 1 {
@@ -55586,7 +49187,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETEQ x))
-	// cond:
 	// result: (SETNE x)
 	for {
 		if v.AuxInt != 1 {
@@ -55602,7 +49202,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETL x))
-	// cond:
 	// result: (SETGE x)
 	for {
 		if v.AuxInt != 1 {
@@ -55618,7 +49217,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETGE x))
-	// cond:
 	// result: (SETL x)
 	for {
 		if v.AuxInt != 1 {
@@ -55634,7 +49232,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETLE x))
-	// cond:
 	// result: (SETG x)
 	for {
 		if v.AuxInt != 1 {
@@ -55650,7 +49247,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETG x))
-	// cond:
 	// result: (SETLE x)
 	for {
 		if v.AuxInt != 1 {
@@ -55666,7 +49262,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETB x))
-	// cond:
 	// result: (SETAE x)
 	for {
 		if v.AuxInt != 1 {
@@ -55682,7 +49277,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETAE x))
-	// cond:
 	// result: (SETB x)
 	for {
 		if v.AuxInt != 1 {
@@ -55698,7 +49292,6 @@
 		return true
 	}
 	// match: (XORLconst [1] (SETBE x))
-	// cond:
 	// result: (SETA x)
 	for {
 		if v.AuxInt != 1 {
@@ -55717,7 +49310,6 @@
 }
 func rewriteValueAMD64_OpAMD64XORLconst_10(v *Value) bool {
 	// match: (XORLconst [1] (SETA x))
-	// cond:
 	// result: (SETBE x)
 	for {
 		if v.AuxInt != 1 {
@@ -55733,7 +49325,6 @@
 		return true
 	}
 	// match: (XORLconst [c] (XORLconst [d] x))
-	// cond:
 	// result: (XORLconst [c ^ d] x)
 	for {
 		c := v.AuxInt
@@ -55749,7 +49340,6 @@
 		return true
 	}
 	// match: (XORLconst [c] (BTCLconst [d] x))
-	// cond:
 	// result: (XORLconst [c ^ 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -55779,7 +49369,6 @@
 		return true
 	}
 	// match: (XORLconst [c] (MOVLconst [d]))
-	// cond:
 	// result: (MOVLconst [c^d])
 	for {
 		c := v.AuxInt
@@ -55899,7 +49488,6 @@
 		return true
 	}
 	// match: (XORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
-	// cond:
 	// result: (XORL x (MOVLf2i y))
 	for {
 		off := v.AuxInt
@@ -55908,15 +49496,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSSstore {
+		if v_2.Op != OpAMD64MOVSSstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -55999,15 +49581,9 @@
 		}
 		y := v_0.Args[1]
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0.Op != OpAMD64MOVQconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_0_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTCQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -56025,15 +49601,9 @@
 		}
 		y := v_1.Args[1]
 		v_1_0 := v_1.Args[0]
-		if v_1_0.Op != OpAMD64MOVQconst {
+		if v_1_0.Op != OpAMD64MOVQconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 			break
 		}
-		if v_1_0.AuxInt != 1 {
-			break
-		}
-		if !(!config.nacl) {
-			break
-		}
 		v.reset(OpAMD64BTCQ)
 		v.AddArg(x)
 		v.AddArg(y)
@@ -56129,12 +49699,9 @@
 			break
 		}
 		d := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
@@ -56156,19 +49723,15 @@
 			break
 		}
 		c := v_1.AuxInt
-		if x != v_1.Args[0] {
+		if x != v_1.Args[0] || !(d == 64-c) {
 			break
 		}
-		if !(d == 64-c) {
-			break
-		}
 		v.reset(OpAMD64ROLQconst)
 		v.AuxInt = c
 		v.AddArg(x)
 		return true
 	}
 	// match: (XORQ x x)
-	// cond:
 	// result: (MOVQconst [0])
 	for {
 		x := v.Args[1]
@@ -56251,7 +49814,6 @@
 		return true
 	}
 	// match: (XORQconst [c] (XORQconst [d] x))
-	// cond:
 	// result: (XORQconst [c ^ d] x)
 	for {
 		c := v.AuxInt
@@ -56267,7 +49829,6 @@
 		return true
 	}
 	// match: (XORQconst [c] (BTCQconst [d] x))
-	// cond:
 	// result: (XORQconst [c ^ 1<<uint32(d)] x)
 	for {
 		c := v.AuxInt
@@ -56283,7 +49844,6 @@
 		return true
 	}
 	// match: (XORQconst [0] x)
-	// cond:
 	// result: x
 	for {
 		if v.AuxInt != 0 {
@@ -56296,7 +49856,6 @@
 		return true
 	}
 	// match: (XORQconst [c] (MOVQconst [d]))
-	// cond:
 	// result: (MOVQconst [c^d])
 	for {
 		c := v.AuxInt
@@ -56416,7 +49975,6 @@
 		return true
 	}
 	// match: (XORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
-	// cond:
 	// result: (XORQ x (MOVQf2i y))
 	for {
 		off := v.AuxInt
@@ -56425,15 +49983,9 @@
 		x := v.Args[0]
 		ptr := v.Args[1]
 		v_2 := v.Args[2]
-		if v_2.Op != OpAMD64MOVSDstore {
+		if v_2.Op != OpAMD64MOVSDstore || v_2.AuxInt != off || v_2.Aux != sym {
 			break
 		}
-		if v_2.AuxInt != off {
-			break
-		}
-		if v_2.Aux != sym {
-			break
-		}
 		_ = v_2.Args[2]
 		if ptr != v_2.Args[0] {
 			break
@@ -56504,7 +50056,6 @@
 }
 func rewriteValueAMD64_OpAdd16_0(v *Value) bool {
 	// match: (Add16 x y)
-	// cond:
 	// result: (ADDL x y)
 	for {
 		y := v.Args[1]
@@ -56517,7 +50068,6 @@
 }
 func rewriteValueAMD64_OpAdd32_0(v *Value) bool {
 	// match: (Add32 x y)
-	// cond:
 	// result: (ADDL x y)
 	for {
 		y := v.Args[1]
@@ -56530,7 +50080,6 @@
 }
 func rewriteValueAMD64_OpAdd32F_0(v *Value) bool {
 	// match: (Add32F x y)
-	// cond:
 	// result: (ADDSS x y)
 	for {
 		y := v.Args[1]
@@ -56543,7 +50092,6 @@
 }
 func rewriteValueAMD64_OpAdd64_0(v *Value) bool {
 	// match: (Add64 x y)
-	// cond:
 	// result: (ADDQ x y)
 	for {
 		y := v.Args[1]
@@ -56556,7 +50104,6 @@
 }
 func rewriteValueAMD64_OpAdd64F_0(v *Value) bool {
 	// match: (Add64F x y)
-	// cond:
 	// result: (ADDSD x y)
 	for {
 		y := v.Args[1]
@@ -56569,7 +50116,6 @@
 }
 func rewriteValueAMD64_OpAdd8_0(v *Value) bool {
 	// match: (Add8 x y)
-	// cond:
 	// result: (ADDL x y)
 	for {
 		y := v.Args[1]
@@ -56648,7 +50194,6 @@
 }
 func rewriteValueAMD64_OpAnd16_0(v *Value) bool {
 	// match: (And16 x y)
-	// cond:
 	// result: (ANDL x y)
 	for {
 		y := v.Args[1]
@@ -56661,7 +50206,6 @@
 }
 func rewriteValueAMD64_OpAnd32_0(v *Value) bool {
 	// match: (And32 x y)
-	// cond:
 	// result: (ANDL x y)
 	for {
 		y := v.Args[1]
@@ -56674,7 +50218,6 @@
 }
 func rewriteValueAMD64_OpAnd64_0(v *Value) bool {
 	// match: (And64 x y)
-	// cond:
 	// result: (ANDQ x y)
 	for {
 		y := v.Args[1]
@@ -56687,7 +50230,6 @@
 }
 func rewriteValueAMD64_OpAnd8_0(v *Value) bool {
 	// match: (And8 x y)
-	// cond:
 	// result: (ANDL x y)
 	for {
 		y := v.Args[1]
@@ -56700,7 +50242,6 @@
 }
 func rewriteValueAMD64_OpAndB_0(v *Value) bool {
 	// match: (AndB x y)
-	// cond:
 	// result: (ANDL x y)
 	for {
 		y := v.Args[1]
@@ -56715,7 +50256,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (AtomicAdd32 ptr val mem)
-	// cond:
 	// result: (AddTupleFirst32 val (XADDLlock val ptr mem))
 	for {
 		mem := v.Args[2]
@@ -56735,7 +50275,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (AtomicAdd64 ptr val mem)
-	// cond:
 	// result: (AddTupleFirst64 val (XADDQlock val ptr mem))
 	for {
 		mem := v.Args[2]
@@ -56753,7 +50292,6 @@
 }
 func rewriteValueAMD64_OpAtomicAnd8_0(v *Value) bool {
 	// match: (AtomicAnd8 ptr val mem)
-	// cond:
 	// result: (ANDBlock ptr val mem)
 	for {
 		mem := v.Args[2]
@@ -56768,7 +50306,6 @@
 }
 func rewriteValueAMD64_OpAtomicCompareAndSwap32_0(v *Value) bool {
 	// match: (AtomicCompareAndSwap32 ptr old new_ mem)
-	// cond:
 	// result: (CMPXCHGLlock ptr old new_ mem)
 	for {
 		mem := v.Args[3]
@@ -56785,7 +50322,6 @@
 }
 func rewriteValueAMD64_OpAtomicCompareAndSwap64_0(v *Value) bool {
 	// match: (AtomicCompareAndSwap64 ptr old new_ mem)
-	// cond:
 	// result: (CMPXCHGQlock ptr old new_ mem)
 	for {
 		mem := v.Args[3]
@@ -56802,7 +50338,6 @@
 }
 func rewriteValueAMD64_OpAtomicExchange32_0(v *Value) bool {
 	// match: (AtomicExchange32 ptr val mem)
-	// cond:
 	// result: (XCHGL val ptr mem)
 	for {
 		mem := v.Args[2]
@@ -56817,7 +50352,6 @@
 }
 func rewriteValueAMD64_OpAtomicExchange64_0(v *Value) bool {
 	// match: (AtomicExchange64 ptr val mem)
-	// cond:
 	// result: (XCHGQ val ptr mem)
 	for {
 		mem := v.Args[2]
@@ -56832,7 +50366,6 @@
 }
 func rewriteValueAMD64_OpAtomicLoad32_0(v *Value) bool {
 	// match: (AtomicLoad32 ptr mem)
-	// cond:
 	// result: (MOVLatomicload ptr mem)
 	for {
 		mem := v.Args[1]
@@ -56845,7 +50378,6 @@
 }
 func rewriteValueAMD64_OpAtomicLoad64_0(v *Value) bool {
 	// match: (AtomicLoad64 ptr mem)
-	// cond:
 	// result: (MOVQatomicload ptr mem)
 	for {
 		mem := v.Args[1]
@@ -56858,7 +50390,6 @@
 }
 func rewriteValueAMD64_OpAtomicLoad8_0(v *Value) bool {
 	// match: (AtomicLoad8 ptr mem)
-	// cond:
 	// result: (MOVBatomicload ptr mem)
 	for {
 		mem := v.Args[1]
@@ -56904,7 +50435,6 @@
 }
 func rewriteValueAMD64_OpAtomicOr8_0(v *Value) bool {
 	// match: (AtomicOr8 ptr val mem)
-	// cond:
 	// result: (ORBlock ptr val mem)
 	for {
 		mem := v.Args[2]
@@ -56921,7 +50451,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (AtomicStore32 ptr val mem)
-	// cond:
 	// result: (Select1 (XCHGL <types.NewTuple(typ.UInt32,types.TypeMem)> val ptr mem))
 	for {
 		mem := v.Args[2]
@@ -56940,7 +50469,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (AtomicStore64 ptr val mem)
-	// cond:
 	// result: (Select1 (XCHGQ <types.NewTuple(typ.UInt64,types.TypeMem)> val ptr mem))
 	for {
 		mem := v.Args[2]
@@ -56999,7 +50527,6 @@
 }
 func rewriteValueAMD64_OpAvg64u_0(v *Value) bool {
 	// match: (Avg64u x y)
-	// cond:
 	// result: (AVGQU x y)
 	for {
 		y := v.Args[1]
@@ -57014,7 +50541,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (BitLen16 x)
-	// cond:
 	// result: (BSRL (LEAL1 <typ.UInt32> [1] (MOVWQZX <typ.UInt32> x) (MOVWQZX <typ.UInt32> x)))
 	for {
 		x := v.Args[0]
@@ -57035,7 +50561,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (BitLen32 x)
-	// cond:
 	// result: (Select0 (BSRQ (LEAQ1 <typ.UInt64> [1] (MOVLQZX <typ.UInt64> x) (MOVLQZX <typ.UInt64> x))))
 	for {
 		x := v.Args[0]
@@ -57058,7 +50583,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (BitLen64 <t> x)
-	// cond:
 	// result: (ADDQconst [1] (CMOVQEQ <t> (Select0 <t> (BSRQ x)) (MOVQconst <t> [-1]) (Select1 <types.TypeFlags> (BSRQ x))))
 	for {
 		t := v.Type
@@ -57087,7 +50611,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (BitLen8 x)
-	// cond:
 	// result: (BSRL (LEAL1 <typ.UInt32> [1] (MOVBQZX <typ.UInt32> x) (MOVBQZX <typ.UInt32> x)))
 	for {
 		x := v.Args[0]
@@ -57106,7 +50629,6 @@
 }
 func rewriteValueAMD64_OpBswap32_0(v *Value) bool {
 	// match: (Bswap32 x)
-	// cond:
 	// result: (BSWAPL x)
 	for {
 		x := v.Args[0]
@@ -57117,7 +50639,6 @@
 }
 func rewriteValueAMD64_OpBswap64_0(v *Value) bool {
 	// match: (Bswap64 x)
-	// cond:
 	// result: (BSWAPQ x)
 	for {
 		x := v.Args[0]
@@ -57128,7 +50649,6 @@
 }
 func rewriteValueAMD64_OpCeil_0(v *Value) bool {
 	// match: (Ceil x)
-	// cond:
 	// result: (ROUNDSD [2] x)
 	for {
 		x := v.Args[0]
@@ -57140,7 +50660,6 @@
 }
 func rewriteValueAMD64_OpClosureCall_0(v *Value) bool {
 	// match: (ClosureCall [argwid] entry closure mem)
-	// cond:
 	// result: (CALLclosure [argwid] entry closure mem)
 	for {
 		argwid := v.AuxInt
@@ -57157,7 +50676,6 @@
 }
 func rewriteValueAMD64_OpCom16_0(v *Value) bool {
 	// match: (Com16 x)
-	// cond:
 	// result: (NOTL x)
 	for {
 		x := v.Args[0]
@@ -57168,7 +50686,6 @@
 }
 func rewriteValueAMD64_OpCom32_0(v *Value) bool {
 	// match: (Com32 x)
-	// cond:
 	// result: (NOTL x)
 	for {
 		x := v.Args[0]
@@ -57179,7 +50696,6 @@
 }
 func rewriteValueAMD64_OpCom64_0(v *Value) bool {
 	// match: (Com64 x)
-	// cond:
 	// result: (NOTQ x)
 	for {
 		x := v.Args[0]
@@ -57190,7 +50706,6 @@
 }
 func rewriteValueAMD64_OpCom8_0(v *Value) bool {
 	// match: (Com8 x)
-	// cond:
 	// result: (NOTL x)
 	for {
 		x := v.Args[0]
@@ -58262,7 +51777,6 @@
 }
 func rewriteValueAMD64_OpConst16_0(v *Value) bool {
 	// match: (Const16 [val])
-	// cond:
 	// result: (MOVLconst [val])
 	for {
 		val := v.AuxInt
@@ -58273,7 +51787,6 @@
 }
 func rewriteValueAMD64_OpConst32_0(v *Value) bool {
 	// match: (Const32 [val])
-	// cond:
 	// result: (MOVLconst [val])
 	for {
 		val := v.AuxInt
@@ -58284,7 +51797,6 @@
 }
 func rewriteValueAMD64_OpConst32F_0(v *Value) bool {
 	// match: (Const32F [val])
-	// cond:
 	// result: (MOVSSconst [val])
 	for {
 		val := v.AuxInt
@@ -58295,7 +51807,6 @@
 }
 func rewriteValueAMD64_OpConst64_0(v *Value) bool {
 	// match: (Const64 [val])
-	// cond:
 	// result: (MOVQconst [val])
 	for {
 		val := v.AuxInt
@@ -58306,7 +51817,6 @@
 }
 func rewriteValueAMD64_OpConst64F_0(v *Value) bool {
 	// match: (Const64F [val])
-	// cond:
 	// result: (MOVSDconst [val])
 	for {
 		val := v.AuxInt
@@ -58317,7 +51827,6 @@
 }
 func rewriteValueAMD64_OpConst8_0(v *Value) bool {
 	// match: (Const8 [val])
-	// cond:
 	// result: (MOVLconst [val])
 	for {
 		val := v.AuxInt
@@ -58328,7 +51837,6 @@
 }
 func rewriteValueAMD64_OpConstBool_0(v *Value) bool {
 	// match: (ConstBool [b])
-	// cond:
 	// result: (MOVLconst [b])
 	for {
 		b := v.AuxInt
@@ -58368,7 +51876,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Ctz16 x)
-	// cond:
 	// result: (BSFL (BTSLconst <typ.UInt32> [16] x))
 	for {
 		x := v.Args[0]
@@ -58382,7 +51889,6 @@
 }
 func rewriteValueAMD64_OpCtz16NonZero_0(v *Value) bool {
 	// match: (Ctz16NonZero x)
-	// cond:
 	// result: (BSFL x)
 	for {
 		x := v.Args[0]
@@ -58395,7 +51901,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Ctz32 x)
-	// cond:
 	// result: (Select0 (BSFQ (BTSQconst <typ.UInt64> [32] x)))
 	for {
 		x := v.Args[0]
@@ -58411,7 +51916,6 @@
 }
 func rewriteValueAMD64_OpCtz32NonZero_0(v *Value) bool {
 	// match: (Ctz32NonZero x)
-	// cond:
 	// result: (BSFL x)
 	for {
 		x := v.Args[0]
@@ -58424,7 +51928,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Ctz64 <t> x)
-	// cond:
 	// result: (CMOVQEQ (Select0 <t> (BSFQ x)) (MOVQconst <t> [64]) (Select1 <types.TypeFlags> (BSFQ x)))
 	for {
 		t := v.Type
@@ -58450,7 +51953,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Ctz64NonZero x)
-	// cond:
 	// result: (Select0 (BSFQ x))
 	for {
 		x := v.Args[0]
@@ -58465,7 +51967,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Ctz8 x)
-	// cond:
 	// result: (BSFL (BTSLconst <typ.UInt32> [ 8] x))
 	for {
 		x := v.Args[0]
@@ -58479,7 +51980,6 @@
 }
 func rewriteValueAMD64_OpCtz8NonZero_0(v *Value) bool {
 	// match: (Ctz8NonZero x)
-	// cond:
 	// result: (BSFL x)
 	for {
 		x := v.Args[0]
@@ -58490,7 +51990,6 @@
 }
 func rewriteValueAMD64_OpCvt32Fto32_0(v *Value) bool {
 	// match: (Cvt32Fto32 x)
-	// cond:
 	// result: (CVTTSS2SL x)
 	for {
 		x := v.Args[0]
@@ -58501,7 +52000,6 @@
 }
 func rewriteValueAMD64_OpCvt32Fto64_0(v *Value) bool {
 	// match: (Cvt32Fto64 x)
-	// cond:
 	// result: (CVTTSS2SQ x)
 	for {
 		x := v.Args[0]
@@ -58512,7 +52010,6 @@
 }
 func rewriteValueAMD64_OpCvt32Fto64F_0(v *Value) bool {
 	// match: (Cvt32Fto64F x)
-	// cond:
 	// result: (CVTSS2SD x)
 	for {
 		x := v.Args[0]
@@ -58523,7 +52020,6 @@
 }
 func rewriteValueAMD64_OpCvt32to32F_0(v *Value) bool {
 	// match: (Cvt32to32F x)
-	// cond:
 	// result: (CVTSL2SS x)
 	for {
 		x := v.Args[0]
@@ -58534,7 +52030,6 @@
 }
 func rewriteValueAMD64_OpCvt32to64F_0(v *Value) bool {
 	// match: (Cvt32to64F x)
-	// cond:
 	// result: (CVTSL2SD x)
 	for {
 		x := v.Args[0]
@@ -58545,7 +52040,6 @@
 }
 func rewriteValueAMD64_OpCvt64Fto32_0(v *Value) bool {
 	// match: (Cvt64Fto32 x)
-	// cond:
 	// result: (CVTTSD2SL x)
 	for {
 		x := v.Args[0]
@@ -58556,7 +52050,6 @@
 }
 func rewriteValueAMD64_OpCvt64Fto32F_0(v *Value) bool {
 	// match: (Cvt64Fto32F x)
-	// cond:
 	// result: (CVTSD2SS x)
 	for {
 		x := v.Args[0]
@@ -58567,7 +52060,6 @@
 }
 func rewriteValueAMD64_OpCvt64Fto64_0(v *Value) bool {
 	// match: (Cvt64Fto64 x)
-	// cond:
 	// result: (CVTTSD2SQ x)
 	for {
 		x := v.Args[0]
@@ -58578,7 +52070,6 @@
 }
 func rewriteValueAMD64_OpCvt64to32F_0(v *Value) bool {
 	// match: (Cvt64to32F x)
-	// cond:
 	// result: (CVTSQ2SS x)
 	for {
 		x := v.Args[0]
@@ -58589,7 +52080,6 @@
 }
 func rewriteValueAMD64_OpCvt64to64F_0(v *Value) bool {
 	// match: (Cvt64to64F x)
-	// cond:
 	// result: (CVTSQ2SD x)
 	for {
 		x := v.Args[0]
@@ -58600,7 +52090,6 @@
 }
 func rewriteValueAMD64_OpDiv128u_0(v *Value) bool {
 	// match: (Div128u xhi xlo y)
-	// cond:
 	// result: (DIVQU2 xhi xlo y)
 	for {
 		y := v.Args[2]
@@ -58617,7 +52106,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div16 [a] x y)
-	// cond:
 	// result: (Select0 (DIVW [a] x y))
 	for {
 		a := v.AuxInt
@@ -58636,7 +52124,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div16u x y)
-	// cond:
 	// result: (Select0 (DIVWU x y))
 	for {
 		y := v.Args[1]
@@ -58653,7 +52140,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div32 [a] x y)
-	// cond:
 	// result: (Select0 (DIVL [a] x y))
 	for {
 		a := v.AuxInt
@@ -58670,7 +52156,6 @@
 }
 func rewriteValueAMD64_OpDiv32F_0(v *Value) bool {
 	// match: (Div32F x y)
-	// cond:
 	// result: (DIVSS x y)
 	for {
 		y := v.Args[1]
@@ -58685,7 +52170,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div32u x y)
-	// cond:
 	// result: (Select0 (DIVLU x y))
 	for {
 		y := v.Args[1]
@@ -58702,7 +52186,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div64 [a] x y)
-	// cond:
 	// result: (Select0 (DIVQ [a] x y))
 	for {
 		a := v.AuxInt
@@ -58719,7 +52202,6 @@
 }
 func rewriteValueAMD64_OpDiv64F_0(v *Value) bool {
 	// match: (Div64F x y)
-	// cond:
 	// result: (DIVSD x y)
 	for {
 		y := v.Args[1]
@@ -58734,7 +52216,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div64u x y)
-	// cond:
 	// result: (Select0 (DIVQU x y))
 	for {
 		y := v.Args[1]
@@ -58751,7 +52232,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div8 x y)
-	// cond:
 	// result: (Select0 (DIVW (SignExt8to16 x) (SignExt8to16 y)))
 	for {
 		y := v.Args[1]
@@ -58772,7 +52252,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Div8u x y)
-	// cond:
 	// result: (Select0 (DIVWU (ZeroExt8to16 x) (ZeroExt8to16 y)))
 	for {
 		y := v.Args[1]
@@ -58792,7 +52271,6 @@
 func rewriteValueAMD64_OpEq16_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq16 x y)
-	// cond:
 	// result: (SETEQ (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -58808,7 +52286,6 @@
 func rewriteValueAMD64_OpEq32_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq32 x y)
-	// cond:
 	// result: (SETEQ (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -58824,7 +52301,6 @@
 func rewriteValueAMD64_OpEq32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq32F x y)
-	// cond:
 	// result: (SETEQF (UCOMISS x y))
 	for {
 		y := v.Args[1]
@@ -58840,7 +52316,6 @@
 func rewriteValueAMD64_OpEq64_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq64 x y)
-	// cond:
 	// result: (SETEQ (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -58856,7 +52331,6 @@
 func rewriteValueAMD64_OpEq64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq64F x y)
-	// cond:
 	// result: (SETEQF (UCOMISD x y))
 	for {
 		y := v.Args[1]
@@ -58872,7 +52346,6 @@
 func rewriteValueAMD64_OpEq8_0(v *Value) bool {
 	b := v.Block
 	// match: (Eq8 x y)
-	// cond:
 	// result: (SETEQ (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -58888,7 +52361,6 @@
 func rewriteValueAMD64_OpEqB_0(v *Value) bool {
 	b := v.Block
 	// match: (EqB x y)
-	// cond:
 	// result: (SETEQ (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -58940,7 +52412,6 @@
 }
 func rewriteValueAMD64_OpFloor_0(v *Value) bool {
 	// match: (Floor x)
-	// cond:
 	// result: (ROUNDSD [1] x)
 	for {
 		x := v.Args[0]
@@ -58953,7 +52424,6 @@
 func rewriteValueAMD64_OpGeq16_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq16 x y)
-	// cond:
 	// result: (SETGE (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -58969,7 +52439,6 @@
 func rewriteValueAMD64_OpGeq16U_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq16U x y)
-	// cond:
 	// result: (SETAE (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -58985,7 +52454,6 @@
 func rewriteValueAMD64_OpGeq32_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq32 x y)
-	// cond:
 	// result: (SETGE (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59001,7 +52469,6 @@
 func rewriteValueAMD64_OpGeq32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq32F x y)
-	// cond:
 	// result: (SETGEF (UCOMISS x y))
 	for {
 		y := v.Args[1]
@@ -59017,7 +52484,6 @@
 func rewriteValueAMD64_OpGeq32U_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq32U x y)
-	// cond:
 	// result: (SETAE (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59033,7 +52499,6 @@
 func rewriteValueAMD64_OpGeq64_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq64 x y)
-	// cond:
 	// result: (SETGE (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59049,7 +52514,6 @@
 func rewriteValueAMD64_OpGeq64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq64F x y)
-	// cond:
 	// result: (SETGEF (UCOMISD x y))
 	for {
 		y := v.Args[1]
@@ -59065,7 +52529,6 @@
 func rewriteValueAMD64_OpGeq64U_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq64U x y)
-	// cond:
 	// result: (SETAE (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59081,7 +52544,6 @@
 func rewriteValueAMD64_OpGeq8_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq8 x y)
-	// cond:
 	// result: (SETGE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59097,7 +52559,6 @@
 func rewriteValueAMD64_OpGeq8U_0(v *Value) bool {
 	b := v.Block
 	// match: (Geq8U x y)
-	// cond:
 	// result: (SETAE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59112,7 +52573,6 @@
 }
 func rewriteValueAMD64_OpGetCallerPC_0(v *Value) bool {
 	// match: (GetCallerPC)
-	// cond:
 	// result: (LoweredGetCallerPC)
 	for {
 		v.reset(OpAMD64LoweredGetCallerPC)
@@ -59121,7 +52581,6 @@
 }
 func rewriteValueAMD64_OpGetCallerSP_0(v *Value) bool {
 	// match: (GetCallerSP)
-	// cond:
 	// result: (LoweredGetCallerSP)
 	for {
 		v.reset(OpAMD64LoweredGetCallerSP)
@@ -59130,7 +52589,6 @@
 }
 func rewriteValueAMD64_OpGetClosurePtr_0(v *Value) bool {
 	// match: (GetClosurePtr)
-	// cond:
 	// result: (LoweredGetClosurePtr)
 	for {
 		v.reset(OpAMD64LoweredGetClosurePtr)
@@ -59139,7 +52597,6 @@
 }
 func rewriteValueAMD64_OpGetG_0(v *Value) bool {
 	// match: (GetG mem)
-	// cond:
 	// result: (LoweredGetG mem)
 	for {
 		mem := v.Args[0]
@@ -59151,7 +52608,6 @@
 func rewriteValueAMD64_OpGreater16_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater16 x y)
-	// cond:
 	// result: (SETG (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59167,7 +52623,6 @@
 func rewriteValueAMD64_OpGreater16U_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater16U x y)
-	// cond:
 	// result: (SETA (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59183,7 +52638,6 @@
 func rewriteValueAMD64_OpGreater32_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater32 x y)
-	// cond:
 	// result: (SETG (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59199,7 +52653,6 @@
 func rewriteValueAMD64_OpGreater32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater32F x y)
-	// cond:
 	// result: (SETGF (UCOMISS x y))
 	for {
 		y := v.Args[1]
@@ -59215,7 +52668,6 @@
 func rewriteValueAMD64_OpGreater32U_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater32U x y)
-	// cond:
 	// result: (SETA (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59231,7 +52683,6 @@
 func rewriteValueAMD64_OpGreater64_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater64 x y)
-	// cond:
 	// result: (SETG (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59247,7 +52698,6 @@
 func rewriteValueAMD64_OpGreater64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater64F x y)
-	// cond:
 	// result: (SETGF (UCOMISD x y))
 	for {
 		y := v.Args[1]
@@ -59263,7 +52713,6 @@
 func rewriteValueAMD64_OpGreater64U_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater64U x y)
-	// cond:
 	// result: (SETA (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59279,7 +52728,6 @@
 func rewriteValueAMD64_OpGreater8_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater8 x y)
-	// cond:
 	// result: (SETG (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59295,7 +52743,6 @@
 func rewriteValueAMD64_OpGreater8U_0(v *Value) bool {
 	b := v.Block
 	// match: (Greater8U x y)
-	// cond:
 	// result: (SETA (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59310,7 +52757,6 @@
 }
 func rewriteValueAMD64_OpHmul32_0(v *Value) bool {
 	// match: (Hmul32 x y)
-	// cond:
 	// result: (HMULL x y)
 	for {
 		y := v.Args[1]
@@ -59323,7 +52769,6 @@
 }
 func rewriteValueAMD64_OpHmul32u_0(v *Value) bool {
 	// match: (Hmul32u x y)
-	// cond:
 	// result: (HMULLU x y)
 	for {
 		y := v.Args[1]
@@ -59336,7 +52781,6 @@
 }
 func rewriteValueAMD64_OpHmul64_0(v *Value) bool {
 	// match: (Hmul64 x y)
-	// cond:
 	// result: (HMULQ x y)
 	for {
 		y := v.Args[1]
@@ -59349,7 +52793,6 @@
 }
 func rewriteValueAMD64_OpHmul64u_0(v *Value) bool {
 	// match: (Hmul64u x y)
-	// cond:
 	// result: (HMULQU x y)
 	for {
 		y := v.Args[1]
@@ -59362,7 +52805,6 @@
 }
 func rewriteValueAMD64_OpInt64Hi_0(v *Value) bool {
 	// match: (Int64Hi x)
-	// cond:
 	// result: (SHRQconst [32] x)
 	for {
 		x := v.Args[0]
@@ -59374,7 +52816,6 @@
 }
 func rewriteValueAMD64_OpInt64Lo_0(v *Value) bool {
 	// match: (Int64Lo x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -59386,7 +52827,6 @@
 }
 func rewriteValueAMD64_OpInterCall_0(v *Value) bool {
 	// match: (InterCall [argwid] entry mem)
-	// cond:
 	// result: (CALLinter [argwid] entry mem)
 	for {
 		argwid := v.AuxInt
@@ -59511,7 +52951,6 @@
 func rewriteValueAMD64_OpLeq16_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq16 x y)
-	// cond:
 	// result: (SETLE (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59527,7 +52966,6 @@
 func rewriteValueAMD64_OpLeq16U_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq16U x y)
-	// cond:
 	// result: (SETBE (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59543,7 +52981,6 @@
 func rewriteValueAMD64_OpLeq32_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq32 x y)
-	// cond:
 	// result: (SETLE (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59559,7 +52996,6 @@
 func rewriteValueAMD64_OpLeq32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq32F x y)
-	// cond:
 	// result: (SETGEF (UCOMISS y x))
 	for {
 		y := v.Args[1]
@@ -59575,7 +53011,6 @@
 func rewriteValueAMD64_OpLeq32U_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq32U x y)
-	// cond:
 	// result: (SETBE (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59591,7 +53026,6 @@
 func rewriteValueAMD64_OpLeq64_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq64 x y)
-	// cond:
 	// result: (SETLE (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59607,7 +53041,6 @@
 func rewriteValueAMD64_OpLeq64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq64F x y)
-	// cond:
 	// result: (SETGEF (UCOMISD y x))
 	for {
 		y := v.Args[1]
@@ -59623,7 +53056,6 @@
 func rewriteValueAMD64_OpLeq64U_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq64U x y)
-	// cond:
 	// result: (SETBE (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59639,7 +53071,6 @@
 func rewriteValueAMD64_OpLeq8_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq8 x y)
-	// cond:
 	// result: (SETLE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59655,7 +53086,6 @@
 func rewriteValueAMD64_OpLeq8U_0(v *Value) bool {
 	b := v.Block
 	// match: (Leq8U x y)
-	// cond:
 	// result: (SETBE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59671,7 +53101,6 @@
 func rewriteValueAMD64_OpLess16_0(v *Value) bool {
 	b := v.Block
 	// match: (Less16 x y)
-	// cond:
 	// result: (SETL (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59687,7 +53116,6 @@
 func rewriteValueAMD64_OpLess16U_0(v *Value) bool {
 	b := v.Block
 	// match: (Less16U x y)
-	// cond:
 	// result: (SETB (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -59703,7 +53131,6 @@
 func rewriteValueAMD64_OpLess32_0(v *Value) bool {
 	b := v.Block
 	// match: (Less32 x y)
-	// cond:
 	// result: (SETL (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59719,7 +53146,6 @@
 func rewriteValueAMD64_OpLess32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Less32F x y)
-	// cond:
 	// result: (SETGF (UCOMISS y x))
 	for {
 		y := v.Args[1]
@@ -59735,7 +53161,6 @@
 func rewriteValueAMD64_OpLess32U_0(v *Value) bool {
 	b := v.Block
 	// match: (Less32U x y)
-	// cond:
 	// result: (SETB (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -59751,7 +53176,6 @@
 func rewriteValueAMD64_OpLess64_0(v *Value) bool {
 	b := v.Block
 	// match: (Less64 x y)
-	// cond:
 	// result: (SETL (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59767,7 +53191,6 @@
 func rewriteValueAMD64_OpLess64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Less64F x y)
-	// cond:
 	// result: (SETGF (UCOMISD y x))
 	for {
 		y := v.Args[1]
@@ -59783,7 +53206,6 @@
 func rewriteValueAMD64_OpLess64U_0(v *Value) bool {
 	b := v.Block
 	// match: (Less64U x y)
-	// cond:
 	// result: (SETB (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -59799,7 +53221,6 @@
 func rewriteValueAMD64_OpLess8_0(v *Value) bool {
 	b := v.Block
 	// match: (Less8 x y)
-	// cond:
 	// result: (SETL (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -59815,7 +53236,6 @@
 func rewriteValueAMD64_OpLess8U_0(v *Value) bool {
 	b := v.Block
 	// match: (Less8U x y)
-	// cond:
 	// result: (SETB (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -60618,7 +54038,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod16 [a] x y)
-	// cond:
 	// result: (Select1 (DIVW [a] x y))
 	for {
 		a := v.AuxInt
@@ -60637,7 +54056,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod16u x y)
-	// cond:
 	// result: (Select1 (DIVWU x y))
 	for {
 		y := v.Args[1]
@@ -60654,7 +54072,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod32 [a] x y)
-	// cond:
 	// result: (Select1 (DIVL [a] x y))
 	for {
 		a := v.AuxInt
@@ -60673,7 +54090,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod32u x y)
-	// cond:
 	// result: (Select1 (DIVLU x y))
 	for {
 		y := v.Args[1]
@@ -60690,7 +54106,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod64 [a] x y)
-	// cond:
 	// result: (Select1 (DIVQ [a] x y))
 	for {
 		a := v.AuxInt
@@ -60709,7 +54124,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod64u x y)
-	// cond:
 	// result: (Select1 (DIVQU x y))
 	for {
 		y := v.Args[1]
@@ -60726,7 +54140,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod8 x y)
-	// cond:
 	// result: (Select1 (DIVW (SignExt8to16 x) (SignExt8to16 y)))
 	for {
 		y := v.Args[1]
@@ -60747,7 +54160,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Mod8u x y)
-	// cond:
 	// result: (Select1 (DIVWU (ZeroExt8to16 x) (ZeroExt8to16 y)))
 	for {
 		y := v.Args[1]
@@ -60769,7 +54181,6 @@
 	config := b.Func.Config
 	typ := &b.Func.Config.Types
 	// match: (Move [0] _ _ mem)
-	// cond:
 	// result: mem
 	for {
 		if v.AuxInt != 0 {
@@ -60782,7 +54193,6 @@
 		return true
 	}
 	// match: (Move [1] dst src mem)
-	// cond:
 	// result: (MOVBstore dst (MOVBload src mem) mem)
 	for {
 		if v.AuxInt != 1 {
@@ -60801,7 +54211,6 @@
 		return true
 	}
 	// match: (Move [2] dst src mem)
-	// cond:
 	// result: (MOVWstore dst (MOVWload src mem) mem)
 	for {
 		if v.AuxInt != 2 {
@@ -60820,7 +54229,6 @@
 		return true
 	}
 	// match: (Move [4] dst src mem)
-	// cond:
 	// result: (MOVLstore dst (MOVLload src mem) mem)
 	for {
 		if v.AuxInt != 4 {
@@ -60839,7 +54247,6 @@
 		return true
 	}
 	// match: (Move [8] dst src mem)
-	// cond:
 	// result: (MOVQstore dst (MOVQload src mem) mem)
 	for {
 		if v.AuxInt != 8 {
@@ -60911,7 +54318,6 @@
 		return true
 	}
 	// match: (Move [32] dst src mem)
-	// cond:
 	// result: (Move [16] (OffPtr <dst.Type> dst [16]) (OffPtr <src.Type> src [16]) (Move [16] dst src mem))
 	for {
 		if v.AuxInt != 32 {
@@ -61007,7 +54413,6 @@
 	config := b.Func.Config
 	typ := &b.Func.Config.Types
 	// match: (Move [3] dst src mem)
-	// cond:
 	// result: (MOVBstore [2] dst (MOVBload [2] src mem) (MOVWstore dst (MOVWload src mem) mem))
 	for {
 		if v.AuxInt != 3 {
@@ -61035,7 +54440,6 @@
 		return true
 	}
 	// match: (Move [5] dst src mem)
-	// cond:
 	// result: (MOVBstore [4] dst (MOVBload [4] src mem) (MOVLstore dst (MOVLload src mem) mem))
 	for {
 		if v.AuxInt != 5 {
@@ -61063,7 +54467,6 @@
 		return true
 	}
 	// match: (Move [6] dst src mem)
-	// cond:
 	// result: (MOVWstore [4] dst (MOVWload [4] src mem) (MOVLstore dst (MOVLload src mem) mem))
 	for {
 		if v.AuxInt != 6 {
@@ -61091,7 +54494,6 @@
 		return true
 	}
 	// match: (Move [7] dst src mem)
-	// cond:
 	// result: (MOVLstore [3] dst (MOVLload [3] src mem) (MOVLstore dst (MOVLload src mem) mem))
 	for {
 		if v.AuxInt != 7 {
@@ -61119,7 +54521,6 @@
 		return true
 	}
 	// match: (Move [9] dst src mem)
-	// cond:
 	// result: (MOVBstore [8] dst (MOVBload [8] src mem) (MOVQstore dst (MOVQload src mem) mem))
 	for {
 		if v.AuxInt != 9 {
@@ -61147,7 +54548,6 @@
 		return true
 	}
 	// match: (Move [10] dst src mem)
-	// cond:
 	// result: (MOVWstore [8] dst (MOVWload [8] src mem) (MOVQstore dst (MOVQload src mem) mem))
 	for {
 		if v.AuxInt != 10 {
@@ -61175,7 +54575,6 @@
 		return true
 	}
 	// match: (Move [12] dst src mem)
-	// cond:
 	// result: (MOVLstore [8] dst (MOVLload [8] src mem) (MOVQstore dst (MOVQload src mem) mem))
 	for {
 		if v.AuxInt != 12 {
@@ -61381,7 +54780,6 @@
 }
 func rewriteValueAMD64_OpMul16_0(v *Value) bool {
 	// match: (Mul16 x y)
-	// cond:
 	// result: (MULL x y)
 	for {
 		y := v.Args[1]
@@ -61394,7 +54792,6 @@
 }
 func rewriteValueAMD64_OpMul32_0(v *Value) bool {
 	// match: (Mul32 x y)
-	// cond:
 	// result: (MULL x y)
 	for {
 		y := v.Args[1]
@@ -61407,7 +54804,6 @@
 }
 func rewriteValueAMD64_OpMul32F_0(v *Value) bool {
 	// match: (Mul32F x y)
-	// cond:
 	// result: (MULSS x y)
 	for {
 		y := v.Args[1]
@@ -61420,7 +54816,6 @@
 }
 func rewriteValueAMD64_OpMul64_0(v *Value) bool {
 	// match: (Mul64 x y)
-	// cond:
 	// result: (MULQ x y)
 	for {
 		y := v.Args[1]
@@ -61433,7 +54828,6 @@
 }
 func rewriteValueAMD64_OpMul64F_0(v *Value) bool {
 	// match: (Mul64F x y)
-	// cond:
 	// result: (MULSD x y)
 	for {
 		y := v.Args[1]
@@ -61446,7 +54840,6 @@
 }
 func rewriteValueAMD64_OpMul64uhilo_0(v *Value) bool {
 	// match: (Mul64uhilo x y)
-	// cond:
 	// result: (MULQU2 x y)
 	for {
 		y := v.Args[1]
@@ -61459,7 +54852,6 @@
 }
 func rewriteValueAMD64_OpMul8_0(v *Value) bool {
 	// match: (Mul8 x y)
-	// cond:
 	// result: (MULL x y)
 	for {
 		y := v.Args[1]
@@ -61472,7 +54864,6 @@
 }
 func rewriteValueAMD64_OpNeg16_0(v *Value) bool {
 	// match: (Neg16 x)
-	// cond:
 	// result: (NEGL x)
 	for {
 		x := v.Args[0]
@@ -61483,7 +54874,6 @@
 }
 func rewriteValueAMD64_OpNeg32_0(v *Value) bool {
 	// match: (Neg32 x)
-	// cond:
 	// result: (NEGL x)
 	for {
 		x := v.Args[0]
@@ -61496,7 +54886,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Neg32F x)
-	// cond:
 	// result: (PXOR x (MOVSSconst <typ.Float32> [auxFrom32F(float32(math.Copysign(0, -1)))]))
 	for {
 		x := v.Args[0]
@@ -61510,7 +54899,6 @@
 }
 func rewriteValueAMD64_OpNeg64_0(v *Value) bool {
 	// match: (Neg64 x)
-	// cond:
 	// result: (NEGQ x)
 	for {
 		x := v.Args[0]
@@ -61523,7 +54911,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Neg64F x)
-	// cond:
 	// result: (PXOR x (MOVSDconst <typ.Float64> [auxFrom64F(math.Copysign(0, -1))]))
 	for {
 		x := v.Args[0]
@@ -61537,7 +54924,6 @@
 }
 func rewriteValueAMD64_OpNeg8_0(v *Value) bool {
 	// match: (Neg8 x)
-	// cond:
 	// result: (NEGL x)
 	for {
 		x := v.Args[0]
@@ -61549,7 +54935,6 @@
 func rewriteValueAMD64_OpNeq16_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq16 x y)
-	// cond:
 	// result: (SETNE (CMPW x y))
 	for {
 		y := v.Args[1]
@@ -61565,7 +54950,6 @@
 func rewriteValueAMD64_OpNeq32_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq32 x y)
-	// cond:
 	// result: (SETNE (CMPL x y))
 	for {
 		y := v.Args[1]
@@ -61581,7 +54965,6 @@
 func rewriteValueAMD64_OpNeq32F_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq32F x y)
-	// cond:
 	// result: (SETNEF (UCOMISS x y))
 	for {
 		y := v.Args[1]
@@ -61597,7 +54980,6 @@
 func rewriteValueAMD64_OpNeq64_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq64 x y)
-	// cond:
 	// result: (SETNE (CMPQ x y))
 	for {
 		y := v.Args[1]
@@ -61613,7 +54995,6 @@
 func rewriteValueAMD64_OpNeq64F_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq64F x y)
-	// cond:
 	// result: (SETNEF (UCOMISD x y))
 	for {
 		y := v.Args[1]
@@ -61629,7 +55010,6 @@
 func rewriteValueAMD64_OpNeq8_0(v *Value) bool {
 	b := v.Block
 	// match: (Neq8 x y)
-	// cond:
 	// result: (SETNE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -61645,7 +55025,6 @@
 func rewriteValueAMD64_OpNeqB_0(v *Value) bool {
 	b := v.Block
 	// match: (NeqB x y)
-	// cond:
 	// result: (SETNE (CMPB x y))
 	for {
 		y := v.Args[1]
@@ -61697,7 +55076,6 @@
 }
 func rewriteValueAMD64_OpNilCheck_0(v *Value) bool {
 	// match: (NilCheck ptr mem)
-	// cond:
 	// result: (LoweredNilCheck ptr mem)
 	for {
 		mem := v.Args[1]
@@ -61710,7 +55088,6 @@
 }
 func rewriteValueAMD64_OpNot_0(v *Value) bool {
 	// match: (Not x)
-	// cond:
 	// result: (XORLconst [1] x)
 	for {
 		x := v.Args[0]
@@ -61772,7 +55149,6 @@
 }
 func rewriteValueAMD64_OpOr16_0(v *Value) bool {
 	// match: (Or16 x y)
-	// cond:
 	// result: (ORL x y)
 	for {
 		y := v.Args[1]
@@ -61785,7 +55161,6 @@
 }
 func rewriteValueAMD64_OpOr32_0(v *Value) bool {
 	// match: (Or32 x y)
-	// cond:
 	// result: (ORL x y)
 	for {
 		y := v.Args[1]
@@ -61798,7 +55173,6 @@
 }
 func rewriteValueAMD64_OpOr64_0(v *Value) bool {
 	// match: (Or64 x y)
-	// cond:
 	// result: (ORQ x y)
 	for {
 		y := v.Args[1]
@@ -61811,7 +55185,6 @@
 }
 func rewriteValueAMD64_OpOr8_0(v *Value) bool {
 	// match: (Or8 x y)
-	// cond:
 	// result: (ORL x y)
 	for {
 		y := v.Args[1]
@@ -61824,7 +55197,6 @@
 }
 func rewriteValueAMD64_OpOrB_0(v *Value) bool {
 	// match: (OrB x y)
-	// cond:
 	// result: (ORL x y)
 	for {
 		y := v.Args[1]
@@ -61959,7 +55331,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (PopCount16 x)
-	// cond:
 	// result: (POPCNTL (MOVWQZX <typ.UInt32> x))
 	for {
 		x := v.Args[0]
@@ -61972,7 +55343,6 @@
 }
 func rewriteValueAMD64_OpPopCount32_0(v *Value) bool {
 	// match: (PopCount32 x)
-	// cond:
 	// result: (POPCNTL x)
 	for {
 		x := v.Args[0]
@@ -61983,7 +55353,6 @@
 }
 func rewriteValueAMD64_OpPopCount64_0(v *Value) bool {
 	// match: (PopCount64 x)
-	// cond:
 	// result: (POPCNTQ x)
 	for {
 		x := v.Args[0]
@@ -61996,7 +55365,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (PopCount8 x)
-	// cond:
 	// result: (POPCNTL (MOVBQZX <typ.UInt32> x))
 	for {
 		x := v.Args[0]
@@ -62009,7 +55377,6 @@
 }
 func rewriteValueAMD64_OpRotateLeft16_0(v *Value) bool {
 	// match: (RotateLeft16 a b)
-	// cond:
 	// result: (ROLW a b)
 	for {
 		b := v.Args[1]
@@ -62022,7 +55389,6 @@
 }
 func rewriteValueAMD64_OpRotateLeft32_0(v *Value) bool {
 	// match: (RotateLeft32 a b)
-	// cond:
 	// result: (ROLL a b)
 	for {
 		b := v.Args[1]
@@ -62035,7 +55401,6 @@
 }
 func rewriteValueAMD64_OpRotateLeft64_0(v *Value) bool {
 	// match: (RotateLeft64 a b)
-	// cond:
 	// result: (ROLQ a b)
 	for {
 		b := v.Args[1]
@@ -62048,7 +55413,6 @@
 }
 func rewriteValueAMD64_OpRotateLeft8_0(v *Value) bool {
 	// match: (RotateLeft8 a b)
-	// cond:
 	// result: (ROLB a b)
 	for {
 		b := v.Args[1]
@@ -62061,7 +55425,6 @@
 }
 func rewriteValueAMD64_OpRound32F_0(v *Value) bool {
 	// match: (Round32F x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -62073,7 +55436,6 @@
 }
 func rewriteValueAMD64_OpRound64F_0(v *Value) bool {
 	// match: (Round64F x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -62085,7 +55447,6 @@
 }
 func rewriteValueAMD64_OpRoundToEven_0(v *Value) bool {
 	// match: (RoundToEven x)
-	// cond:
 	// result: (ROUNDSD [0] x)
 	for {
 		x := v.Args[0]
@@ -63459,7 +56820,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Select0 (Mul64uover x y))
-	// cond:
 	// result: (Select0 <typ.UInt64> (MULQU x y))
 	for {
 		v_0 := v.Args[0]
@@ -63477,7 +56837,6 @@
 		return true
 	}
 	// match: (Select0 (Mul32uover x y))
-	// cond:
 	// result: (Select0 <typ.UInt32> (MULLU x y))
 	for {
 		v_0 := v.Args[0]
@@ -63495,7 +56854,6 @@
 		return true
 	}
 	// match: (Select0 (Add64carry x y c))
-	// cond:
 	// result: (Select0 <typ.UInt64> (ADCQ x y (Select1 <types.TypeFlags> (NEGLflags c))))
 	for {
 		v_0 := v.Args[0]
@@ -63519,7 +56877,6 @@
 		return true
 	}
 	// match: (Select0 (Sub64borrow x y c))
-	// cond:
 	// result: (Select0 <typ.UInt64> (SBBQ x y (Select1 <types.TypeFlags> (NEGLflags c))))
 	for {
 		v_0 := v.Args[0]
@@ -63543,7 +56900,6 @@
 		return true
 	}
 	// match: (Select0 <t> (AddTupleFirst32 val tuple))
-	// cond:
 	// result: (ADDL val (Select0 <t> tuple))
 	for {
 		t := v.Type
@@ -63561,7 +56917,6 @@
 		return true
 	}
 	// match: (Select0 <t> (AddTupleFirst64 val tuple))
-	// cond:
 	// result: (ADDQ val (Select0 <t> tuple))
 	for {
 		t := v.Type
@@ -63584,7 +56939,6 @@
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (Select1 (Mul64uover x y))
-	// cond:
 	// result: (SETO (Select1 <types.TypeFlags> (MULQU x y)))
 	for {
 		v_0 := v.Args[0]
@@ -63603,7 +56957,6 @@
 		return true
 	}
 	// match: (Select1 (Mul32uover x y))
-	// cond:
 	// result: (SETO (Select1 <types.TypeFlags> (MULLU x y)))
 	for {
 		v_0 := v.Args[0]
@@ -63622,7 +56975,6 @@
 		return true
 	}
 	// match: (Select1 (Add64carry x y c))
-	// cond:
 	// result: (NEGQ <typ.UInt64> (SBBQcarrymask <typ.UInt64> (Select1 <types.TypeFlags> (ADCQ x y (Select1 <types.TypeFlags> (NEGLflags c))))))
 	for {
 		v_0 := v.Args[0]
@@ -63650,7 +57002,6 @@
 		return true
 	}
 	// match: (Select1 (Sub64borrow x y c))
-	// cond:
 	// result: (NEGQ <typ.UInt64> (SBBQcarrymask <typ.UInt64> (Select1 <types.TypeFlags> (SBBQ x y (Select1 <types.TypeFlags> (NEGLflags c))))))
 	for {
 		v_0 := v.Args[0]
@@ -63678,7 +57029,6 @@
 		return true
 	}
 	// match: (Select1 (NEGLflags (MOVQconst [0])))
-	// cond:
 	// result: (FlagEQ)
 	for {
 		v_0 := v.Args[0]
@@ -63686,17 +57036,13 @@
 			break
 		}
 		v_0_0 := v_0.Args[0]
-		if v_0_0.Op != OpAMD64MOVQconst {
+		if v_0_0.Op != OpAMD64MOVQconst || v_0_0.AuxInt != 0 {
 			break
 		}
-		if v_0_0.AuxInt != 0 {
-			break
-		}
 		v.reset(OpAMD64FlagEQ)
 		return true
 	}
 	// match: (Select1 (NEGLflags (NEGQ (SBBQcarrymask x))))
-	// cond:
 	// result: x
 	for {
 		v_0 := v.Args[0]
@@ -63718,7 +57064,6 @@
 		return true
 	}
 	// match: (Select1 (AddTupleFirst32 _ tuple))
-	// cond:
 	// result: (Select1 tuple)
 	for {
 		v_0 := v.Args[0]
@@ -63731,7 +57076,6 @@
 		return true
 	}
 	// match: (Select1 (AddTupleFirst64 _ tuple))
-	// cond:
 	// result: (Select1 tuple)
 	for {
 		v_0 := v.Args[0]
@@ -63747,7 +57091,6 @@
 }
 func rewriteValueAMD64_OpSignExt16to32_0(v *Value) bool {
 	// match: (SignExt16to32 x)
-	// cond:
 	// result: (MOVWQSX x)
 	for {
 		x := v.Args[0]
@@ -63758,7 +57101,6 @@
 }
 func rewriteValueAMD64_OpSignExt16to64_0(v *Value) bool {
 	// match: (SignExt16to64 x)
-	// cond:
 	// result: (MOVWQSX x)
 	for {
 		x := v.Args[0]
@@ -63769,7 +57111,6 @@
 }
 func rewriteValueAMD64_OpSignExt32to64_0(v *Value) bool {
 	// match: (SignExt32to64 x)
-	// cond:
 	// result: (MOVLQSX x)
 	for {
 		x := v.Args[0]
@@ -63780,7 +57121,6 @@
 }
 func rewriteValueAMD64_OpSignExt8to16_0(v *Value) bool {
 	// match: (SignExt8to16 x)
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		x := v.Args[0]
@@ -63791,7 +57131,6 @@
 }
 func rewriteValueAMD64_OpSignExt8to32_0(v *Value) bool {
 	// match: (SignExt8to32 x)
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		x := v.Args[0]
@@ -63802,7 +57141,6 @@
 }
 func rewriteValueAMD64_OpSignExt8to64_0(v *Value) bool {
 	// match: (SignExt8to64 x)
-	// cond:
 	// result: (MOVBQSX x)
 	for {
 		x := v.Args[0]
@@ -63814,7 +57152,6 @@
 func rewriteValueAMD64_OpSlicemask_0(v *Value) bool {
 	b := v.Block
 	// match: (Slicemask <t> x)
-	// cond:
 	// result: (SARQconst (NEGQ <t> x) [63])
 	for {
 		t := v.Type
@@ -63829,7 +57166,6 @@
 }
 func rewriteValueAMD64_OpSqrt_0(v *Value) bool {
 	// match: (Sqrt x)
-	// cond:
 	// result: (SQRTSD x)
 	for {
 		x := v.Args[0]
@@ -63840,7 +57176,6 @@
 }
 func rewriteValueAMD64_OpStaticCall_0(v *Value) bool {
 	// match: (StaticCall [argwid] {target} mem)
-	// cond:
 	// result: (CALLstatic [argwid] {target} mem)
 	for {
 		argwid := v.AuxInt
@@ -63960,7 +57295,6 @@
 }
 func rewriteValueAMD64_OpSub16_0(v *Value) bool {
 	// match: (Sub16 x y)
-	// cond:
 	// result: (SUBL x y)
 	for {
 		y := v.Args[1]
@@ -63973,7 +57307,6 @@
 }
 func rewriteValueAMD64_OpSub32_0(v *Value) bool {
 	// match: (Sub32 x y)
-	// cond:
 	// result: (SUBL x y)
 	for {
 		y := v.Args[1]
@@ -63986,7 +57319,6 @@
 }
 func rewriteValueAMD64_OpSub32F_0(v *Value) bool {
 	// match: (Sub32F x y)
-	// cond:
 	// result: (SUBSS x y)
 	for {
 		y := v.Args[1]
@@ -63999,7 +57331,6 @@
 }
 func rewriteValueAMD64_OpSub64_0(v *Value) bool {
 	// match: (Sub64 x y)
-	// cond:
 	// result: (SUBQ x y)
 	for {
 		y := v.Args[1]
@@ -64012,7 +57343,6 @@
 }
 func rewriteValueAMD64_OpSub64F_0(v *Value) bool {
 	// match: (Sub64F x y)
-	// cond:
 	// result: (SUBSD x y)
 	for {
 		y := v.Args[1]
@@ -64025,7 +57355,6 @@
 }
 func rewriteValueAMD64_OpSub8_0(v *Value) bool {
 	// match: (Sub8 x y)
-	// cond:
 	// result: (SUBL x y)
 	for {
 		y := v.Args[1]
@@ -64071,7 +57400,6 @@
 }
 func rewriteValueAMD64_OpTrunc_0(v *Value) bool {
 	// match: (Trunc x)
-	// cond:
 	// result: (ROUNDSD [3] x)
 	for {
 		x := v.Args[0]
@@ -64083,7 +57411,6 @@
 }
 func rewriteValueAMD64_OpTrunc16to8_0(v *Value) bool {
 	// match: (Trunc16to8 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64095,7 +57422,6 @@
 }
 func rewriteValueAMD64_OpTrunc32to16_0(v *Value) bool {
 	// match: (Trunc32to16 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64107,7 +57433,6 @@
 }
 func rewriteValueAMD64_OpTrunc32to8_0(v *Value) bool {
 	// match: (Trunc32to8 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64119,7 +57444,6 @@
 }
 func rewriteValueAMD64_OpTrunc64to16_0(v *Value) bool {
 	// match: (Trunc64to16 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64131,7 +57455,6 @@
 }
 func rewriteValueAMD64_OpTrunc64to32_0(v *Value) bool {
 	// match: (Trunc64to32 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64143,7 +57466,6 @@
 }
 func rewriteValueAMD64_OpTrunc64to8_0(v *Value) bool {
 	// match: (Trunc64to8 x)
-	// cond:
 	// result: x
 	for {
 		x := v.Args[0]
@@ -64155,7 +57477,6 @@
 }
 func rewriteValueAMD64_OpWB_0(v *Value) bool {
 	// match: (WB {fn} destptr srcptr mem)
-	// cond:
 	// result: (LoweredWB {fn} destptr srcptr mem)
 	for {
 		fn := v.Aux
@@ -64172,7 +57493,6 @@
 }
 func rewriteValueAMD64_OpXor16_0(v *Value) bool {
 	// match: (Xor16 x y)
-	// cond:
 	// result: (XORL x y)
 	for {
 		y := v.Args[1]
@@ -64185,7 +57505,6 @@
 }
 func rewriteValueAMD64_OpXor32_0(v *Value) bool {
 	// match: (Xor32 x y)
-	// cond:
 	// result: (XORL x y)
 	for {
 		y := v.Args[1]
@@ -64198,7 +57517,6 @@
 }
 func rewriteValueAMD64_OpXor64_0(v *Value) bool {
 	// match: (Xor64 x y)
-	// cond:
 	// result: (XORQ x y)
 	for {
 		y := v.Args[1]
@@ -64211,7 +57529,6 @@
 }
 func rewriteValueAMD64_OpXor8_0(v *Value) bool {
 	// match: (Xor8 x y)
-	// cond:
 	// result: (XORL x y)
 	for {
 		y := v.Args[1]
@@ -64226,7 +57543,6 @@
 	b := v.Block
 	config := b.Func.Config
 	// match: (Zero [0] _ mem)
-	// cond:
 	// result: mem
 	for {
 		if v.AuxInt != 0 {
@@ -64239,7 +57555,6 @@
 		return true
 	}
 	// match: (Zero [1] destptr mem)
-	// cond:
 	// result: (MOVBstoreconst [0] destptr mem)
 	for {
 		if v.AuxInt != 1 {
@@ -64254,7 +57569,6 @@
 		return true
 	}
 	// match: (Zero [2] destptr mem)
-	// cond:
 	// result: (MOVWstoreconst [0] destptr mem)
 	for {
 		if v.AuxInt != 2 {
@@ -64269,7 +57583,6 @@
 		return true
 	}
 	// match: (Zero [4] destptr mem)
-	// cond:
 	// result: (MOVLstoreconst [0] destptr mem)
 	for {
 		if v.AuxInt != 4 {
@@ -64284,7 +57597,6 @@
 		return true
 	}
 	// match: (Zero [8] destptr mem)
-	// cond:
 	// result: (MOVQstoreconst [0] destptr mem)
 	for {
 		if v.AuxInt != 8 {
@@ -64299,7 +57611,6 @@
 		return true
 	}
 	// match: (Zero [3] destptr mem)
-	// cond:
 	// result: (MOVBstoreconst [makeValAndOff(0,2)] destptr (MOVWstoreconst [0] destptr mem))
 	for {
 		if v.AuxInt != 3 {
@@ -64318,7 +57629,6 @@
 		return true
 	}
 	// match: (Zero [5] destptr mem)
-	// cond:
 	// result: (MOVBstoreconst [makeValAndOff(0,4)] destptr (MOVLstoreconst [0] destptr mem))
 	for {
 		if v.AuxInt != 5 {
@@ -64337,7 +57647,6 @@
 		return true
 	}
 	// match: (Zero [6] destptr mem)
-	// cond:
 	// result: (MOVWstoreconst [makeValAndOff(0,4)] destptr (MOVLstoreconst [0] destptr mem))
 	for {
 		if v.AuxInt != 6 {
@@ -64356,7 +57665,6 @@
 		return true
 	}
 	// match: (Zero [7] destptr mem)
-	// cond:
 	// result: (MOVLstoreconst [makeValAndOff(0,3)] destptr (MOVLstoreconst [0] destptr mem))
 	for {
 		if v.AuxInt != 7 {
@@ -64732,7 +58040,6 @@
 }
 func rewriteValueAMD64_OpZeroExt16to32_0(v *Value) bool {
 	// match: (ZeroExt16to32 x)
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		x := v.Args[0]
@@ -64743,7 +58050,6 @@
 }
 func rewriteValueAMD64_OpZeroExt16to64_0(v *Value) bool {
 	// match: (ZeroExt16to64 x)
-	// cond:
 	// result: (MOVWQZX x)
 	for {
 		x := v.Args[0]
@@ -64754,7 +58060,6 @@
 }
 func rewriteValueAMD64_OpZeroExt32to64_0(v *Value) bool {
 	// match: (ZeroExt32to64 x)
-	// cond:
 	// result: (MOVLQZX x)
 	for {
 		x := v.Args[0]
@@ -64765,7 +58070,6 @@
 }
 func rewriteValueAMD64_OpZeroExt8to16_0(v *Value) bool {
 	// match: (ZeroExt8to16 x)
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		x := v.Args[0]
@@ -64776,7 +58080,6 @@
 }
 func rewriteValueAMD64_OpZeroExt8to32_0(v *Value) bool {
 	// match: (ZeroExt8to32 x)
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		x := v.Args[0]
@@ -64787,7 +58090,6 @@
 }
 func rewriteValueAMD64_OpZeroExt8to64_0(v *Value) bool {
 	// match: (ZeroExt8to64 x)
-	// cond:
 	// result: (MOVBQZX x)
 	for {
 		x := v.Args[0]
@@ -64812,15 +58114,9 @@
 			}
 			x := v_0.Args[1]
 			v_0_0 := v_0.Args[0]
-			if v_0_0.Op != OpAMD64MOVLconst {
+			if v_0_0.Op != OpAMD64MOVLconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_0_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 			v0.AddArg(x)
@@ -64841,15 +58137,9 @@
 			}
 			x := v_1.Args[1]
 			v_1_0 := v_1.Args[0]
-			if v_1_0.Op != OpAMD64MOVLconst {
+			if v_1_0.Op != OpAMD64MOVLconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_1_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 			v0.AddArg(x)
@@ -64869,15 +58159,9 @@
 			}
 			x := v_0.Args[1]
 			v_0_0 := v_0.Args[0]
-			if v_0_0.Op != OpAMD64MOVQconst {
+			if v_0_0.Op != OpAMD64MOVQconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_0_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 			v0.AddArg(x)
@@ -64898,15 +58182,9 @@
 			}
 			x := v_1.Args[1]
 			v_1_0 := v_1.Args[0]
-			if v_1_0.Op != OpAMD64MOVQconst {
+			if v_1_0.Op != OpAMD64MOVQconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_1_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 			v0.AddArg(x)
@@ -64998,19 +58276,13 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHLQconst {
+			if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65030,19 +58302,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHLQconst {
+			if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65061,19 +58327,13 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHLLconst {
+			if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65093,19 +58353,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHLLconst {
+			if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65124,19 +58378,13 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLQconst {
+			if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65156,19 +58404,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLQconst {
+			if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65187,19 +58429,13 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLLconst {
+			if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65219,19 +58455,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLLconst {
+			if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65250,12 +58480,9 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65275,12 +58502,9 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65299,12 +58523,9 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65324,12 +58545,9 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -65343,7 +58561,6 @@
 			return true
 		}
 		// match: (EQ (InvertFlags cmp) yes no)
-		// cond:
 		// result: (EQ cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -65353,7 +58570,6 @@
 			return true
 		}
 		// match: (EQ (FlagEQ) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -65362,7 +58578,6 @@
 			return true
 		}
 		// match: (EQ (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -65372,7 +58587,6 @@
 			return true
 		}
 		// match: (EQ (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -65382,7 +58596,6 @@
 			return true
 		}
 		// match: (EQ (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -65392,7 +58605,6 @@
 			return true
 		}
 		// match: (EQ (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -65403,7 +58615,6 @@
 		}
 	case BlockAMD64GE:
 		// match: (GE (InvertFlags cmp) yes no)
-		// cond:
 		// result: (LE cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -65413,7 +58624,6 @@
 			return true
 		}
 		// match: (GE (FlagEQ) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -65422,7 +58632,6 @@
 			return true
 		}
 		// match: (GE (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -65432,7 +58641,6 @@
 			return true
 		}
 		// match: (GE (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -65442,7 +58650,6 @@
 			return true
 		}
 		// match: (GE (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -65451,7 +58658,6 @@
 			return true
 		}
 		// match: (GE (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -65461,7 +58667,6 @@
 		}
 	case BlockAMD64GT:
 		// match: (GT (InvertFlags cmp) yes no)
-		// cond:
 		// result: (LT cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -65471,7 +58676,6 @@
 			return true
 		}
 		// match: (GT (FlagEQ) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -65481,7 +58685,6 @@
 			return true
 		}
 		// match: (GT (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -65491,7 +58694,6 @@
 			return true
 		}
 		// match: (GT (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -65501,7 +58703,6 @@
 			return true
 		}
 		// match: (GT (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -65510,7 +58711,6 @@
 			return true
 		}
 		// match: (GT (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -65520,7 +58720,6 @@
 		}
 	case BlockIf:
 		// match: (If (SETL cmp) yes no)
-		// cond:
 		// result: (LT cmp yes no)
 		for v.Op == OpAMD64SETL {
 			cmp := v.Args[0]
@@ -65530,7 +58729,6 @@
 			return true
 		}
 		// match: (If (SETLE cmp) yes no)
-		// cond:
 		// result: (LE cmp yes no)
 		for v.Op == OpAMD64SETLE {
 			cmp := v.Args[0]
@@ -65540,7 +58738,6 @@
 			return true
 		}
 		// match: (If (SETG cmp) yes no)
-		// cond:
 		// result: (GT cmp yes no)
 		for v.Op == OpAMD64SETG {
 			cmp := v.Args[0]
@@ -65550,7 +58747,6 @@
 			return true
 		}
 		// match: (If (SETGE cmp) yes no)
-		// cond:
 		// result: (GE cmp yes no)
 		for v.Op == OpAMD64SETGE {
 			cmp := v.Args[0]
@@ -65560,7 +58756,6 @@
 			return true
 		}
 		// match: (If (SETEQ cmp) yes no)
-		// cond:
 		// result: (EQ cmp yes no)
 		for v.Op == OpAMD64SETEQ {
 			cmp := v.Args[0]
@@ -65570,7 +58765,6 @@
 			return true
 		}
 		// match: (If (SETNE cmp) yes no)
-		// cond:
 		// result: (NE cmp yes no)
 		for v.Op == OpAMD64SETNE {
 			cmp := v.Args[0]
@@ -65580,7 +58774,6 @@
 			return true
 		}
 		// match: (If (SETB cmp) yes no)
-		// cond:
 		// result: (ULT cmp yes no)
 		for v.Op == OpAMD64SETB {
 			cmp := v.Args[0]
@@ -65590,7 +58783,6 @@
 			return true
 		}
 		// match: (If (SETBE cmp) yes no)
-		// cond:
 		// result: (ULE cmp yes no)
 		for v.Op == OpAMD64SETBE {
 			cmp := v.Args[0]
@@ -65600,7 +58792,6 @@
 			return true
 		}
 		// match: (If (SETA cmp) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64SETA {
 			cmp := v.Args[0]
@@ -65610,7 +58801,6 @@
 			return true
 		}
 		// match: (If (SETAE cmp) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64SETAE {
 			cmp := v.Args[0]
@@ -65620,7 +58810,6 @@
 			return true
 		}
 		// match: (If (SETO cmp) yes no)
-		// cond:
 		// result: (OS cmp yes no)
 		for v.Op == OpAMD64SETO {
 			cmp := v.Args[0]
@@ -65630,7 +58819,6 @@
 			return true
 		}
 		// match: (If (SETGF cmp) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64SETGF {
 			cmp := v.Args[0]
@@ -65640,7 +58828,6 @@
 			return true
 		}
 		// match: (If (SETGEF cmp) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64SETGEF {
 			cmp := v.Args[0]
@@ -65650,7 +58837,6 @@
 			return true
 		}
 		// match: (If (SETEQF cmp) yes no)
-		// cond:
 		// result: (EQF cmp yes no)
 		for v.Op == OpAMD64SETEQF {
 			cmp := v.Args[0]
@@ -65660,7 +58846,6 @@
 			return true
 		}
 		// match: (If (SETNEF cmp) yes no)
-		// cond:
 		// result: (NEF cmp yes no)
 		for v.Op == OpAMD64SETNEF {
 			cmp := v.Args[0]
@@ -65670,7 +58855,6 @@
 			return true
 		}
 		// match: (If cond yes no)
-		// cond:
 		// result: (NE (TESTB cond cond) yes no)
 		for {
 			cond := b.Control
@@ -65684,7 +58868,6 @@
 		}
 	case BlockAMD64LE:
 		// match: (LE (InvertFlags cmp) yes no)
-		// cond:
 		// result: (GE cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -65694,7 +58877,6 @@
 			return true
 		}
 		// match: (LE (FlagEQ) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -65703,7 +58885,6 @@
 			return true
 		}
 		// match: (LE (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -65712,7 +58893,6 @@
 			return true
 		}
 		// match: (LE (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -65721,7 +58901,6 @@
 			return true
 		}
 		// match: (LE (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -65731,7 +58910,6 @@
 			return true
 		}
 		// match: (LE (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -65742,7 +58920,6 @@
 		}
 	case BlockAMD64LT:
 		// match: (LT (InvertFlags cmp) yes no)
-		// cond:
 		// result: (GT cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -65752,7 +58929,6 @@
 			return true
 		}
 		// match: (LT (FlagEQ) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -65762,7 +58938,6 @@
 			return true
 		}
 		// match: (LT (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -65771,7 +58946,6 @@
 			return true
 		}
 		// match: (LT (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -65780,7 +58954,6 @@
 			return true
 		}
 		// match: (LT (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -65790,7 +58963,6 @@
 			return true
 		}
 		// match: (LT (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -65801,7 +58973,6 @@
 		}
 	case BlockAMD64NE:
 		// match: (NE (TESTB (SETL cmp) (SETL cmp)) yes no)
-		// cond:
 		// result: (LT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65811,19 +58982,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETL {
+			if v_1.Op != OpAMD64SETL || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64LT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETL cmp) (SETL cmp)) yes no)
-		// cond:
 		// result: (LT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65833,19 +59000,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETL {
+			if v_1.Op != OpAMD64SETL || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64LT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETLE cmp) (SETLE cmp)) yes no)
-		// cond:
 		// result: (LE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65855,19 +59018,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETLE {
+			if v_1.Op != OpAMD64SETLE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64LE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETLE cmp) (SETLE cmp)) yes no)
-		// cond:
 		// result: (LE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65877,19 +59036,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETLE {
+			if v_1.Op != OpAMD64SETLE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64LE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETG cmp) (SETG cmp)) yes no)
-		// cond:
 		// result: (GT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65899,19 +59054,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETG {
+			if v_1.Op != OpAMD64SETG || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64GT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETG cmp) (SETG cmp)) yes no)
-		// cond:
 		// result: (GT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65921,19 +59072,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETG {
+			if v_1.Op != OpAMD64SETG || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64GT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETGE cmp) (SETGE cmp)) yes no)
-		// cond:
 		// result: (GE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65943,19 +59090,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGE {
+			if v_1.Op != OpAMD64SETGE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64GE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETGE cmp) (SETGE cmp)) yes no)
-		// cond:
 		// result: (GE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65965,19 +59108,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGE {
+			if v_1.Op != OpAMD64SETGE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64GE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETEQ cmp) (SETEQ cmp)) yes no)
-		// cond:
 		// result: (EQ cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -65987,19 +59126,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETEQ {
+			if v_1.Op != OpAMD64SETEQ || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64EQ
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETEQ cmp) (SETEQ cmp)) yes no)
-		// cond:
 		// result: (EQ cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66009,19 +59144,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETEQ {
+			if v_1.Op != OpAMD64SETEQ || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64EQ
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETNE cmp) (SETNE cmp)) yes no)
-		// cond:
 		// result: (NE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66031,19 +59162,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETNE {
+			if v_1.Op != OpAMD64SETNE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64NE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETNE cmp) (SETNE cmp)) yes no)
-		// cond:
 		// result: (NE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66053,19 +59180,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETNE {
+			if v_1.Op != OpAMD64SETNE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64NE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETB cmp) (SETB cmp)) yes no)
-		// cond:
 		// result: (ULT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66075,19 +59198,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETB {
+			if v_1.Op != OpAMD64SETB || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETB cmp) (SETB cmp)) yes no)
-		// cond:
 		// result: (ULT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66097,19 +59216,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETB {
+			if v_1.Op != OpAMD64SETB || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETBE cmp) (SETBE cmp)) yes no)
-		// cond:
 		// result: (ULE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66119,19 +59234,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETBE {
+			if v_1.Op != OpAMD64SETBE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64ULE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETBE cmp) (SETBE cmp)) yes no)
-		// cond:
 		// result: (ULE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66141,19 +59252,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETBE {
+			if v_1.Op != OpAMD64SETBE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64ULE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETA cmp) (SETA cmp)) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66163,19 +59270,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETA {
+			if v_1.Op != OpAMD64SETA || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETA cmp) (SETA cmp)) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66185,19 +59288,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETA {
+			if v_1.Op != OpAMD64SETA || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETAE cmp) (SETAE cmp)) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66207,19 +59306,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETAE {
+			if v_1.Op != OpAMD64SETAE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETAE cmp) (SETAE cmp)) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66229,19 +59324,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETAE {
+			if v_1.Op != OpAMD64SETAE || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETO cmp) (SETO cmp)) yes no)
-		// cond:
 		// result: (OS cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66251,19 +59342,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETO {
+			if v_1.Op != OpAMD64SETO || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64OS
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETO cmp) (SETO cmp)) yes no)
-		// cond:
 		// result: (OS cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66273,12 +59360,9 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETO {
+			if v_1.Op != OpAMD64SETO || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64OS
 			b.SetControl(cmp)
 			b.Aux = nil
@@ -66295,15 +59379,9 @@
 			}
 			x := v_0.Args[1]
 			v_0_0 := v_0.Args[0]
-			if v_0_0.Op != OpAMD64MOVLconst {
+			if v_0_0.Op != OpAMD64MOVLconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_0_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 			v0.AddArg(x)
@@ -66324,15 +59402,9 @@
 			}
 			x := v_1.Args[1]
 			v_1_0 := v_1.Args[0]
-			if v_1_0.Op != OpAMD64MOVLconst {
+			if v_1_0.Op != OpAMD64MOVLconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_1_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			v0 := b.NewValue0(v.Pos, OpAMD64BTL, types.TypeFlags)
 			v0.AddArg(x)
@@ -66352,15 +59424,9 @@
 			}
 			x := v_0.Args[1]
 			v_0_0 := v_0.Args[0]
-			if v_0_0.Op != OpAMD64MOVQconst {
+			if v_0_0.Op != OpAMD64MOVQconst || v_0_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_0_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 			v0.AddArg(x)
@@ -66381,15 +59447,9 @@
 			}
 			x := v_1.Args[1]
 			v_1_0 := v_1.Args[0]
-			if v_1_0.Op != OpAMD64MOVQconst {
+			if v_1_0.Op != OpAMD64MOVQconst || v_1_0.AuxInt != 1 || !(!config.nacl) {
 				break
 			}
-			if v_1_0.AuxInt != 1 {
-				break
-			}
-			if !(!config.nacl) {
-				break
-			}
 			b.Kind = BlockAMD64ULT
 			v0 := b.NewValue0(v.Pos, OpAMD64BTQ, types.TypeFlags)
 			v0.AddArg(x)
@@ -66481,19 +59541,13 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHLQconst {
+			if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66513,19 +59567,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHLQconst {
+			if z1.Op != OpAMD64SHLQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66544,19 +59592,13 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHLLconst {
+			if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66576,19 +59618,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHLLconst {
+			if z1.Op != OpAMD64SHLLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHRQconst {
+			if z1_0.Op != OpAMD64SHRQconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66607,19 +59643,13 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLQconst {
+			if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66639,19 +59669,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLQconst {
+			if z1_0.Op != OpAMD64SHLQconst || z1_0.AuxInt != 63 {
 				break
 			}
-			if z1_0.AuxInt != 63 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66670,19 +59694,13 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLLconst {
+			if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66702,19 +59720,13 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			z1_0 := z1.Args[0]
-			if z1_0.Op != OpAMD64SHLLconst {
+			if z1_0.Op != OpAMD64SHLLconst || z1_0.AuxInt != 31 {
 				break
 			}
-			if z1_0.AuxInt != 31 {
-				break
-			}
 			x := z1_0.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66733,12 +59745,9 @@
 		for v.Op == OpAMD64TESTQ {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66758,12 +59767,9 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRQconst {
+			if z1.Op != OpAMD64SHRQconst || z1.AuxInt != 63 {
 				break
 			}
-			if z1.AuxInt != 63 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66782,12 +59788,9 @@
 		for v.Op == OpAMD64TESTL {
 			z2 := v.Args[1]
 			z1 := v.Args[0]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66807,12 +59810,9 @@
 			_ = v.Args[1]
 			z2 := v.Args[0]
 			z1 := v.Args[1]
-			if z1.Op != OpAMD64SHRLconst {
+			if z1.Op != OpAMD64SHRLconst || z1.AuxInt != 31 {
 				break
 			}
-			if z1.AuxInt != 31 {
-				break
-			}
 			x := z1.Args[0]
 			if !(z1 == z2 && !config.nacl) {
 				break
@@ -66826,7 +59826,6 @@
 			return true
 		}
 		// match: (NE (TESTB (SETGF cmp) (SETGF cmp)) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66836,19 +59835,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGF {
+			if v_1.Op != OpAMD64SETGF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETGF cmp) (SETGF cmp)) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66858,19 +59853,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGF {
+			if v_1.Op != OpAMD64SETGF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGT
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETGEF cmp) (SETGEF cmp)) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66880,19 +59871,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGEF {
+			if v_1.Op != OpAMD64SETGEF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETGEF cmp) (SETGEF cmp)) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66902,19 +59889,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETGEF {
+			if v_1.Op != OpAMD64SETGEF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64UGE
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETEQF cmp) (SETEQF cmp)) yes no)
-		// cond:
 		// result: (EQF cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66924,19 +59907,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETEQF {
+			if v_1.Op != OpAMD64SETEQF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64EQF
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETEQF cmp) (SETEQF cmp)) yes no)
-		// cond:
 		// result: (EQF cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66946,19 +59925,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETEQF {
+			if v_1.Op != OpAMD64SETEQF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64EQF
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETNEF cmp) (SETNEF cmp)) yes no)
-		// cond:
 		// result: (NEF cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66968,19 +59943,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETNEF {
+			if v_1.Op != OpAMD64SETNEF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64NEF
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (TESTB (SETNEF cmp) (SETNEF cmp)) yes no)
-		// cond:
 		// result: (NEF cmp yes no)
 		for v.Op == OpAMD64TESTB {
 			_ = v.Args[1]
@@ -66990,19 +59961,15 @@
 			}
 			cmp := v_0.Args[0]
 			v_1 := v.Args[1]
-			if v_1.Op != OpAMD64SETNEF {
+			if v_1.Op != OpAMD64SETNEF || cmp != v_1.Args[0] {
 				break
 			}
-			if cmp != v_1.Args[0] {
-				break
-			}
 			b.Kind = BlockAMD64NEF
 			b.SetControl(cmp)
 			b.Aux = nil
 			return true
 		}
 		// match: (NE (InvertFlags cmp) yes no)
-		// cond:
 		// result: (NE cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -67012,7 +59979,6 @@
 			return true
 		}
 		// match: (NE (FlagEQ) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -67022,7 +59988,6 @@
 			return true
 		}
 		// match: (NE (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -67031,7 +59996,6 @@
 			return true
 		}
 		// match: (NE (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -67040,7 +60004,6 @@
 			return true
 		}
 		// match: (NE (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -67049,7 +60012,6 @@
 			return true
 		}
 		// match: (NE (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -67059,7 +60021,6 @@
 		}
 	case BlockAMD64UGE:
 		// match: (UGE (InvertFlags cmp) yes no)
-		// cond:
 		// result: (ULE cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -67069,7 +60030,6 @@
 			return true
 		}
 		// match: (UGE (FlagEQ) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -67078,7 +60038,6 @@
 			return true
 		}
 		// match: (UGE (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -67088,7 +60047,6 @@
 			return true
 		}
 		// match: (UGE (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -67097,7 +60055,6 @@
 			return true
 		}
 		// match: (UGE (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -67107,7 +60064,6 @@
 			return true
 		}
 		// match: (UGE (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -67117,7 +60073,6 @@
 		}
 	case BlockAMD64UGT:
 		// match: (UGT (InvertFlags cmp) yes no)
-		// cond:
 		// result: (ULT cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -67127,7 +60082,6 @@
 			return true
 		}
 		// match: (UGT (FlagEQ) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -67137,7 +60091,6 @@
 			return true
 		}
 		// match: (UGT (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -67147,7 +60100,6 @@
 			return true
 		}
 		// match: (UGT (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -67156,7 +60108,6 @@
 			return true
 		}
 		// match: (UGT (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -67166,7 +60117,6 @@
 			return true
 		}
 		// match: (UGT (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -67176,7 +60126,6 @@
 		}
 	case BlockAMD64ULE:
 		// match: (ULE (InvertFlags cmp) yes no)
-		// cond:
 		// result: (UGE cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -67186,7 +60135,6 @@
 			return true
 		}
 		// match: (ULE (FlagEQ) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -67195,7 +60143,6 @@
 			return true
 		}
 		// match: (ULE (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -67204,7 +60151,6 @@
 			return true
 		}
 		// match: (ULE (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -67214,7 +60160,6 @@
 			return true
 		}
 		// match: (ULE (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -67223,7 +60168,6 @@
 			return true
 		}
 		// match: (ULE (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
@@ -67234,7 +60178,6 @@
 		}
 	case BlockAMD64ULT:
 		// match: (ULT (InvertFlags cmp) yes no)
-		// cond:
 		// result: (UGT cmp yes no)
 		for v.Op == OpAMD64InvertFlags {
 			cmp := v.Args[0]
@@ -67244,7 +60187,6 @@
 			return true
 		}
 		// match: (ULT (FlagEQ) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagEQ {
 			b.Kind = BlockFirst
@@ -67254,7 +60196,6 @@
 			return true
 		}
 		// match: (ULT (FlagLT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagLT_ULT {
 			b.Kind = BlockFirst
@@ -67263,7 +60204,6 @@
 			return true
 		}
 		// match: (ULT (FlagLT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagLT_UGT {
 			b.Kind = BlockFirst
@@ -67273,7 +60213,6 @@
 			return true
 		}
 		// match: (ULT (FlagGT_ULT) yes no)
-		// cond:
 		// result: (First nil yes no)
 		for v.Op == OpAMD64FlagGT_ULT {
 			b.Kind = BlockFirst
@@ -67282,7 +60221,6 @@
 			return true
 		}
 		// match: (ULT (FlagGT_UGT) yes no)
-		// cond:
 		// result: (First nil no yes)
 		for v.Op == OpAMD64FlagGT_UGT {
 			b.Kind = BlockFirst
